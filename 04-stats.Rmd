Section 4: Understanding Graphical & Statistical Procedures
===========================================================

Thinking About Statistics
-------------------------

Statistics is in a sense a giant toolbox containing a collection of
graphical and statistical procedures.\
\
Each graphical or statistical procedure is good for a particular
situation we may run into while doing data analysis. The main purpose of
any graphical and statistical procedure is to investigate a variable or
the relationships between variables. That is a very important concept!

**THE MAIN PURPOSE OF ANY GRAPHICAL OR STATISTICAL PROCEDURE IS TO
INVESTIGATE A VARIABLE OR THE RELATIONSHIPS BETWEEN VARIABLES.**

Keep in mind that graphical procedures can be more valuable to you than
statistical procedures. You should try to express your results in graphs
whenever you can.

It is not hard to implement or interpret any graphical or statistical
procedure once you understand and can explain the procedure. SPSS is
very helpful in both regards. The biggest challenge facing any
researcher is to know the most appropriate procedure to apply in any
particular situation.\
\
The types of the independent and dependent variables (predictors and
outcome) will guide your choice for the appropriate graphical and
statistical procedure.

Just like in many things in life, the 80/20 rule somewhat applies to
statistics. There are a small number of procedures that you will use
more repeatedly than others. Here, we will divide those essential
procedures, graphical and statistical, into 4 major classifications:

-   One Variable Only Procedures

-   One-on-One Procedures investigating two variables at a time

-   Many-on-One Procedures

-   Repeated, Longitudinal, Clustered, Multilevel, and Mixed Procedures

Correlation vs. Causation
-------------------------

The presence of a correlation between two variables DOES NOT imply that
there is causation between them. Any of the three scenarios below could
explain the correlation between two variables A and B. We can't tell
using statistics alone which scenario it is.

-   A causes B

-   B causes A

-   C causes both A and B

Everything On One Page Handout
------------------------------

The chart on the next page lays out the essential graphical and
statistical procedures by type and classification.

![](./media/image53.png){width="9.269444444444444in"
height="6.001388888888889in"}

Parametric vs. Non-parametric Tests
-----------------------------------

There are varying assumptions that underlie the validity of each
statistical procedure. A common assumption for statistical procedures is
that the samples being analyzed should come from an underlying normal
distribution. If this is not a reasonable assumption, you can use
non-parametric tests. Non-parametric tests do not have this
distributional assumption, and generally use ranks in the place of the
raw scores. The table below gives non-parametric tests that are
equivalent to common parametric tests.

Basic Summary Statistics (Investigate One Variable at a Time)
-------------------------------------------------------------

As the name implies, One-Variable-Only Procedures help us investigate a
single variable at a time. They can tell us about the frequency
distribution of a categorical variable (Frequency Table, Mode, Bar
Graph, Pie Chart, etc.). They can give us insight into the central
tendency of a continuous variable (Mean, Median, Mode, etc.). They can
help us test a hypothesis about the mean of a variable (One Sample
t-test). They can give us insight into the dispersion of a variable
(Standard Deviation, Range, Inter-Quartile Range, Boxplots, Error Bar
Plots, etc.). They can also give us insight into the relative position
of any data point with respect to the other data points in a variable
(Percentiles, Quartiles, Boxplots, etc.).

In SPSS, there are two procedures which provide simple descriptive
statistics. You can find both procedures under "Analyze" "Descriptive
Statistics".

![](./media/image55.png){width="5.0in" height="2.4583333333333335in"}
![](./media/image56.png){width="5.0in" height="2.2395833333333335in"}

**Frequencies** procedure provides the number and % of cases which have
each value of a variable (e.g., 46% male, 54% female). You can request
other output by clicking Statistics. Frequencies are most useful for
categorical variables.

**Try it: Use Section4\_1\_Data.sav. Obtain the frequency (descriptive)
statistics for the variable Sex.**

![](./media/image57.png){width="4.895833333333333in"
height="3.0833333333333335in"}

+-------------------+-----------+--------+
| > **Statistics**  |
+-------------------+-----------+--------+
| Respondent\'s Sex |
+-------------------+-----------+--------+
| > N               | > Valid   | > 1517 |
+-------------------+-----------+--------+
|                   | > Missing | > 0    |
+-------------------+-----------+--------+

+-----------+-----------+-----------+-----------+-----------+-----------+
| > **Respo |
| ndent\'s  |
| > Sex**   |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Frequen | > Percent | > Valid   | > Cumulat |
|           | cy        |           | > Percent | ive       |
|           |           |           |           | > Percent |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Valid   | > Male    | > 636     | > 41.9    | > 41.9    | > 41.9    |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Female  | > 881     | > 58.1    | > 58.1    | > 100.0   |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Total   | > 1517    | > 100.0   | > 100.0   |           |
+-----------+-----------+-----------+-----------+-----------+-----------+

**Descriptives** provides the mean, standard deviation, minimum, maximum
and non-missing sample size by default. Other statistics are available
by clicking Options. Descriptives are most useful for continuous
variables, and sometimes useful for ordinal data (categorical data with
ordering, e.g., small, medium, large) alongside the frequencies.

**Try it: Use Section4\_1\_Data.sav. Obtain the descriptive statistics
for the variable Age.**

![](./media/image58.png){width="6.5in" height="3.2291666666666665in"}

![](./media/image59.png){width="4.416666666666667in" height="2.0in"}

+-----------+-----------+-----------+-----------+-----------+-----------+
| > **Descr |
| iptive    |
| > Statist |
| ics**     |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > N       | > Minimum | > Maximum | > Mean    | > Std.    |
|           |           |           |           |           | > Deviati |
|           |           |           |           |           | on        |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Age of  | > 1514    | > 18      | > 89      | > 45.63   | > 17.808  |
| > Respond |           |           |           |           |           |
| ent       |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Valid N | > 1514    |           |           |           |           |
| > (listwi |           |           |           |           |           |
| se)       |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+

As a first step in data analysis, one might run frequencies on all
categorical variables and descriptives on all continuous variables.
Obtaining descriptive statistics is an important step to detect possible
data entry errors.

Visualizations
--------------

There are two methods for creating charts in SPSS, Chart Builder and
Legacy Dialogs. (There is a third method, in which other analysis
methods create their own graphics, but we're covering only direct
creation of graphics here.)

The newer approach is Chart Builder, which is a more free-form approach.
It has a steeper learning curve but is ultimately more powerful.

The classic approach is legacy dialogs which are much easier to use, but
more restrictive in the types of plots they can create.

### Chart Builder

To create a graph in "Chart Builder", first select the type of graph
that you would like to create by dragging and dropping the appropriate
graph image to the "Chart Preview" area. Once you select a chart, the
Element Properties window will appear. The Element Properties window
allows you to modify what is displayed in the graph

![](./media/image60.png){width="6.5in" height="4.488888888888889in"}

**Try it: Use Section4\_1Data.sav. Create a simple bar chart for
"Region". **

![](./media/image61.png){width="5.05625in"
height="4.614583333333333in"}![](./media/image62.png){width="5.18125in"
height="3.8229166666666665in"}

### Legacy Dialogs

The "Legacy Dialogs" interface requires that you determine the type of
graph you would like to create before providing a dialog box, which is
similar to other procedures in SPSS. After you select the general type
of graph or chart, SPSS will then prompt you to be more specific. If the
general form is a scatter plot, for example, SPSS will ask you to then
specify which type of scatter plot you would like to create. The
software will present you with the graphing dialogue box once you
specify the specific form for the graph.

![](./media/image63.png){width="3.6875in" height="1.6041666666666667in"}
![](./media/image64.png){width="4.552083333333333in" height="4.71875in"}

**Try it: Use Section4\_1Data.sav. Create a simple bar chart for
"Region". **

![](./media/image65.png){width="3.5377318460192475in"
height="4.020833333333333in"}![](./media/image62.png){width="5.18125in"
height="4.177083333333333in"}

Normality
---------

Many statistical procedures assume "normality", which means the
population which the data is from follows the Normal Distribution. You
may know this as the "bell curve".

![https://s15-us2.ixquick.com/cgi-bin/serveimage?url=https:%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2Fd%2Fdf%2FBellcurve.svg%2F2000px-Bellcurve.svg.png&sp=e6ff634ca3ce0a0de1bfab4490a45ca7](./media/image66.png){width="5.05625in"
height="3.159650043744532in"}

Many real-life variables follow a normal distribution such as height. If
you were to collect a random sample of heights, most people would fall
near the mean height for the population. Some people would be much
taller or shorter, and a very limited number of people would be
extremely short or extremely tall.

The normality assumption as written is usually quite strict; in practice
we often loosen it. Rather than "The data comes from a normal
population", you can think of it as "The data comes from a population
that's not too badly non-normal." Essentially, you're looking for major
violations of normality, rather than trying to determine whether the
bell curve perfectly fits your data.

Finally, a large sample size oftens "protects" you from normality
violations; the larger the sample size, the more extreme a normality
violation needs to be to be a concern.

While there are formal tests of normality, typically assessment is done
with a histogram (looking for that bell shape) or a QQ-plot, which looks
for its values to fall along the 90° line. The histogram can be created
from the Histogram Legacy Dialog, the QQ-plot is created under Analyze
-\> Descriptive Statistics -\> QQPlot.

**Try it: Use Section4\_1Data.sav. Obtain a histogram for the variable
"Age" and display the normal curve. Obtain a QQ plot for the variable
"Age". Hint: 'Analyze' 'Descriptive Statistics' 'QQPlot'.**

![](./media/image67.png){width="3.0625in" height="2.7527777777777778in"}

![](./media/image68.png){width="3.5729166666666665in"
height="2.8314818460192477in"}

![](./media/image69.png){width="3.6979166666666665in"
height="2.7043985126859145in"}![](./media/image70.png){width="3.5625in"
height="2.82245406824147in"}

Exercise 8 -- Data Exploration and Visualization
------------------------------------------------

Open Exercise8\_Data.sav

**Part 1**: Investigate the variable attributes. Determine which
variables are categorical variables (nominal and ordinal), and which
variables are continuous (scale).

Obtain the appropriate descriptive statistics for each variable.
Remember, continuous variables should be investigated with descriptives
and categorical variables should be investigated with frequency tables.

\*Hint: Select more than one variable in the "Analyze" "Descriptive
Statistics" "Descriptives" or "Frequencies" dialog boxes.

**Part 2**: Assess the distribution of the Occupational Prestige Score
("prestg80") with both a histogram (normal curve displayed) and a Q-Q
plot. Is the assumption that the population of Occupational Prestige
Scores is normally distributed reasonable?

**Part 3**: Compare the average highest year of school completed
("educ") for males and females.

\*Hint: First split the file by "sex" ("Data" "Split File"), then
calculate the descriptive statistics. Be sure to return to the "Split
File" menu when you are done with this question and return the dialog
box to "Analyze all cases".

**Part 4**: Produce a pie chart for the variable "region". (We didn't
cover this, you can use either Chart Builder or Legacy Dialogs.)

Investigating Two Variables at a Time
-------------------------------------

The main purpose of any graphical and statistical procedure is to
investigate a variable or the relationships between variables. We start
by examining the relationship between variables using simple
two-variable procedures. The type of independent and dependent variables
that you would like to investigate determines the appropriate
statistical or graphical procedure. Remember that the presence of a
correlation between two variables DOES NOT imply that there is causation
between them.

### Pearson Correlation Coefficient & Scatterplots

The Pearson Correlation Coefficient measures the linear association of
two continuous variables. A scatterplot is an easy way to visually
explore the association between two variables. When you plot the
variables together, you obtain a clear sense of the overall relationship
between the two variables.

The Pearson Correlation Coefficient (Pearson's r) varies from -1 to +1.
A value of zero indicates that there is no linear relationship between
the two variables, a value of +1 indicates that there is a perfect
positive linear relationship, and a value of -1 indicates that there is
a perfect negative relationship. Positive relationships imply that
variable 2 increases when variable 1 increases, and vice versa, while
negative relationships imply variable 2 increases when variable 1
decreases, and vice versa.

Assessing the statistical significance of a correlation is the same as
testing the chance that the observed correlation is significantly
different from zero correlation.

For the Pearson Correlation Coefficient in SPSS, select "Analyze"
"Correlate" "Bivariate".

![](./media/image71.png){width="3.8541666666666665in" height="3.0in"}

For the Scatterplot in SPSS, select "Graphs" "Legacy Dialogs"
"Scatter/Dot" "Simple Scatter" and click "Define".

![](./media/image64.png){width="3.880323709536308in"
height="3.9676115485564303in"}![](./media/image63.png){width="3.18125in"
height="1.6041666666666667in"}

**Try it: Use Section4\_2\_Data.sav. Investigate the correlation between
the individual behavior intention scales. Select "Analyze" "Correlate"
"Bivariate". Select "BIndBehInt\_Pre" and "BIndBehInt\_Post". Select
"OK".**

![](./media/image72.png){width="4.895833333333333in"
height="4.270833333333333in"}

+-----------------+-----------------+-----------------+-----------------+
| > **Correlation |
| s**             |
+-----------------+-----------------+-----------------+-----------------+
|                 | > Individual    | > Individual    |
|                 | > behavior      | > behavior      |
|                 | > intention     | > intention     |
|                 | > scale before  | > scale after   |
|                 | > intervention  | > intervention  |
+-----------------+-----------------+-----------------+-----------------+
| > Individual    | > Pearson       | > 1             | > .701^\*\*^    |
| > behavior      | > Correlation   |                 |                 |
| > intention     |                 |                 |                 |
| > scale before  |                 |                 |                 |
| > intervention  |                 |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | > Sig.          |                 | > .000          |
|                 | > (2-tailed)    |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | > N             | > 59            | > 59            |
+-----------------+-----------------+-----------------+-----------------+
| > Individual    | > Pearson       | > .701^\*\*^    | > 1             |
| > behavior      | > Correlation   |                 |                 |
| > intention     |                 |                 |                 |
| > scale after   |                 |                 |                 |
| > intervention  |                 |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | > Sig.          | > .000          |                 |
|                 | > (2-tailed)    |                 |                 |
+-----------------+-----------------+-----------------+-----------------+
|                 | > N             | > 59            | > 59            |
+-----------------+-----------------+-----------------+-----------------+
| > \*\*.         |
| > Correlation   |
| > is            |
| > significant   |
| > at the 0.01   |
| > level         |
| > (2-tailed).   |
+-----------------+-----------------+-----------------+-----------------+
|                 |
+-----------------+-----------------+-----------------+-----------------+

The table indicates that there is a significant correlation between the
pre intervention and post intervention behavior scale scores. Our
p-value (Sig (2-tailed)) is less than our predetermined 0.05 level of
significance, so we reject the null hypothesis that there is not an
association between these two variables. The correlation coefficient is
positive, indicating that high scores for one variable correspond to
high scores for the other variable. Conversely, low scores for one
variable correspond to low scores for the other variable. Individuals
who scored high on the pre-test also tended to score high on the post
test.

To visually investigate this relationship, use a scatterplot:

Select "Graphs" "Legacy Dialogs" "Scatter/Dot".

Select "Simple Scatter" "Define".

Select "BIndBehInt\_Post" for the Y Axis.

Select "BIndBehInt\_Pre" for the X Axis.

Select "OK".

![](./media/image73.png){width="4.30625in" height="4.572916666666667in"}

![](./media/image74.png){width="6.5in" height="5.197916666666667in"}

The scatterplot indicates a linear relationship between the two
variables.

### Pearson Chi-Square Crosstabs and Test of Independence

The Chi-square test is very common way to explore the relationship
between two categorical variables. This tests the null hypothesis that
there is no relationship between the two variables, and rejecting the
null hypothesis allows us to conclude that the variables have a
statistically significant relationship with each other.

Suppose that we're interested in determining if there is a significant
relationship between smoking status and lung cancer status. Our
variables are:

1\) Smoking Status (1=Yes, 0=No) , and

2\) Lung Cancer Status (1=Diagnosed, 2=Not Diagnosed).

We can summarize these variables in a 2x2 table called a **crosstab**
where the cell values represent the counts in our data that fall in
those particular categories. We can perform a Chi-square test to
determine if there is a relationship between smoking and lung cancer.

Select "Analyze" "Descriptive Statistics" "Crosstabs" for the Chi-square
test of independence and make sure to check the box "Chi-Square" under
"Statistics". You can produce a clustered bar chart to visualize this
table by checking the box for "Display Clustered Bar Chart" in the
"Crosstab" dialog box.

![](./media/image76.png){width="5.046990376202975in"
height="4.510416666666667in"}

![](./media/image77.png){width="3.2414348206474193in"
height="3.7708333333333335in"}

**Try it: Use Section4\_2\_Data.sav. Are females more likely to
participate in jokes that are derogatory to any racial group?
Investigate the data to see what types of variables we have to answer
this question. We have the categorical variable "Sex" and the
categorical variable "Joke". Since we are comparing two categorical
variables, we will use a Chi-square test. Select "Analyze" "Descriptive
Statistics" "Crosstabs". Select "Sex" for rows, "Joke" for column, check
the box to "Display clustered bar charts". Select "Statistics" and check
the box for "Chi-Square". Select "Continue" and the select "OK".**

![](./media/image78.png){width="4.0in" height="3.7395833333333335in"}

![](./media/image79.png){width="2.6145833333333335in"
height="2.8777777777777778in"}

+-------------+-------------+-------------+-------------+-------------+
| > **Sex \*  |
| > Would you |
| > participa |
| te          |
| > in jokes  |
| > that are  |
| > derogator |
| y           |
| > to any    |
| > racial    |
| > group?    |
| > Crosstabu |
| lation**    |
+-------------+-------------+-------------+-------------+-------------+
| Count       |
+-------------+-------------+-------------+-------------+-------------+
|             | > Would you | > Total     |
|             | > participa |             |
|             | te          |             |
|             | > in jokes  |             |
|             | > that are  |             |
|             | > derogator |             |
|             | y           |             |
|             | > to any    |             |
|             | > racial    |             |
|             | > group?    |             |
+-------------+-------------+-------------+-------------+-------------+
|             | > No        | > Yes       |             |
+-------------+-------------+-------------+-------------+-------------+
| > Sex       | > Male      | > 7         | > 7         | > 14        |
+-------------+-------------+-------------+-------------+-------------+
|             | > Female    | > 27        | > 16        | > 43        |
+-------------+-------------+-------------+-------------+-------------+
| > Total     | > 34        | > 23        | > 57        |
+-------------+-------------+-------------+-------------+-------------+

+-----------+-----------+-----------+-----------+-----------+-----------+
| > **Chi-S |
| quare     |
| > Tests** |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Value   | > df      | > Asympto | > Exact   | > Exact   |
|           |           |           | tic       | > Sig.    | > Sig.    |
|           |           |           | > Signifi | > (2-side | > (1-side |
|           |           |           | cance     | d)        | d)        |
|           |           |           | > (2-side |           |           |
|           |           |           | d)        |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Pearson | > .718^a^ | > 1       | > .397    |           |           |
| > Chi-Squ |           |           |           |           |           |
| are       |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Continu | > .285    | > 1       | > .594    |           |           |
| ity       |           |           |           |           |           |
| > Correct |           |           |           |           |           |
| ion^b^    |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Likelih | > .709    | > 1       | > .400    |           |           |
| ood       |           |           |           |           |           |
| > Ratio   |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Fisher\ |           |           |           | > .532    | > .295    |
| 's        |           |           |           |           |           |
| > Exact   |           |           |           |           |           |
| > Test    |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Linear- | > .705    | > 1       | > .401    |           |           |
| by-Linear |           |           |           |           |           |
| > Associa |           |           |           |           |           |
| tion      |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > N of    | > 57      |           |           |           |           |
| > Valid   |           |           |           |           |           |
| > Cases   |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > a\. 0   |
| > cells   |
| > (0.0%)  |
| > have    |
| > expecte |
| d         |
| > count   |
| > less    |
| > than 5. |
| > The     |
| > minimum |
| > expecte |
| d         |
| > count   |
| > is      |
| > 5.65.   |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > b.      |
| > Compute |
| d         |
| > only    |
| > for a   |
| > 2x2     |
| > table   |
+-----------+-----------+-----------+-----------+-----------+-----------+

![](./media/image80.png){width="4.40625in" height="2.75in"}

The results above indicate that there is not a significant difference
between how females and males answered the question "Would you
participate in jokes that are derogatory to any racial group?"
(p-value=0.397).

***Two-Sample T-Test and One-Way ANOVA***

The purpose of the two-sample t-test, also known as the independent
samples t-test, is to determine if mean values of a particular
continuous variable are significantly different for two groups. The
one-way analysis of variance (ANOVA) is mathematically equivalent to the
two-sample t-test, and is appropriate when there are two or more groups.

There are 3 assumptions that must be met in order to perform these
tests:

1)  Normality of sample means within groups for the two-sample t-test,
    and normality of the underlying variable within groups for ANOVA.

2)  Homogeneity of variance for ANOVA

3)  Independence of groups and observations

You can investigate normality with Q-Q plots or histograms and use
Levene's test to assess homogeneity of variance. You can also
side-by-side box plots to investigate the relationship between a
continuous dependent variable and a categorical predictor.

In SPSS, select "Analyze" "Compare Means" to find the two-sample t-test
and one-way ANOVA

![](./media/image81.png){width="4.229166666666667in"
height="2.3645833333333335in"}

![](./media/image82.png){width="4.90625in"
height="2.7916666666666665in"}

For the side-by-side box plots, select "Graphs" "Legacy Dialogs"
"Boxplot" "Simple" "Summaries for groups of cases" "Define" "Variable":
Continuous dependent variable, "Category Axis": Categorical predictor
"OK"

![](./media/image83.png){width="2.0104166666666665in"
height="2.2916666666666665in"}![](./media/image84.png){width="4.114583333333333in"
height="3.5833333333333335in"}

**Try it: Use Section4\_2\_Data.sav. Is there a relationship between sex
and the post intervention intension scale score? Sex is a categorical
variable, the intension scale is continuous. We can use either an
independent samples t-test or one-way ANOVA. Select "Analyze" "Compare
Means" "Independent Samples T Test". Select "BIndBehInt\_Post" for Test
Variable(s). Select "Sex" for Grouping Variable. Select "Define
Groups..." and let group 1=1, group 2=2. Select "Continue". Select
"OK".**

![](./media/image85.png){width="4.895833333333333in"
height="3.0416666666666665in"}

![](./media/image86.png){width="2.4791666666666665in"
height="2.0416666666666665in"}

+-----------+-----------+-----------+-----------+-----------+-----------+
| > **Group |
| > Statist |
| ics**     |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Sex     | > N       | > Mean    | > Std.    | > Std.    |
|           |           |           |           | > Deviati | > Error   |
|           |           |           |           | on        | > Mean    |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Individ | > Male    | > 14      | > 5.3036  | > 1.66855 | > .44594  |
| ual       |           |           |           |           |           |
| > behavio |           |           |           |           |           |
| r         |           |           |           |           |           |
| > intenti |           |           |           |           |           |
| on        |           |           |           |           |           |
| > scale   |           |           |           |           |           |
| > after   |           |           |           |           |           |
| > interve |           |           |           |           |           |
| ntion     |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Female  | > 43      | > 5.5940  | > 2.03090 | > .30971  |
+-----------+-----------+-----------+-----------+-----------+-----------+

                                                           Levene\'s Test for Equality of Variances   t-test for Equality of Means
  -------------------------------------------------------- ------------------------------------------ ------------------------------ ------- -------- ----------------- ----------------- ----------------------- ------------------------------------------- ---------- ---------
                                                           F                                          Sig.                           t       df       Sig. (2-tailed)   Mean Difference   Std. Error Difference   95% Confidence Interval of the Difference
                                                                                                                                                                                                                  Lower                                       Upper
  Individual behavior intention scale after intervention   Equal variances assumed                    0.695                          0.408   -0.484   55                0.631             -0.29038                0.60044                                     -1.49370   0.91293
                                                           Equal variances not assumed                                                       -0.535   26.647            0.597             -0.29038                0.54294                                     -1.40509   0.82433

The tables above indicate that the males and females have similar
average intension scale scores (males=5.3, females=5.59). We fail to
reject the null hypothesis for Levene's test, so we will report the
information for "Equal variances assumed". Our p-value is .631, so we
fail to reject the null hypothesis that males and females have similar
average intention scale scores.

Select "Analyze" "Compare Means" "One-Way ANOVA". Select
"BIndBehInt\_Post" for the dependent list. Select "Sex" for the factor.
Select "OK"

![](./media/image87.png){width="3.6875in" height="1.75in"}

+-----------+-----------+-----------+-----------+-----------+-----------+
| > **ANOVA |
| **        |
+-----------+-----------+-----------+-----------+-----------+-----------+
| Individua |
| l         |
| behavior  |
| intention |
| scale     |
| after     |
| intervent |
| ion       |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Sum of  | > df      | > Mean    | > F       | > Sig.    |
|           | > Squares |           | > Square  |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Between | > .891    | > 1       | > .891    | > .234    | > .631    |
| > Groups  |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Within  | > 209.424 | > 55      | > 3.808   |           |           |
| > Groups  |           |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Total   | > 210.315 | > 56      |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+

The ANOVA table above yields the same p-value and conclusion as using
the two-sample t-test.

Select "Graphs" "Legacy Dialogs" "Boxplot". Select "Simple" "Summaries
for groups of cases" "Define". Select the continuous dependent variable
for "Variable", Categorical predictor for "Category Axis". Select "OK".

![](./media/image88.png){width="3.2604166666666665in"
height="2.1979166666666665in"}

![](./media/image89.png){width="5.5625in" height="4.083333333333333in"}

***Paired T-Test***

A paired t-test, also known as a repeated measures t-test or dependent
samples t-test, is appropriate when there are two related observations
(variables) and we want to determine if the average values of these
variables differ from one another. The purpose of the paired t-test is
to test the same units of observation under different treatment
conditions to see if a treatment effect exists. The test compares the
pre-treatment value to the post-treatment value for each case.

The null hypothesis is that the mean value of the differences for these
two related

variables is 0. If we reject this hypothesis, then we conclude that the
difference is

significantly different from 0. This test assumes that the sample mean
of the differences

is normally distributed. The test only considers cases with both
pre-treatment and

post-treatment values.

In SPSS, select "Analyze" "Compare Means" "Paired Samples T-Test".

![](./media/image90.png){width="6.05625in"
height="3.3645833333333335in"}

**Try it: Use Section4\_2\_Data.sav. Investigate whether or not the
average intention scores are statistically different from each other.
Since these variables are pre and post variables, it would be
interesting to see if the intervention was successful in increasing the
scores of participants. To investigate this, we will use a paired
t-test. Select "Analyze" "Compare Means" "Paired Samples T-Test". Select
"BIndBehInt\_Pre" for Variable 1. Select "BIndBehInt\_Post" for Variable
2. Select "OK".**

![](./media/image91.png){width="6.18125in"
height="3.3645833333333335in"}

+-----------+-----------+-----------+-----------+-----------+-----------+
| > **Paire |
| d         |
| > Samples |
| > Statist |
| ics**     |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Mean    | > N       | > Std.    | > Std.    |
|           |           |           | > Deviati | > Error   |
|           |           |           | on        | > Mean    |
+-----------+-----------+-----------+-----------+-----------+-----------+
| > Pair 1  | > Individ | > 3.7034  | > 59      | > 2.61758 | > .34078  |
|           | ual       |           |           |           |           |
|           | > behavio |           |           |           |           |
|           | r         |           |           |           |           |
|           | > intenti |           |           |           |           |
|           | on        |           |           |           |           |
|           | > scale   |           |           |           |           |
|           | > before  |           |           |           |           |
|           | > interve |           |           |           |           |
|           | ntion     |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+
|           | > Individ | > 5.6507  | > 59      | > 2.02827 | > .26406  |
|           | ual       |           |           |           |           |
|           | > behavio |           |           |           |           |
|           | r         |           |           |           |           |
|           | > intenti |           |           |           |           |
|           | on        |           |           |           |           |
|           | > scale   |           |           |           |           |
|           | > after   |           |           |           |           |
|           | > interve |           |           |           |           |
|           | ntion     |           |           |           |           |
+-----------+-----------+-----------+-----------+-----------+-----------+

+-------------+-------------+-------------+-------------+-------------+
| > **Paired  |
| > Samples   |
| > Correlati |
| ons**       |
+-------------+-------------+-------------+-------------+-------------+
|             | > N         | > Correlati | > Sig.      |
|             |             | on          |             |
+-------------+-------------+-------------+-------------+-------------+
| > Pair 1    | > Individua | > 59        | > .701      | > .000      |
|             | l           |             |             |             |
|             | > behavior  |             |             |             |
|             | > intention |             |             |             |
|             | > scale     |             |             |             |
|             | > before    |             |             |             |
|             | > intervent |             |             |             |
|             | ion         |             |             |             |
|             | > &         |             |             |             |
|             | > Individua |             |             |             |
|             | l           |             |             |             |
|             | > behavior  |             |             |             |
|             | > intention |             |             |             |
|             | > scale     |             |             |             |
|             | > after     |             |             |             |
|             | > intervent |             |             |             |
|             | ion         |             |             |             |
+-------------+-------------+-------------+-------------+-------------+

  **Paired Samples Test**
  ------------------------- ------------------------------------------------------------------------------------------------------------------ ---------------- ----------------- ------------------------------------------- ---------- ---------- -------- ---- -------
                            Paired Differences                                                                                                 t                df                Sig. (2-tailed)
                            Mean                                                                                                               Std. Deviation   Std. Error Mean   95% Confidence Interval of the Difference
                                                                                                                                                                                  Lower                                       Upper
  Pair 1                    Individual behavior intention scale before intervention - Individual behavior intention scale after intervention   -1.94729         1.87705           0.24437                                     -2.43645   -1.45813   -7.969   58   0.000

The tables above indicate that there is a significant increase in
average behavior intention score after the intervention (p-value\<.001).

Investigating Many Variables at a Time
--------------------------------------

It is often useful to investigate the relationship between one outcome
variable and multiple predictor variables. The type of the outcome
variable determines the appropriate model; general linear models are
appropriate for continuous outcomes and generalized linear models are
appropriate for categorical outcomes. General linear models include
simple linear regression and multiple linear regression while
generalized linear models include binary logistic regression and ordinal
logistic regression. Linear regression and binary linear regression will
be covered through **EXERCISES** in this workshop, time permitting.

Repeated Measures, Longitudinal, Clustered, Multilevel, Mixed Procedures
------------------------------------------------------------------------

It is very common in many studies to take multiple measurements on a
unit of analysis, typically a subject. These multiple measures may be
occurring over time, conditions, regions, or the levels of any other
variable. Depending on what the measurements are taking place over,
there are many names we give these studies. It is also very common in
many studies to have the units of analysis be clustered (i.e. grouped)
into higher level clusters (i.e. groups). Sometimes the clusters
themselves are further clustered into even higher level clusters, and so
on.

In all of these studies, we must use more advanced statistical
procedures that take into consideration the possible correlation of
observations that are coming from the same unit of analysis. While using
advanced procedures to analyze such data sets is beyond the scope of
this workshop, you should be able to identify these multilevel data sets
and discuss them with your statistician.

Other Procedures in SPSS
------------------------

Here is a non-exhaustive list of other procedures in SPSS that you may
use:

Tests for checking the assumptions of normality

Intraclass correlation coefficient

Partial correlations\
General linear models\
Generalized linear models

Categorical data analysis

Randomized clinical trials

Case-control clinical trials

Matching and propensity scores\
Survival analysis\
Cox regression

Two-stage least squares regression

Probit regression\
Cluster analysis\
Discriminant analysis

Factor analysis\
Principal components analysis\
Reliability analysis\
Path analysis\
Structural equations modeling\
Latent class analysis

Multidimensional ccaling\
Spatial statistics\
Time series analysis\
Complex samples and survey methodology\
Missing data analysis and imputation\
Geographical information systems\
Qualitative data analysis\
Text mining

Receiver operator characteristic (ROC) curve analysis\
Functional data analysis\
Data mining

Classification and regression trees (CART)

Chi-square automatic interaction detection (CHAID)

Neural networks

Miscellaneous
-------------

### Descriptive Statistics

"Analyze" "Descriptive Statistics" "Descriptives"

### Frequencies

"Analyze" "Descriptive Statistics" "Frequencies"

### Rank Cases

"Transform" "Rank Cases" "Rank Types"

### T-Tests & One-Way ANOVA

"Analyze" "Compare Means"

### Chi-Square Test

"Analyze" "Descriptive Statistics" "Crosstabs" Check the Chi-square box
under "Statistics"

### Create a Code Book

"File" "Display Data File Information" "Working File"

Check output

Can export or copy/paste into Word or Excel

### Adjust Options

"Edit" "Options"

You can select to display variable labels or variable names in dialog
boxes

You can change what Output looks like (labels, no labels)

Many other options

### Recall Recently Used Dialogs Button

Will open recently used dialog boxes (chi-square cross tabs,
frequencies, etc.)

Button is forth from the left at the top of the Data View screen

### Jump to a Case

"Edit" "Go to Case"

Can type in or select

### Jump to a Variable

"Edit" "Go to Variable"

Can select the variable from the drop down menu or start typing it

### Spell Check

In Variable View and Data View, upper right corner

Will be grayed out in Data View if you do not have string variables

### Sort Variable

In Data View, right click the variable you would like to sort by

Select "Sort Ascending" or "Sort Descending"

### View Value Labels in Data View

"View" "Check the box for Value Labels"

Check data in Data View

### Weights in Crosstabs

If you don't have raw data (only cell counts) you can still do a
chi-square crosstabs in SPSS

Open a blank SPSS data file

The first variable will serve as the "weights" variable

The next two variables represent rows and columns

Data Weight Cases Weight Cases by Var0001 OK

Analyze Descriptive Statistics Crosstabs

Enter in Var0002 for rows and Var0003 for columns OK

EXAMPLE:

> ***Given a Table of Counts:***
>
> *Yes No*
>
> *Yes 35 90*
>
> *No 50 100*
>
> ***SPSS Data:***
>
> *Var0001 Var0002 Var0003*
>
> *90.00 1.00 .0*
>
> *50.00 .0 1.00*
>
> *35.00 1.00 1.00*

100. *.0 .0*

### Useful websites

Statnotes: http://faculty.chass.ncsu.edu/garson/PA765/statnote.htm

http://www.ats.ucla.edu/stat/SPSS/

Interpreting Interactions in a Regression Model Overview
========================================================

Two-Way Interactions
--------------------

### General

Let our regression model follow this form:

Y=A+B+A\*B

Where Y represents our dependent/outcome variable and A\*B represents
the interaction between A and B.

-   The regression coefficient for A shows the effect of A when B=0.

-   The regression coefficient for B shows the effect of B when A=0.

-   The regression coefficient for A\*B demonstrates how A changes with
    a one unit increase in B. It also demonstrates how B changes with a
    one unit increase in A.

### Two Categorical Variables

-   Let A represent gender

    -   0=Female

    -   1=Male

-   Let B represent treatment condition

    -   0=Control

    -   1=Experimental

-   The interaction regression coefficient shows whether the effect of
    treatment condition is different for males and females.

-   The regression coefficient for A shows the difference in Y between
    males and females for the 'control' treatment group.

-   The regression coefficient for B shows the difference in Y between
    treatment and control groups for females.

### One Categorical and One Continuous Variable

-   Let A represent gender

    -   0=Female

    -   1=Male

-   Let B represent a continuous variable: age in years.

-   The interaction regression coefficient shows if the effect of age on
    Y is different for males and females.

-   The regression coefficient for A shows the difference between males
    and females when age is equal to zero.

-   The regression coefficient for B shows the effect of age for
    females.

### Two Continuous Variables

-   Let A represent a continuous variable: IQ score.

-   Let B represent a continuous variable: Age.

-   The interaction regression coefficient shows

    -   if the relationship between age and Y differs according to IQ

    -   if the relationship between IQ and Y differs according to age.

-   The regression coefficient for A shows the relationship between IQ
    and Y when age equals zero.

-   The regression coefficient for B shows the relationship between age
    and Y when IQ equals zero.

Three-Way Interactions
----------------------

The same principles apply from above. The general model:

Y=A+B+C+A\*B+A\*C+B\*C+A\*B\*C

-   The coefficient for A shows the effect of A on Y when both B and C
    are zero.

-   The coefficient for B shows the effect of B on Y when both A and C
    are zero.

-   The coefficient for C shows the effect of C on Y when both A and B
    are zero.

-   The coefficient for A\*B shows the interaction between A and B when
    C is zero.

-   The coefficient for A\*C shows the interaction between A and C when
    B is zero.

-   The coefficient for B\*C shows the interaction between B and C when
    A is zero.

-   The interaction regression coefficient shows if the relationship
    between

    -   A and Y differs according to B and C

    -   B and Y differs according to A and C

    -   C and Y differs according to A and B.
