[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to SPSS",
    "section": "",
    "text": "Overview of the Workshop\nThere are four sections to this workshop:\nThese sections will generally be presented in sequence. The discussion will alternate between theory and practice. The format will alternate between lecture and lab sessions. Please ask questions as soon as they arise in your mind. Please provide feedback or voice concerns.\nThere is additionally an Appendix which primarily houses the exercise solutions, as well as a collection of additional, more advanced, exercises."
  },
  {
    "objectID": "index.html#contact-information",
    "href": "index.html#contact-information",
    "title": "Introduction to SPSS",
    "section": "Contact information",
    "text": "Contact information\n\nCSCAR\n\nOffice Hours: Monday-Friday 9am to 5pm (Closed Tuesday 12-1pm)\nPhone: 734.764.7828\nStatistical Assistance: stats-consulting@umich.edu\nData Science Assistance: ds-consulting@umich.edu\nHigh Performance Computing: hpc-consulting@umich.edu\nhttp://cscar.research.umich.edu/"
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Introduction to SPSS",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThese notes have evolved over the years thanks to many CSCAR statisticians, including Corey Powell, Josh Errickson, Giselle Kolenic, and Missy Plegue.\nThis material was created for use in workshops and short courses presented by faculty and staff from the Consulting for Statistics, Computing & Analytics Research (CSCAR) at the University of Michigan. No part of this material may be used for other purposes, copied, changed, or sold."
  },
  {
    "objectID": "index.html#images",
    "href": "index.html#images",
    "title": "Introduction to SPSS",
    "section": "Images",
    "text": "Images\nAll images embedded within the document should link to a full-size version of the image."
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "Introduction to SPSS",
    "section": "Data",
    "text": "Data\nThere are a number of data sets used in these notes; some used for the examples, others for the execises.\ndata.zip - This zip files contains all data used within the notes.\n\nExample Data\n\nSection 2: section2_data.sav\nSection 3: section3_data.sav\nSection 4: section4_1_data.sav, section4_2_data.sav\n\n\n\nExercise Data\n\nExercise 0: exercise0_data.sav, exercise0_output.spv, exercise0_syntax.sps (You may need to right-click & Save As for the .sps file)\nExercise 1: exercise1_data.sav\nExercise 2: exercise2_data.xls\nExercise 3: exercise3_data.sav\nExercise 4: exercise4_data.sav\nExercise 5: exercise5_data.sav\nExercise 6: exercise6_data.sav\nExercise 7: exercise7_data.sav\nExercise 8: exercise8_data.sav\n\n\n\nAdditional Exercises\nThese are for the additional exercises and final project found in the appendix.\n\nExercise A1: exercisea1_data.sav\nExercise A2: exercisea2_data.sav\nExercise A3: exercisea3_data_a.sav, exercisea3_data_b.sav\nExercise A4: exercisea4_data.sav\nExercise A5: exercisea5_data.sav\nFinal Project: cars_wave1.xls, cars_wave2.xls"
  },
  {
    "objectID": "01-basics.html#what-does-spss-stand-for",
    "href": "01-basics.html#what-does-spss-stand-for",
    "title": "1  The Basics of SPSS",
    "section": "1.1 What does SPSS Stand For?",
    "text": "1.1 What does SPSS Stand For?\n\nOriginally, SPSS stood for Statistical Package for the Social Sciences.\nNow, it stands for Statistical Product and Service Solutions.\nSPSS has also been known as “PASW” which stands for Predictive Analytics Software."
  },
  {
    "objectID": "01-basics.html#spss-compared-to-other-statistical-software-packages",
    "href": "01-basics.html#spss-compared-to-other-statistical-software-packages",
    "title": "1  The Basics of SPSS",
    "section": "1.2 SPSS Compared to Other Statistical Software Packages",
    "text": "1.2 SPSS Compared to Other Statistical Software Packages\nWe can think of statistical software packages on a spectrum organized by difficulty and complexity. On one end we have Excel which is easy and familiar to most people. On the other end we have C++ which is difficult and unfamiliar. All software packages are somewhere in between. SPSS is closer to the Excel end of the spectrum which makes it convenient to use. SPSS builds on what you already know from Excel, which makes the transition from Excel to a more powerful statistical software package easier.\nEasiest: Excel\nSPSS\nMinitab\nJMP\nStata,SAS\nR/S-Plus\nMatlab\nHardest: C++\nSPSS requires that data, code, and output are in separate places, unlike Excel. These differences seem big at first, but they are a small price to pay for the additional data management, graphical, and statistical capabilities that SPSS will give you over Excel. While SPSS seems to be more restrictive than Excel, the restrictions it sets ensure that your data set is ready for statistical analysis."
  },
  {
    "objectID": "01-basics.html#the-three-parts-of-spss",
    "href": "01-basics.html#the-three-parts-of-spss",
    "title": "1  The Basics of SPSS",
    "section": "1.3 The Three Parts of SPSS",
    "text": "1.3 The Three Parts of SPSS\nThere are three parts to SPSS, each with its own window: Data Editor, Output Viewer, and Syntax Window. The sections below describe each of these parts in detail.\n\nData Editor Enter and View Data Values, files end in .sav or.por\nOutput Viewer View Statistical Results, files end in .spv\nSyntax Window Write & Run Syntax Command, files end in .sps\n\n\n1.3.1 Data Editor\nThe Data Editor is visible when SPSS starts up. There are two views of the Data Editor: Data View and Variable View. In Data View, each row represents one case (e.g., one survey respondent), while each column represents one variable (one piece of information, e.g. age). By using the scroll bars to go up and down, you can examine any case in the sample. By using the scroll bars to go right and left, you can see any variable.\nThe first step in an SPSS session is to open a data file or start entering data in a new data file. A data file is a binary file ending in the extension .sav or .por, which contains a given data set. Any requested statistics or analyses that are performed pertain to this data set.\n\n1.3.1.1 Open a Data File\nTo open a data file, go to “File” at the upper left of the menu bar. Click “Open” then “Data”. Locate the file that you want to open and double-click on it.\nTry it: Open exercise0_data.sav\n\n\n\n\n\n\n\n\n\n\nStart a New Data File\nTo start a new data file, go to “File” at the upper left of the menu bar. Click “New” then “Data”.\n\n\n\n1.3.2 Output Viewer\nThe output viewer is a window where any statistical results, including tables or graphs, can be viewed. The output window does not appear until the first time SPSS is asked to provide some sort of results. The output viewer will also record the syntax used to generate the results.\nTry it: Open exercise0_output.spv\n\n\n\n\n\nThe output viewer is divided into two parts: on the left, a narrow window shows an outline which organizes all the results. The outline can be used to delete certain portions of the output, rearrange pieces of the output, jump to specific results, and temporarily hide (or make visible) certain parts of the output. More on this later.\nThe actual results themselves are in the larger window to the right. When printing the output, only the information in this window is printed. Once the viewer has been opened, it will remain open even if all the output is deleted and the output window is empty.\nOccasionally the results from a procedure will be quite lengthy, and only the first portion will appear in the window. In these cases, a small red triangle pointing down will appear at the bottom of this visible portion. To see those results in their entirety, double-click on that section of output. Scroll bars will appear which pertain to that piece of output; scroll down to see the remainder.\n\n1.3.2.1 Labels in Output\nVariable labels and value labels will be used in place of the actual variable names or values, by default. This can be changed under the Edit -&gt; Options -&gt; Output tab. SPSS can display labels only, the actual names or values only, or both.\n\n\n1.3.2.2 Tables & Charts\nResults are commonly presented in the output viewer in table form or chart (graph) form. To edit a table, double-click on that table (anywhere will do). An editing window is set up around that table, indicated by a rough gray outline. New menus appear in the menu bar at the top. Once this editing mode is begun, double-clicking in any cell in a table will allow you to change the names, labels, or values in those cells.\nHelpful Hint: To remove scientific notation in a table, double-click on the table and highlight the columns or rows containing the notation. Under Format -&gt; Cell Properties and select a new numeric format, such as #,###.##. The number of decimal places can be increased or decreased here as well.\nEditing a chart is similar to editing a table. Begin by double-clicking anywhere on the chart and the Chart Editor window will appear. Once in the Chart Editor, many things can be altered simply by double-clicking and changing fields in the dialogue boxes which appear.\nTry it: Double click on the Descriptive Statistics table for the salary variable. Change the Std. Deviation to have only two digits to the right of the decimal point.\n\n\n\n\n\n\n\n1.3.2.3 Export Output\nYou can save the output file for future use or to send to colleagues. In order to open a SPSS output file, your computer must have SPSS. Sometimes it is useful to export the information from your output file into another format, such as Microsoft Excel or Microsoft Word. Excel is a great platform to export to—tables turn out very nicely. To export, select File -&gt; Export and the export wizard will appear. Select the file type and the location to save the file, then select “OK”.\nTry it: Export the output table as an Excel file and investigate the Excel file.\n\n\n\n\n\nStarting with SPSS Version 11.5, selected output objects, such as charts and tables, can also be exported in an Excel or Word format. This is a very useful feature that can be used to export selected tables from the Output Viewer into an Excel format, for additional work such as creation of custom graphs. To export charts, select the charts in the output window by clicking once on them, and then go to File -&gt; Export and select “Selected” where it asks what objects to export. Choose the “html” file type for charts, and under the Graphics portion of the dialogue box a drop down menu allows one to access the various types of image files available. The bitmap image format is one option. Although these images are somewhat large in terms of kilobytes, they can be read by a great many programs, including Word, Power Point and others.\nOne last option for exporting SPSS output is to copy and paste all output into a Word file. The steps are as follows:\n\nClick once to select the piece(s) of output to move.\nGo to Edit -&gt; Copy, press the short-cut ctrl-C, or right-click and select “Copy”).\nIn Word, place the cursor where the output will go.\nUnder “Edit”, click “Paste”, or use the short-cut ctrl-V.\n\nYou can then resize and move around the pasted objects in Word. The same process outlined above should work for other Microsoft programs, such as Power Point or Excel. While pasted objects can be edited in theory, this is usually difficult. It is best to do all editing in SPSS before pasting to Word.\n\n\n\n1.3.3 Syntax Window\nThe Syntax Window looks like the Output Viewer, but it is a text editing window in which SPSS commands can be written out by hand. It allows users to type commands in the right-hand side window rather than use menus. Commands executed using written code are no different from commands executed using the pull-down menus and dialogue boxes. There are some rare instances when something is available only by writing syntax, and cannot be found in any menu.\nThe syntax window provides these advantages:\n\nIt allows a user to do repetitive tasks more quickly, using copy & paste.\nIt provides a written record of data management and analyses performed.\nIt can be sent to other SPSS users to help in setting up data files or to re-create your analyses.\n\nTry it: Open exercise0_syntax.sps (Right-click & Save-as)\n\n\n\n\n\nYou can generate syntax in a few different ways:\n\nWrite out the syntax by hand.\nUse the “Paste” button inside a dialogue box.\nCopy and paste the syntax from the output viewer.\n\nThe “Paste” button in dialogue boxes causes the written syntax equivalent of a command to be entered into the syntax window. A new syntax window will open if no syntax window was open previously.\n\n1.3.3.1 Run Syntax\nTo run commands in the syntax window, highlight the commands of interest and go to Run -&gt; Selection. Alternatively, you can click on the toolbar button that looks like a “Play” symbol on a CD player or press ctrl-R as a short-cut. You can also run all commands in the syntax window by using Run -&gt; All.\nTry it: In the Syntax Window, highlight number 3 and run the selection highlighted below. Check the Output Viewer.\n\n\n\n\n\nRepetitive Commands\nAs a simple example of repetitive commands, consider a user who needs to take logs of thirty different variables. To go through the menus and do thirty computations would be quite time-consuming. This is a case where using syntax would be easier, because cut, copy, and paste commands are available in the Syntax Window. If you pasted one such computation command to the syntax window, you could then copy the command out thirty times. You would only need to edit the variable names in each line.\nThe steps for using syntax for repetitive commands are:\n\nPaste one example command into the syntax window.\nCopy this command by highlighting it and typing ctrl-C or by right clicking and copying.\nPaste the command repeatedly using ctrl-V or right clicking and pasting.\nEdit each line by changing the variable names.\nRun the commands!\n\nOnce again, the cut, copy, and paste commands have these short-cuts:\n\nCut ctrl-X\nCopy ctrl-C\nPaste ctrl-V\n\nHelpful Hint: If you want to start setting up a data set, by formatting variables, recoding, etc., you can begin before you receive all the data. Test your data management commands on the cases you do have, and save the syntax file. When you receive the final data delivery, you can re-run the syntax one last time and be ready to go!\nTry it: Highlight Number 5, copy and paste the syntax. Modify the syntax such that VARIABLES=salbegin.\n\n\n\n\n\n\n\n1.3.3.2 Reading in Raw Data with Syntax\nReading in raw data files is another common use of the syntax window. Many organizations will provide large, publicly available data sets by distributing the raw data and a SPSS syntax file which reads in and formats that data. If you receive a raw data file and a SPSS syntax file, sometimes referred to as data definition statements, then follow these steps to get a copy of the data file in SPSS format:\n\nStart SPSS, but do not open any data file yet.\nOpen the syntax file containing the commands to read the data.\nAt the top of the syntax, find the “FILE HANDLE” statement. Change the path and the name of the file to match the current file location and name (the file should contain instructions as well).\nSelect Run -&gt; All .\n\n\n\n1.3.3.3 Syntax Examples\n1) Accessing an SPSS data file and rename the dataset\nGET FILE = 'C:\\\\SPSS\\\\data\\\\example.sav'.\nEXECUTE.\nDATASET NAME example.\n2) Entering new variables and data\nDATA LIST LIST / age (F2.0) sex (A1) income (F2.1) ethnic (F1.0).\nBEGIN DATA\n45 F 60.9 2\n52 M 22.3 1\n34 M 45.8 3\n67 F 34.5 1\nEND DATA.\n3) Creating new numeric or string variables\nNUMERIC ses (F1.0) / numkids yrsmarr (F2.0).\nSTRING state (A2) / region (A1) / citycode (A4).\n4) Labeling variables\nVARIABLE LABELS age \"Age\" sex \"Sex\" ethnic \"Ethnic category\".\n5) Labeling values of a variable\nVALUE LABELS sex 'M' \"Male\" 'F' \"Female\".\n6) Defining missing values\nMISSING VALUES sex ('X') ethnic (8,9) income (7777) age (0).\n7) Calculating a new variable using a function\nCOMPUTE log10inc = LG10(income).\nEXECUTE.\n8) Calculating a new variable using “if then” logic\nIF (sex='M' and age &gt;= 65) olderman=1.\nIF (sex='F' or age &lt; 65) olderman=0.\nEXECUTE.\nor:\nCOMPUTE olderman = (sex='M' and age &gt;= 65).\nEXECUTE.\n9) Recoding a variable\nRECODE ethnic (1=0) (2=1) (3=1).\nEXECUTE.\n10) Recoding into a new variable, keeping the original intact\nRECODE ethnic (1=0) (2=1) (3=1) INTO wh_nonwh.\nEXECUTE.\n\nRECODE income (LOWEST THRU 25 = 1) (26 THRU 44 = 2) (45 THRU HIGHEST=3)\nINTO incomcat.\nEXECUTE.\n11) Obtaining descriptive statistics for continuous variables\nDESCRIPTIVES VARIABLES=income age\n /STATISTICS=MEAN STDDEV VARIANCE MIN MAX SEMEAN.\n12) Getting frequencies for categorical variables\nFREQUENCIES VARIABLES=sex ethnic olderman.\n13) Obtaining a cross-tabulation between two categorical variables\nCROSSTABS\n /TABLES = jobcat BY gender\n /STATISTIC = CHISQ\n /CELLS = COUNT ROW COLUMN.\n14) Producing a histogram\nGRAPH\n /HISTOGRAM(NORMAL)=income\n /TITLE= 'Histogram of Income'.\n15) Creating side-by-side box-plots\nEXAMINE VARIABLES=income BY ethnic\n /PLOT=BOXPLOT\n /STATISTICS=NONE\n /NOTOTAL.\n16) Generating a scatter plot\nGRAPH\n /SCATTERPLOT(BIVAR)=age WITH income\n /MISSING=LISTWISE.\n17) Obtaining a line graph\nGRAPH\n /LINE(SIMPLE)=MEAN(income) BY ethnic.\n18) Getting a line graph with multiple lines (e.g. one for women, one for men)\nGRAPH\n /LINE(MULTIPLE)=MEAN(income) BY ethnic BY sex.\n19) Choosing a subset of the data to analyze or examine\nCOMPUTE filt_var=(gender='m').\nFILTER BY filt_var.\nEXECUTE.\n20) Returning to the entire sample after looking at a subset\nFILTER OFF.\nEXECUTE.\n21) Splitting the observations into strata, so that future analyses will be repeated for each stratum separately\nSORT CASES BY ethnic.\nSPLIT FILE BY ethnic.\n\n\n1.3.3.4 Writing Syntax Tips\n\nEach command must begin on a new line and must end with a period.\nA comment can be included in a syntax file. The comment starts with an asterisk (*) and can go beyond one line. A period (.) is required in the end of the last line to terminate the comment.\nSPSS syntax is case insensitive. Capitalized words are used to indicate keywords and command names in SPSS documentation, while lowercase letters indicate user-specified words; this is only a convention.\nString values must be enclosed in single or double quotes.\nCommands, sub-commands, and keywords can be abbreviated to three letters, but use four or five to avoid ambiguities.\nVariable names must always be typed out in full. Numbers and underscores are valid in a variable name if they are not the first letter.\nThe use of capitals will not distinguish two variable names; name and NAME are identical.\nSub-commands are preceded by a forward slash (/); they need not begin on a new line. However, lines of code can’t be more than 80 characters long.\nThe word EXECUTE and a period (.) should be included after each command, such as COMPUTE and RECODE, that requires changes to the data set. Adding in EXECUTE. will never hurt anything; if in doubt, include it.\nLabels and other items enclosed in quotes must not run onto the next line.\nThe word “then” never appears in “if then” types of commands."
  },
  {
    "objectID": "01-basics.html#good-to-know",
    "href": "01-basics.html#good-to-know",
    "title": "1  The Basics of SPSS",
    "section": "1.4 Good to Know",
    "text": "1.4 Good to Know\n\n1.4.1 Dialogue Boxes\nThe main way that a user tells SPSS what to do is through dialogue boxes. These are windows that pop up when you click on an item in a menu or double-click on particular objects.\nTry it: In Data View for exercise0_data.sav, select Analyze -&gt; Descriptive Statistics -&gt; Descriptives.\n\n\n\n\n\nWhile dialogue boxes vary according to the task involved, they all have at least some of the following buttons:\n\n“OK” Carries out the procedure; executes the command now.\n“Continue” Returns to the main dialogue box after specifying an option.\n“Paste” Writes out the syntax for the procedure in a syntax window.\n“Reset” Returns the dialogue box to its original blank state.\n“Cancel” Closes the dialogue box without taking any action.\n“Help” Opens up a help window specific to that procedure.\n\nIn most dialogue boxes, you select certain variables from the list on the left and move these variables into the active variable box on the right. Here are some tips:\n\nClick on any variable in the variable list, then type the first few letters of a variable name to zoom to that name in the list.\nHold down the Shift key and click on any two variables to select every variable in between.\nHold down the Control key and click to select multiple variables that are not necessarily adjacent in the list.\n\nYou could choose to display either variable labels or names in the variable list. For example, if you want the names to be displayed, go to then “Edit” menu and click “Options”. When a new window comes up, click on the tab labeled “General”. In the “Variable Lists” section, choose option “Display names” or “Display labels” for variable labels.\n\n\n1.4.2 Adding Comments\nYou can add descriptive comments to data files by going to Utilities -&gt; Data File Comments."
  },
  {
    "objectID": "01-basics.html#tips-for-preparing-an-excel-file-for-use-with-spss",
    "href": "01-basics.html#tips-for-preparing-an-excel-file-for-use-with-spss",
    "title": "1  The Basics of SPSS",
    "section": "1.5 Tips for Preparing an Excel File for Use with SPSS",
    "text": "1.5 Tips for Preparing an Excel File for Use with SPSS\n\nPlace the variable names in the first row. Be sure the names follow these rules:\n\nvariable names should be no more than 64 characters long (and no longer than 8 characters is usually recommended)\nvariable names must start with a letter\nvariable names may only have letters, numbers, or underscores in them\nthe following characters must not appear in variable names: %,$,#,@,!,+,*,~,\",-,.\nno blank spaces can appear in variable names\neach variable name must be unique, with no duplicate variable names\nvariable names can be on one row only\n\nOnly include the raw, un-summarized data. Delete extraneous data in your Excel file, like row or column totals, graphs, etc.\nInclude an identifying number for each case that is unique. If you have several spreadsheets for one person, include the identifier on each sheet.\nOnly include one value per cell. Don’t enter data such as “120/80” for blood pressure. Enter systolic blood pressure as one variable, and diastolic blood pressure as another variable.\nDon’t leave blank rows in the data.\nDon’t mix numeric and character values, such as names and ID numbers, in the same column.\nCharacter variables are allowed in statistical packages but are not as flexible as numeric variables. Use numeric values when feasible.\nIf you have missing values, you can indicate them with a numeric code, such as 99 or 999, or you can leave the cell blank. Be sure, if you use a missing value code, that it is not a plausible real data value.\nSave the spreadsheet with values only – not formulas.\n\nAn ideal Excel data set might look like this:"
  },
  {
    "objectID": "01-basics.html#exercise-1-properly-formatted-data",
    "href": "01-basics.html#exercise-1-properly-formatted-data",
    "title": "1  The Basics of SPSS",
    "section": "1.6 Exercise 1 – Properly Formatted Data",
    "text": "1.6 Exercise 1 – Properly Formatted Data\nIn order to analyze data properly in SPSS, we need to follow the guidelines set out in the course notes.\nOpen exercise1_data.sav and see what guidelines we have ignored."
  },
  {
    "objectID": "01-basics.html#importing-data-into-spss",
    "href": "01-basics.html#importing-data-into-spss",
    "title": "1  The Basics of SPSS",
    "section": "1.7 Importing Data into SPSS",
    "text": "1.7 Importing Data into SPSS\nSPSS can easily read in data from Excel, SAS or Stata, as well as several lesser used options.\nTo open a file from another program, go to File -&gt; Open. Under “File Type” find the program the data file was created in. Select this type and find the file you’d like to open. Click “Open”. It’s that easy – the data file should appear. If your data is not stored in a format that SPSS can read, then first convert the file to Excel format. Excel is a useful liaison between other programs and SPSS.\nTry it: Select File -&gt; Open. Investigate the different file types that you can open.\n\n\n\n\n\nData files that are in TEXT FORMAT (.txt) are either delimited or divided into columns of fixed length. SPSS provides a wizard that asks questions and makes intelligent guesses in order to import your text data. This facility is somewhat like Excel’s data-reading wizard.\nDelimited files have rows of values that are separated by tabs, commas, or spaces.\nThe first rows of data from a tab-delimited file might look like (where the first row identifies variable names, the second row is the first row of data):\nName Age Gender Occupation Yearly Salary\nJim 25 Male Accountant 65,000\nA row of data from a comma-delimited file might look like:\nName,Age,Gender,Occupation,Yearly,Salary\nJim,25,Male,Accountant,65,000\nRead delimited files into SPSS by going to File -&gt; Read Text Data. First, locate the name of the text file and click Open. Answer the questions as you go along, clicking Next to move on to the next question. Be sure to choose the Delimited file type, and identify the character (comma, space, tab, etc) that acts as the delimiter.\nSimilarly, read fixed-column data files by going to File -&gt; Read Text Data. Open the file containing the text data. Follow along with the questions, clicking Next to move along. Be sure to select the Fixed width option.\nYou may name the variables for either delimited or fixed width files during the import procedure, or after the data have already been read into the Data Editor. Sometimes the variable names are already in the top row of the text file. You will be able to tell SPSS whether these names are present or absent in the text file.\nNote that for fixed width data, particularly when many variables are involved, it may be easier to use syntax commands rather than the menus. This will provide a record of how the data were imported, and it will allow you to stop and resume the import process in a later SPSS session. When using the menus, there is no way to stop halfway through and save your work."
  },
  {
    "objectID": "01-basics.html#exporting-data-from-spss",
    "href": "01-basics.html#exporting-data-from-spss",
    "title": "1  The Basics of SPSS",
    "section": "1.8 Exporting Data from SPSS",
    "text": "1.8 Exporting Data from SPSS\nTo save files in a certain format so that you can move data from SPSS to another program (this is exporting from SPSS), make certain you are in the Data Editor window, and go to File -&gt; Save As and then select “File Type”. Be sure to give this new file a name.\nYou can export to most of the same file types as you can import.\nYou can also select a subset of variables to save in a new data file by selecting the “Variables…” button in the “Save Data As” window. Once you have selected the variables that you want for the new data file, select “Continue” then “Save”.\nTry it: Select File -&gt; Save As. Investigate the different file types. Select the “Variables” button and investigate."
  },
  {
    "objectID": "01-basics.html#exercise-2-importingexporting-excel",
    "href": "01-basics.html#exercise-2-importingexporting-excel",
    "title": "1  The Basics of SPSS",
    "section": "1.9 Exercise 2 – Importing/Exporting Excel",
    "text": "1.9 Exercise 2 – Importing/Exporting Excel\nOpen exercise2_data.xls (an Excel file). Modify this Excel file such that it can be imported into SPSS properly. Save the file and close it.\nOpen the file in SPSS (import it). Export this file back into Excel, but only save the following variables: id, salary, minority."
  },
  {
    "objectID": "01-basics.html#getting-help-from-spss",
    "href": "01-basics.html#getting-help-from-spss",
    "title": "1  The Basics of SPSS",
    "section": "1.10 Getting Help from SPSS",
    "text": "1.10 Getting Help from SPSS\nUnderneath the help menu are several different options. Here are a few:\n\n“Topics” Search for a word or command\n“Tutorial” Get an introduction to some SPSS basics\n“Case Studies” Look at some example analyses using SPSS\n“Statistics Coach” Get help in choosing the right statistical procedure\n“Syntax Reference” View syntax manuals in their complete form (.pdf)\n“SPSS Home Page” Open an internet browser and go to www.spss.com\n“About” View version number and license expiration date\n“Product Registration” Renew the license once it has expired\n\nWhen looking at a help entry for a statistical procedure, there will usually be a link labeled “Show Me”, which provides explicit instructions for carrying out the procedure via an example.\nThe “Command Syntax Reference” menu allows users to access the entire text that can be found in the hard-copy manuals. The on-line manuals open in Adobe Acrobat Reader and come with an index of topics. Click on any page number to go instantly to that page.\nHelpful Hint: when examining the on-line syntax guides, click the small button at the bottom marked “100%” and choose 150% or 200% for easier reading."
  },
  {
    "objectID": "02-variables.html#variable-view-in-data-editor",
    "href": "02-variables.html#variable-view-in-data-editor",
    "title": "2  Working with Variables",
    "section": "2.1 Variable View in Data Editor",
    "text": "2.1 Variable View in Data Editor\nVariables in SPSS vary in length and may consist of letters, numbers, dates, or dollar values. Some values, such as “don’t know” replies on a survey, may be codes for missing values. SPSS allows you to label variables and values with more meaningful phrases that can appear in the output for greater clarity.\nTo view or edit the current format for a variable, double-click on the variable’s name in the Data Editor. Doing this will open the Variable View tab in the Data Editor window. Alternatively, select the “Variable View” tab at the bottom left corner of the data editor window.\nTry it: Open section2_data.sav. Select “Variable View”.\n\n\n\n\n\nThere are eleven columns in the Variable View, containing values that are attributes for the variables that you can change:\n\nName The name of each variable in the data set\nType The type (numeric, character, date, etc) and length\nWidth The amount of information in bytes stored in memory\nDecimals The number of decimals displayed for numeric vars\nLabel A specific label for a variable\nValues Variable value labels\nMissing Missing value codes\nColumns Column width for variable display\nAlign The alignment of values within a cell\nMeasure The measurement scale for a variable\nInput The role of the variable when analyzing the data\n\n\n2.1.1 Variable Name\nBe sure the names follow these rules:\n\nVariable names should be no more than 64 characters long, and preferably no more than 8 characters long.\nVariable names must start with a letter.\nVariable names may only have letters, numbers, or underscores in them.\nVariable names may not have the following characters: %,$,#,@,!,+,*,~,\",-,..\nVariable names may not have blank spaces.\nEach variable name must be unique; the same variable name can’t appear twice.\nVariable names must be on one row only.\n\n\n\n2.1.2 Variable Type\nThe most fundamental characteristic of a variable is its type. These are the four most important types:\n\nNumeric includes comma, dot, and scientific notation types\nString also called character, alpha, or alpha-numeric\nDollar includes custom currency type but is still numeric\nDate is still numeric but displayed using hours, minutes, and seconds\n\n\n\n\n\n\nMost statistical analyses use only numeric variables. SPSS can handle a short string variable, such as gender coded as “m” and “f”, when that variable defines groups for a t-test or an analysis of variance (ANOVA).\nThe Dollar type changes the way the values appear in the data editor and the output, but all analyses treat the Dollar type as numeric.\nThe appearance of a date variable does not affect the way that the .sav file stores the date. SPSS understands date/time variables as the number of seconds since midnight, October 14, 1582 which is a significant date marking a change in the Gregorian calendar. If you subtract one date from the other to create a new variable, the result will be in seconds. To change back to days, hours, or years, it is necessary to use a function to turn the information into a more usable, practical form. See the section Computing New Variables for more information.\nTry it: Use section2_data.sav. Change the Variable Type for the ID variable from Dollar to Numeric.\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.3 Variable Labels\nVariable labels attach a description to a variable, and this description can show up in the output. To enter a variable label, click in the Label cell for a given variable in Variable View, and enter a description for the variable. Variable labels can be up to 255 characters as of Version 15.0.\nTry it: Use section2_data.sav. Provide a label for DepScale (Depression Scale 1998).\n\n\n\n\n\n\n\n2.1.4 Value Labels\nValue labels are similar, except that they refer to specific values within that variable. You don’t have to enter labels for all values. A value label can be up to 120 bytes long. Suppose the following question was in a survey:\nWhich of the following describes your political beliefs best?\n\nDemocrat\nRepublican\nLibertarian\nOther\n\nYou will enter the responses as 1, 2, 3, or 4. These numbers are arbitrarily, however, and some users may not know or may forget their meaning. Value labels allow the user to attach meaning to the numbers. Value labels are absolutely critical in large data files. Like variable labels, value labels will appear in many of the results provided by SPSS.\nTo assign value labels, click on the Values cell for a given variable, and click on the small grey box. Enter a number in the Value box, then the corresponding label in the Value Label box. Then press “Add”. If you do not press “Add”, the information you have typed for that value will be ignored.\nTry it: Use section2_data.sav. Enter in value labels for variable Education:\n\n1: High School or Less\n2: Some College\n3: College Graduate\n\n\n\n\n\n\n\n\n2.1.5 Missing Value Labels\nThere are two kinds of missing values: system-missing, in which the cell is empty, and user-missing, which flags a value as an invalid response. There often could be several reasons that a value is not available, and user-missing values allow us to discriminate between them. Examples of user-defined missing values are:\n\n99 “Don’t Know” reply on a survey\n777 Inapplicable, such as with number of births for a male respondent\n-999 Respondent refused to answer, which often occurs with income\n\nEnter user-missing values just like any other response during data entry. You need to tag the value as missing, however, so that SPSS does not include it in any computations. Consider the repercussions if we forgot to specify the 777 in the above example as Inapplicable, and then attempted to calculate the average number of births!\nYou can specify user-missing values by clicking on the cell in the Missing column for a given variable, and then clicking on the small grey box that appears as “(…)”. You may specify single values or a range of values.\nTry it: Use section2_data.sav.Enter missing value codes for Education (99).\n\n\n\n\n\n\n\n2.1.6 Columns & Alignment\nYou can change the alignment of the data by changing the Columns or Align attributes. You can use the Align attribute to center values or align them to the right or left of the cell in the Data Editor. Additionally, you can decrease or increase the width of the columns using the Columns attribute. A shortcut is to place the mouse at the right edge of a variable name, click on the border, and drag the column to be wider or narrower.\nAsterisks (*) in the cells within a particular column mean that the column is not wide enough to display the data values. Simply increase the column width and the values should appear properly in the Data Editor. Another possible problem might be that the width is too small to display all of the information for a variable.\nThe Columns and Align attributes have no effect on the data; they only affect the way you see the data in the editor.\n\n\n2.1.7 Measure\nEach variable in SPSS may be designated as\n\nScale a continuous variable\nOrdinal a categorical variable with natural ordering\nNominal categorical without any natural ordering\n\nGraphs from the Interactive graphics method use this information. This field has no bearing for most procedures.\nTry it: Use section2_data.sav. Change the Measure for the Education variable from Scale to Ordinal.\n\n\n\n\n\n\n\n2.1.8 Copy and Paste Variable Attributes\nYou can set up any of the attributes discussed above, such as type, labels, missing values, and column format, and apply them to numerous variables all at once. Suppose a researcher has a series of 50 variables that all have values 1 through 5 as follows:\n\n1 Strongly disagree\n2 Disagree\n3 Neutral\n4 Agree\n5 Strongly agree\n\nValue labels would be useful for these variables, but it would be extremely tedious to set up value labels for all 50 variables. Set up the value labels for one of the 50 variables, and then click on the cell containing the value labels for that variable. Select “Copy” from the “Edit” menu or hit CTRL + C, and then highlight the value labels cells for the remaining 49 variables by clicking on the first empty cell and dragging downward. Select “Paste” from the “Edit” menu or hit CTRL + V, and the value labels will be applied to the remaining 49 variables instantly. You can also right-click and use the copy and paste functions. You can use this same copy and paste feature for other variable attributes and save a great deal of time!\nTry it: Use section2_data.sav. Copy and paste the missing value code from Education to DepScale."
  },
  {
    "objectID": "02-variables.html#exercise-3-variable-attributes",
    "href": "02-variables.html#exercise-3-variable-attributes",
    "title": "2  Working with Variables",
    "section": "2.2 Exercise 3 – Variable Attributes",
    "text": "2.2 Exercise 3 – Variable Attributes\nOpen exercise3_data.sav and go to Variable View. Practice defining the correct attributes to each variable by following the code book below.\n\n\n\n\n\n\n\n\n\n\nName\nLabel\nValue Label\nMissing Values\nMeasure\n\n\n\n\nIDnum\n\n\n\nScale\n\n\nsex\nRespondent’s Sex\n1 = Male\n\nNominal\n\n\n\n\n2 = Female\n\n\n\n\nrace\nRace of Respondent\n1 = White\n\nNominal\n\n\n\n\n2 = Black\n\n\n\n\n\n\n3 = Other\n\n\n\n\nregion\nRegion of the United States\n1 = North East\n\nNominal\n\n\n\n\n2 = South East\n\n\n\n\n\n\n3 = West\n\n\n\n\nhappy\nGeneral Happiness\n0 = NAP\n0, 8, 9\nOrdinal\n\n\n\n\n1 = Very Happy\n\n\n\n\n\n\n2 = Pretty Happy\n\n\n\n\n\n\n3 = Not too Happy\n\n\n\n\n\n\n8 = DK\n\n\n\n\n\n\n9 = NA\n\n\n\n\nlife\nIs Life Exciting or Dull\n0 = NAP\n0, 8, 9\nOrdinal\n\n\n\n\n1 = Exciting\n\n\n\n\n\n\n2 = Routine\n\n\n\n\n\n\n3 = Dull\n\n\n\n\n\n\n8 = DK\n\n\n\n\n\n\n9 = NA\n\n\n\n\nsibs\nNumber of Brothers and Sisters\n98 = DK\n98, 99\nScale\n\n\n\n\n99 = NA\n\n\n\n\nchilds\nNumber of Children\n8 = Eight or More\n9\nScale\n\n\n\n\n9 = NA\n\n\n\n\nage\nAge of Respondent\n98 = DK\n0, 98, 99\nScale\n\n\n\n\n99 = NA\n\n\n\n\neduc\nHighest Year of School Completed\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\npaeduc\nHighest Year School, Father\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\nmaeduc\nHighest Year School, Mother\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\nseeduc\nHighest Year School, Spouse\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\nprestg80\nOccupational Prestige Score\n0 = DK,NA,NAP\n0\nScale\n\n\nocccat80\nOccupational Category\n1 = Managerial and Professional\n\nNominal\n\n\n\n\n2 = Technical and Sales\n\n\n\n\n\n\n3 = Service\n\n\n\n\n\n\n4 = Farming, Forest, and Fishing\n\n\n\n\n\n\n5 = Production and Craft\n\n\n\n\n\n\n6 = General Labor"
  },
  {
    "objectID": "02-variables.html#creating-new-variables-and-defining-the-correct-attributes",
    "href": "02-variables.html#creating-new-variables-and-defining-the-correct-attributes",
    "title": "2  Working with Variables",
    "section": "2.3 Creating New Variables and Defining the Correct Attributes",
    "text": "2.3 Creating New Variables and Defining the Correct Attributes\nTo create a new variable in SPSS for entering data, simply double-click on an empty column’s heading, or start entering data directly into the column in Data View. To enter values, first click in an empty cell; then type each value and press either return or the down arrow.\nDuring data entry, be aware that the order of cases in an SPSS data file can change because certain procedures require that cases be sorted. Therefore, be careful to match values with an ID variable. The case that occupied the first row in the file a week ago may not be in the first row any longer!\nNew variables, including those created by computation or recoding, appear at the far right of the data file. Use the scroll bar at the bottom to verify that a new variable was properly created.\nCut, copy, or paste a variable or insert a new empty column by right clicking on a variable name.\nA pasted variable is not inserted in between existing variables. It replaces the highlighted column entirely, and could over-write an existing variable. Be sure to create a new, blank column and paste on top of that.\nTry it: Use section2_data.sav. Create a new variable called NewVar."
  },
  {
    "objectID": "02-variables.html#computing-variables",
    "href": "02-variables.html#computing-variables",
    "title": "2  Working with Variables",
    "section": "2.4 Computing Variables",
    "text": "2.4 Computing Variables\nYou can use the COMPUTE command to create new numeric or string variables by:\n\nAssigning a particular value to all cases, or a subset of cases\nTransforming a variable by taking a log, or another mathematical function\nCreating a sum, average, or other summary of several existing variables\n\nHelpful Hint: You can use the COMPUTE procedure to edit or overwrite an existing variable, but we highly recommend that you create new variables. If you do over-write an existing variable, be aware that some old values may not be overwritten. If some of the necessary information is missing for a certain case in the file, and the software cannot compute the new value, then the value from the old variable will remain.\nSelect Transform -&gt; Compute Variable and enter a name for the new variable in the upper left box, labeled “Target Variable.” SPSS will automatically create the new variable when it executes the compute command.\n\n\n\n\n\nBy default, SPSS assumes that the user wants to compute a numeric variable. If you want to create a string variable, click “Type & Label” underneath the new variable name, and select “String.”\nIn the box titled “Numeric Expression”, provide the actual formula or value for the new variable. You may write the numeric expressions by hand or insert variables and functions using the mouse.\nHelpful Hint: Click on the function name to get a function description in the dialogue box.\nIf you want to create new dollar or date variables, then proceed as if creating a numeric variable. The type can be changed after the compute command is used. Note that seconds are the units of measurement for date variables. To create date variables, we must use functions specifically designed for the date variable type. See the List of Functions below for more information.\n\n2.4.1 Dealing with Missing Data\nApplying a function to a variable containing missing values will result in a variable with corresponding system-missing values.\nWhen taking the mean or sum of a set of variables, be sure to use the mean() and sum() functions. SPSS only evaluates formulas such as (var1 + var2 + var3 + var4)/4 if all four variables have valid, non-missing values.\nBy contrast, the software evaluates the formula mean(var1, var2, var3, var4) as long as an individual has at least one valid response. You can also stipulate that SPSS perform the calculation only when there are a minimum number of valid responses. The formula mean.3(var1, var2, var3, var4, var5), for example, would mean that an individual must have answered at least 3 of the 5 questions. The new variable will have a missing value otherwise.\nTry it: Use section2_data.sav. Calculate the average depression score using DepScale_01, DepScale_02, DepScale_3. First use the function “mean”. Next write the expression by hand. Investigate the differences.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.2 List of Functions Available in the Compute Command\nArithmetic Operators:\n\n+ Addition\n- Subtraction\n* Multiplication\n/ Division\n** Exponentiation\n\nArithmetic Functions:\n\nABS Absolute value\nRND Round\nTRUNC Truncate\nMOD Modulus (remainder)\nSQRT Square root\nEXP Exponential\nLG10 Base 10 log\nLN Natural log\nARSIN Arcsin\nARTAN Arctangent\nSIN Sine\nCOS Cosine\n\nStatistical Functions:\n\nSUM(.n) Sum of arguments\nMEAN(.n) Mean of arguments\nSD(.n) Standard deviation of arguments\nVARIANCE(.n) Variance of arguments\nCFVAR(.n) Coefficient of variation of arguments\nMIN(.n) Minimum of arguments\nMAX(.n) Maximum of arguments\n\nMissing Values Functions:\n\nMISSING True if the value is missing\nNMISS Number of missing values across variables but within cases\nNVALID Number of non-missing values across variables but within cases\n\nAcross-case Function:\n\nLAG Value from previous case, or from n cases earlier if there is a second argument n\n\nDate and Time Functions:\n\nCTIME.xxx SPSS time values to common units\nDATE.xxx Common units to SPSS date values\nTIME.xxx Common units to SPSS time values\nXDATE.xxx SPSS date values to common units\n\nOther Functions:\n\nRV.UNIFORM Uniform pseudorandom no.\nRV.NORMAL Normal pseudorandom no.\nCDF.NORMAL Standard normal cumulative dis.\n\nLogical Functions:\n\nRANGE True if value is within range\nANY True if any value matches\n\nString Functions:\n\nANY Same as for numeric values\nCONCAT Concatenate\nINDEX Index from left\nLAG Same as for numeric values\nLENGTH Defined length\nLOWER Convert to lower case\nLPAD Pad left\nLTRIM Trim left\nMAX Greatest value\nMIN Least value\nNUMBER Convert to a number\nRANGE Same as for numeric values\nRINDEX Index from right\nRPAD Pad right\nRTRIM Trim right\nSTRING Convert to a string\nSUBSTR Substring\nUPCASE Convert to upper case\n\n\n\n2.4.3 Count Values\nOne useful way to compute new variables is through the “Count Values within Cases” procedure. This procedure counts how many times particular values occur, within each case, across certain variables. Suppose we have a data set of students where we recorded their scores on ten separate quizzes over the course of a semester. We could use “Count Values within Cases” to tally up the number of A’s each student earned.\nTo use the Count Values within Cases procedure:\n\nGo to Transform -&gt; Count Values within Cases.\nSpecify a new variable name under “Target Variable”.\nPlace the variables to be examined in the “Variables” box.\nClick “Define Values”, and type the values to be counted.\nClick “Continue”, then “OK”.\n\n\n\n\n\n\nRecoding Variables\nRecoding a variable means changing or “mapping” its values to new ones. Often, you will need to convert string variables into numeric variables in order to use them in a certain statistical procedure. Recoding is also a way to collapse a continuous variable into categories.\nBelow are representations of some possible recodes:\n\n“Male” – 1\n“Female” – 0\n1 – 0\n2 – 1\n3 – 2\n4:15 – 9\n\n\n\n2.4.4 Manual Recoding\nThere are two ways to recode in SPSS:\n\nRecode Into Same Variables Not Recommended\nRecode Into Different Variables Recommended\n\nBy using “Recode Into Different Variables”, your original variable will not change, which is not the case with “Recode Into Same Variables”. “Recode Into Same Variables” is risky since you will not be able to undo the changes if you make a mistake.\nSelect Transform -&gt; Recode into Different Variables\n\n\n\n\n\nIn the “Recode Into Different Variables” dialogue box:\n\nSelect the old (original) variable.\nSpecify a new variable name, and click “Change”.\nClick “Old and New Values”.\n\nSpecify each old value, or range of values, on the left side of the box and each new number you want assigned on the right side of the box. Click “Add” each time.\nMake sure you include every original value. Unmentioned original values become missing values in the new variable.\nClick “Continue”.\n\nClick “OK”.\n\n\n\n\n\n\nNote that when using “Recode Into Different Variables”, it is also possible to recode a numeric variable into a character (string) variable, or vice-versa:\n\nCheck the box marked “Output variables are strings” to change from numeric to string in the “Old and New Values” window\nCheck the box marked “Convert numeric strings to numbers” to change from string to numeric in the “Old and New Values” window.\n\nTry it: Use section2_data.sav. Recode Gender with F=1 and M=2. Inspect the output."
  },
  {
    "objectID": "02-variables.html#automatic-recoding",
    "href": "02-variables.html#automatic-recoding",
    "title": "2  Working with Variables",
    "section": "2.5 Automatic Recoding",
    "text": "2.5 Automatic Recoding\nThe Automatic Recode procedure recodes any variable’s values into consecutive integers 1, 2, 3, etc…. The software codes the lowest numeric value, or the first value in alphabetical order in the case of string variables, to a 1 by default. The next lowest number or next item in alphabetical order becomes a 2, and so forth. Optionally, the recoding can begin with the highest number of the last string value in alphabetical order.\nAutomatic Recode always creates a new variable.\nHelpful Hint: Automatic Recode is a quick way to make string variables (e.g., gender) ready for statistical procedures that require numeric variables.\nTo use Automatic Recode:\n\nGo to Transform -&gt; Automatic Recode.\nChoose the original variable to be recoded.\nSpecify a new variable name and click “Add New Name”.\nSelect the order – start numbering from smallest or largest values.\n\n\n\n\n\n\nHelpful Hint: If you had assigned value labels for the old variable, those labels will carry over to the corresponding new values. If there were no value labels, then the old values themselves become the new labels.\nTry it: Use section2_data.sav. Use Automatic Recode to recode Gender. Call this new variable AutoGender."
  },
  {
    "objectID": "02-variables.html#conditional-transformations-with-ifthen-logic",
    "href": "02-variables.html#conditional-transformations-with-ifthen-logic",
    "title": "2  Working with Variables",
    "section": "2.6 Conditional Transformations with If/Then Logic",
    "text": "2.6 Conditional Transformations with If/Then Logic\nThe “If” button, which appears in the Compute, Recode, and Count dialogue boxes, represents an important feature in variable transformations. Using the “If” option, users can tell SPSS to perform calculations or recodes only if cases meet certain conditions.\nFor example, suppose we surveyed women regarding the number of times they had given birth, but women who had never been pregnant skipped that section of the questionnaire. We might now want to assign a “0” for the number of births for those women who had never been pregnant, to replace the missing entry they currently have.\nAssuming that we have a string variable called “everpreg” coded “Y” and “N” for yes and no, and that our number of births variable is called “numbirth”, we would proceed as follows:\nGo to Transform -&gt; Compute Variable\n\nPut numbirth in the “Target Variable” box.\nPlace a 0 in the “Numeric Expression” box.\nClick “If”.\nClick “Include if case satisfies condition”.\nType everpreg = “N” in the condition box.\nClick “Continue” and “OK”.\n\n\n\n\n\n\n\n\n\n\n\nThis “If” button, which allows transformations to take place for selected cases only, works exactly the same in the Compute, Recode, and Count procedures.\nYou can use the words and, or, and not within the If box to help write your criteria. Some examples of If expressions are as follows:\n\nsex = \"f\" and age &gt; 50 - women over 50\nnot missing(income) - participants whose income is known\neducat = 5 or educat = 6 - respondents with a BA or MA"
  },
  {
    "objectID": "02-variables.html#rank-cases",
    "href": "02-variables.html#rank-cases",
    "title": "2  Working with Variables",
    "section": "2.7 Rank Cases",
    "text": "2.7 Rank Cases\nYou can perform variable transformations based on the ranked value for a particular variable. It may be more convenient to analyze the quartiles, for example, than the variables themselves.\nSelect “Transform” and then “Rank Cases” to recode a continuous variable into a new variable based on rank. Select the variable of interest and then click “Rank Types”. You can select quartiles in this dialogue box by checking the box for Ntiles and placing the number 4 in the blank space. SPSS will create a new categorical variable and add it to the end of the original dataset."
  },
  {
    "objectID": "02-variables.html#exercise-4-computing-and-transforming-variables",
    "href": "02-variables.html#exercise-4-computing-and-transforming-variables",
    "title": "2  Working with Variables",
    "section": "2.8 Exercise 4 – Computing and Transforming Variables",
    "text": "2.8 Exercise 4 – Computing and Transforming Variables\nOpen exercise4_data.sav.\nCompute a new variable that is the change from beginning salary to current salary for each employee.\nRecode the education variable into a new variable according to the following\n\n1 = High School or Less (educ&lt;=12)\n2 = Some College (12&lt;educ&lt;=16)\n3 = Bachelor’s Degree or Higher (educ&gt;=17)"
  },
  {
    "objectID": "03-data-management.html#sorting-cases",
    "href": "03-data-management.html#sorting-cases",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.1 Sorting Cases",
    "text": "3.1 Sorting Cases\nSorting cases based on a particular variable is often necessary when managing data sets. Go to Data -&gt; Sort Cases to place the cases in order. Choose the variable that determines the ordering, and choose “Ascending” or “Descending”.\n\n\n\n\n\nSelecting the ID variable and choosing “Ascending” will place the subject with the smallest ID number in the top row. The bottom row will contain data on the subject with the largest (highest) ID number.\nWhen sorting by more than one variable, SPSS sorts the data initially based on the first variable. Within each value of that first variable, it sorts again based on the second variable. Make sure to select “Ascending” or “Descending” for each variable when you are sorting by multiple variables. Highlight the variable by clicking on it, and choose the correct ordering.\nSuppose we want to sort by gender and then by age, with both in ascending order. Suppose the codes for gender are as follows:\n\n0: male\n1: female\n\nSPSS would first put males at the top of the file and females at the bottom. SPSS would then sort by age within each gender group. The first rows of the data set would contain the youngest men in the sample and the last subjects at the bottom would be the oldest women in the sample."
  },
  {
    "objectID": "03-data-management.html#analyzing-subsets-of-data",
    "href": "03-data-management.html#analyzing-subsets-of-data",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.2 Analyzing Subsets of Data",
    "text": "3.2 Analyzing Subsets of Data\nYou can use the “Select Cases” command to instruct the software to calculate statistical results or summaries based on only some of the cases in the data set. You can define the subset by certain characteristics, such as women over age 40, or you can instruct the software to select a random sample of cases with size that you specify.\nNote: The Select Cases procedure affects which cases that SPSS includes in analysis and output only. It has no effect on transformations of the data, such as computing, recoding, or counting.\nSelecting cases involves turning on a filter that handles the inclusion of certain cases and the exclusion of others. When the filter is on, analyses or summaries will only use the selected cases. There will be a message “Filter On” at the bottom right of the Data Editor window whenever SPSS is using only selected cases.\nThe first time you invoke the “Select Cases” procedure, the software creates a variable called filter_$ in the data set. This variable is equal to 0 for excluded cases and 1 for included cases. SPSS deletes and then re-creates the filter_$ variable each time you run “Select Cases”.\nUsers can specify their own filter variable. He or she can use any variable as a filter as long as a value of 0 for that variable indicates exclusion and a value of 1 inclusion. Click the “Use filter variable” option under Data -&gt; Select Cases to do this; move your filter variable into the box.\n\n3.2.1 If Condition is Satisfied\nGo to Data -&gt; Select Cases to use only some of the cases. Click “If condition is satisfied….” to select cases based on certain criteria. Then click the “If…” button to pull up a window in which you will state the condition. Some example conditions are:\n\ngender = 'm' - selects men only\nage &lt;= 12 and sex = 2 - selects children 12 and under of one sex only\nmarital = 0 -selects all never married respondents\n\nYou can return to the data editor by clicking “Continue” and “OK”. Notice that certain rows have been “scratched” out by SPSS. SPSS has filtered out these cases because they did not satisfy the specified condition. Analyses will only use those cases that are not scratched out.\n\n\n\n\n\n\n\n\n\n\nTo return to the entire sample, go to Data -&gt; Select Cases, choose the radio button next to “All Cases,” and then click “OK”. The “Filter On” message will disappear and all results from that point on refer to the entire data set.\n\n\n3.2.2 Randomly Selecting Subsets\nYou may examine a randomly selected portion of the data by clicking “Random Sample of Cases” in the “Select Cases” window. Then click the “Sample…” button. You can then give an approximate percentage. If you want to take an exact number of cases, first determine the total number of cases (rows) and place this number in the “from the first --- cases” segment of the dialogue box. If you would like to take a precise number of cases from, say, all women, or all children under twelve, then sort the data first so that the cases of interest occupy the first rows. Determine the last row that refers to a female, or to a child under twelve, and proceed as above.\n\n\n\n\n\nNote: When SPSS selects cases randomly, repeated selections will be different even when everything specified by the user has stayed the same. An approximate 30% sample of cases will result in a different 30% each time the user repeats the procedure.\nHelpful Hint: To use the same random selection of cases over and over again, first take the initial random sample. Then re-name the filter_$ variable to any name of your choosing. SPSS will leave the variable alone, and you can re-use the filter in consecutive SPSS sessions.\n\n\n3.2.3 Output Options\nAt the bottom of the “Select Cases” dialogue box are three options:\n\nFilter out unselected cases (recommended)\nCopy selected cases to a new dataset (recommended)\nDelete unselected cases (NOT RECOMMENDED)\n\n\n\n\n\n\nIf you set this to “Filter out unselected cases”, the unselected cases remain in the data set but the software temporarily excludes them from all analyses. If you choose the second option, SPSS copies the selected cases to a new dataset and you can save the dataset on your disk by assigning a file name. The content of your original dataset remains untouched with these two options.\nIf the you change the option to “Delete unselected cases”, unselected cases disappear from the data entirely. Be careful when permanently deleting cases, because you CANNOT undo the deletion. Make sure to first save your data file under a different name if you wish to permanently delete cases.\nTry it: Use section3_data.sav. Select only observations with Education = 1 for analysis."
  },
  {
    "objectID": "03-data-management.html#analyzing-groups-of-data-separately",
    "href": "03-data-management.html#analyzing-groups-of-data-separately",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.3 Analyzing Groups of Data Separately",
    "text": "3.3 Analyzing Groups of Data Separately\nWhen analyzing groups of cases separately, such as men and women, the Split File command spares you from having to repeatedly select different groups of cases.\nThe Split File command first sorts the data into groups based on a specified variable. After that, SPSS generates any requested output for each group separately. If we split the file based on gender and then request the mean current salary, we would receive a mean current salary for men and a mean current salary for women. A flag at the bottom right of the data editor will read “Split File On” when you are using this option.\nYou can use multiple variables to divide the data. If you use both gender and job category as grouping variables, for example, then SPSS will give all output for each job category group within each gender.\nTo use Split File:\n\nGo to Data -&gt; Split File.\nClick on “Compare Groups” or “Organize Output by Groups”.\nSelect variable(s) which divide the data into groups.\nClick OK.\nTo turn off the Split File command, return to Data -&gt; Split File and click on “Analyze all cases, do not create groups”.\n\n\n\n\n\n\nTry it: Use section3_data.sav. Obtain the descriptive statistics for DepScale_01 for males and females separately. Hint: Select Analyze -&gt; Descriptive Statistics -&gt; Descriptives."
  },
  {
    "objectID": "03-data-management.html#exercise-5-subsetting-data",
    "href": "03-data-management.html#exercise-5-subsetting-data",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.4 Exercise 5 – Subsetting Data",
    "text": "3.4 Exercise 5 – Subsetting Data\nOpen exercise5_data.sav.\nSelect male managers. What is their average age?\n(You can obtain the average age by choosing Analyze -&gt; Descriptive Statistics -&gt; Descriptives and moving “Age of Respondent (age)” to the right hand side.)\nUse the “Split File” procedure to get the average age for each job category."
  },
  {
    "objectID": "03-data-management.html#merging-files",
    "href": "03-data-management.html#merging-files",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.5 Merging Files",
    "text": "3.5 Merging Files\n\n\n\n\n\n\n3.5.1 Adding Cases\nSuppose you have two files containing data on different cases, in which many of the variables are the same in name and format. You can merge these files together using the Add Cases command.\n\n\n\n\n\nTo merge the files, the basic steps are:\n\nOpen the first data file.\nGo to Data -&gt; Merge Files -&gt; Add Cases.\nFind and select the second file, containing the additional cases.\nChoose variables to be included in the resulting file.\nClick OK.\n\n\n\n\n\n\nInside the Add Cases dialogue window, one variable box on the right will have label “Variables in New Active Dataset”. Any variable listed in this box exists in both files under the same name, and will automatically be included in the resulting data set.\nVariables listed in the left box are those that SPSS was not certain what to do with. They may appear in only one data set, or the variables in the two data sets may be named slightly differently. One data set we might use the variable number “sex” and the second the variable name “gender”, for example.\nVariable names might come from the active data set or from the external file. SPSS indicates the origin of the name by assigning these symbols:\n\nthe current (working) data file: *\nthe second (external) data file: +\n\nWhen a variable exists in only one data file, and it is not simply a matter of mismatched names, simply move the variable into the right-hand box. The variable will exist in the resulting merged file and will have only missing values for one group of cases.\nIf two variables have different names, on the other hand, then select both variable names and click the “Pair” button. Before pairing them, you may want to rename one of the two to match the other; simply select the one whose name you would like to change and click “Rename”. If you do not use the Rename option, the software will use the name from the current working data file.\nThe last option is the box labeled “Indicate case source as variable”. If you check this box, you can specify a name for a variable in the new file that will indicate the file that the case came from.\nSPSS sets up the new variable as follows:\n\n0 indicates the case came from the currently open data set\n1 indicates that the case is from the external (2nd) data set\n\n\n\n3.5.2 Adding Variables\nSuppose that we have files containing the same subjects, but different information. If we want to combine all the information into one new file, we want to add variables to one of the files.\n\n\n\n\n\nBefore actually using the “Add Variables” procedure, which is found under Data -&gt; Merge Files -&gt; Add Variables, there are certain prerequisites that SPSS is very insistent upon:\n\nBoth files must contain a key “matching” variable, usually ID, which will be the basis for linking up each row of data.\nThis key matching variable must be of the same type, including the same length. Preferably, it should have the same name.\nEach data file must be sorted in ascending order based upon the key matching variable. Save each file in its sorted form.\n\nNote: it is NOT necessary to have exactly the same cases in both files.\nIf all of these conditions are met, we can proceed with the Add Variables procedure. The first step is to identify the external file that we will obtain the new variables from. SPSS identifies variables as follows:\n\nfrom the working, or current, data file: (*)\nfrom the second, or external, data file: (+)\n\n\n\n\n\n\nThere are two locations where we can find variable names in the Add Variables dialogue box. The right box, labeled “New Active Dataset:”, lists the variables from the external dataset to include, and the left lists the excluded variables. The excluded variables are those which were found in both files. If the same variable is in both files, SPSS isn’t sure which one to accept in the resulting file, since there cannot be duplicate variable names. It will exclude one of the two variables.\nClick the box marked “Match cases on key variables in sorted files”. Next, find the ID variable from either data file, and move it into the “Key Variables” box. If the ID variables have different names, then first rename the variables so that they match.\nThere are three options underneath the box marked “Match cases on key variables in sorted files”. The options which include the phrase “keyed table” typically refer to merging with aggregated datasets. If the data file that is being merged into the working data file has at most one record per value of the key variable(s), then use the option “Non-active dataset is Keyed Table” in most cases.\nThere are two things to understand about applying aggregate data:\n\nThe key matching variable is the one that identifies each aggregate case.\nThe phrase “keyed table” refers to the aggregate data set.\n\nSPSS uses the key variable to go to the aggregate data set, look up the information for that group (e.g., job category), and take that information back to each and every individual in that group in the original data file. For that reason, SPSS sees the aggregate data set as a reference table, which of course includes the key variable that attaches the appropriate information to the individuals.\nIf you begin in the individual data set, go to Add Variables and proceed as if both files have individual data. Then select the “Non-active dataset is keyed table” option, notifying SPSS that the external file is really nothing more than a reference table from which to obtain information for each individual case. If you begin in the aggregate data set, which typically has fewer rows, then select “Active dataset is keyed table”."
  },
  {
    "objectID": "03-data-management.html#converting-data-formats",
    "href": "03-data-management.html#converting-data-formats",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.6 Converting Data Formats",
    "text": "3.6 Converting Data Formats\nDifferent statistical methods frequently require different data formats. A repeated measures analysis of variance, for example, requires that data be in Wide format, while a linear mixed model requires that the data be in Long format. SPSS makes it easy to convert between the two formats. The examples below demonstrate how to use the wizard in SPSS.\nTo convert a dataset from one format to the other, first select “Data” and then “Restructure”. SPSS uses terminology that differs from conventional phrasing.\n\nWide to Long Variables into Cases\nLong to Wide Cases into Variables\n\nWe will briefly discuss these two variations, before doing exercises together which include the instructions.\n\n3.6.1 Wide to Long (AKA “Variables into Cases”)\n\n\n\n\n\nThere are seven steps in this Wizard:\n\nIdentify the restructuring plan to be from “Variables into Cases”.\nSelect the number of variable groups.\nSelect variables.\nCreate index variables (usually one).\nCreate one index variable.\nChoose options.\nFinish.\n\n\n\n3.6.2 Long to Wide (AKA “Cases into Variables”)\n\n\n\n\n\nThere are five steps in this Wizard:\n\nIdentify the restructuring plan as “Cases into Variables”.\nSelect variables.\nSort the data.\nChoose options.\nFinish."
  },
  {
    "objectID": "03-data-management.html#exercise-6-restructuring-i-wide-to-long",
    "href": "03-data-management.html#exercise-6-restructuring-i-wide-to-long",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.7 Exercise 6 – Restructuring I (Wide to Long)",
    "text": "3.7 Exercise 6 – Restructuring I (Wide to Long)\nConvert exercise6_data.sav from “Wide” format to “Long” format"
  },
  {
    "objectID": "03-data-management.html#exercise-7-restructuring-ii-long-to-wide",
    "href": "03-data-management.html#exercise-7-restructuring-ii-long-to-wide",
    "title": "3  Understanding Data Management Tasks",
    "section": "3.8 Exercise 7 – Restructuring II (Long to Wide)",
    "text": "3.8 Exercise 7 – Restructuring II (Long to Wide)\nConvert exercise7_data.sav from “Long” format to “Wide” format\n(Both exercises to be done together.)"
  },
  {
    "objectID": "04-stats.html#thinking-about-statistics",
    "href": "04-stats.html#thinking-about-statistics",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.1 Thinking About Statistics",
    "text": "4.1 Thinking About Statistics\nStatistics is in a sense a giant toolbox containing a collection of graphical and statistical procedures.\nEach graphical or statistical procedure is good for a particular situation we may run into while doing data analysis. The main purpose of any graphical and statistical procedure is to investigate a variable or the relationships between variables. That is a very important concept!\nTHE MAIN PURPOSE OF ANY GRAPHICAL OR STATISTICAL PROCEDURE IS TO INVESTIGATE A VARIABLE OR THE RELATIONSHIPS BETWEEN VARIABLES.\nKeep in mind that graphical procedures can be more valuable to you than statistical procedures. You should try to express your results in graphs whenever you can.\nIt is not hard to implement or interpret any graphical or statistical procedure once you understand and can explain the procedure. SPSS is very helpful in both regards. The biggest challenge facing any researcher is to know the most appropriate procedure to apply in any particular situation.\nThe types of the independent and dependent variables (predictors and outcome) will guide your choice for the appropriate graphical and statistical procedure.\nJust like in many things in life, the 80/20 rule somewhat applies to statistics. There are a small number of procedures that you will use more repeatedly than others. Here, we will divide those essential procedures, graphical and statistical, into 4 major classifications:\n\nOne Variable Only Procedures\nOne-on-One Procedures investigating two variables at a time\nMany-on-One Procedures\nRepeated, Longitudinal, Clustered, Multilevel, and Mixed Procedures"
  },
  {
    "objectID": "04-stats.html#correlation-vs.-causation",
    "href": "04-stats.html#correlation-vs.-causation",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.2 Correlation vs. Causation",
    "text": "4.2 Correlation vs. Causation\nThe presence of a correlation between two variables DOES NOT imply that there is causation between them. Any of the three scenarios below could explain the correlation between two variables A and B. We can’t tell using statistics alone which scenario it is.\n\nA causes B\nB causes A\nC causes both A and B"
  },
  {
    "objectID": "04-stats.html#everything-on-one-page-handout",
    "href": "04-stats.html#everything-on-one-page-handout",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.3 Everything On One Page Handout",
    "text": "4.3 Everything On One Page Handout\nThe chart below lays out the essential graphical and statistical procedures by type and classification."
  },
  {
    "objectID": "04-stats.html#parametric-vs.-non-parametric-tests",
    "href": "04-stats.html#parametric-vs.-non-parametric-tests",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.4 Parametric vs. Non-parametric Tests",
    "text": "4.4 Parametric vs. Non-parametric Tests\nThere are varying assumptions that underlie the validity of each statistical procedure. A common assumption for statistical procedures is that the samples being analyzed should come from an underlying normal distribution. If this is not a reasonable assumption, you can use non-parametric tests. Non-parametric tests do not have this distributional assumption, and generally use ranks in the place of the raw scores. The table below gives non-parametric tests that are equivalent to common parametric tests.\n\n\n\n\n\n\n\nParametric Test\nNon-Parametric Test\n\n\n\n\nPearson Correlation Coefficient\nSpearman Correlation Coefficient\n\n\nIndependent Samples t-test (2 groups)\nMann-Whitney / Wilcoxon Rank Sum Test (2 Groups)\n\n\nPaired Samples t-test (2 groups)\nWilcoxon Signed Rank Tests (2 Groups)\n\n\nOne Way ANOVA (3+ groups)\nKruskal-Wallis Test\n\n\nRepeated Measures ANOVA\nFriedman’s Test\n\n\nChi-Square Test\nFisher’s Exact Test"
  },
  {
    "objectID": "04-stats.html#basic-summary-statistics-investigate-one-variable-at-a-time",
    "href": "04-stats.html#basic-summary-statistics-investigate-one-variable-at-a-time",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.5 Basic Summary Statistics (Investigate One Variable at a Time)",
    "text": "4.5 Basic Summary Statistics (Investigate One Variable at a Time)\nAs the name implies, One-Variable-Only Procedures help us investigate a single variable at a time. They can tell us about the frequency distribution of a categorical variable (Frequency Table, Mode, Bar Graph, Pie Chart, etc.). They can give us insight into the central tendency of a continuous variable (Mean, Median, Mode, etc.). They can help us test a hypothesis about the mean of a variable (One Sample t-test). They can give us insight into the dispersion of a variable (Standard Deviation, Range, Inter-Quartile Range, Boxplots, Error Bar Plots, etc.). They can also give us insight into the relative position of any data point with respect to the other data points in a variable (Percentiles, Quartiles, Boxplots, etc.).\nIn SPSS, there are two procedures which provide simple descriptive statistics. You can find both procedures under Analyze -&gt; Descriptive Statistics.\n\n\n\n\n\n\n\n\n\n\nFrequencies procedure provides the number and % of cases which have each value of a variable (e.g., 46% male, 54% female). You can request other output by clicking Statistics. Frequencies are most useful for categorical variables.\nTry it: Use section4_1_data.sav. Obtain the frequency (descriptive) statistics for the variable Sex.\n\n\n\n\n\n\n\n\n\n\nDescriptives provides the mean, standard deviation, minimum, maximum and non-missing sample size by default. Other statistics are available by clicking Options. Descriptives are most useful for continuous variables, and sometimes useful for ordinal data (categorical data with ordering, e.g., small, medium, large) alongside the frequencies.\nTry it: Use section4_1_data.sav. Obtain the descriptive statistics for the variable Age.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs a first step in data analysis, one might run frequencies on all categorical variables and descriptives on all continuous variables. Obtaining descriptive statistics is an important step to detect possible data entry errors."
  },
  {
    "objectID": "04-stats.html#visualizations",
    "href": "04-stats.html#visualizations",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.6 Visualizations",
    "text": "4.6 Visualizations\nThere are two methods for creating charts in SPSS, Chart Builder and Legacy Dialogs. (There is a third method, in which other analysis methods create their own graphics, but we’re covering only direct creation of graphics here.)\nThe newer approach is Chart Builder, which is a more free-form approach. It has a steeper learning curve but is ultimately more powerful.\nThe classic approach is legacy dialogs which are much easier to use, but more restrictive in the types of plots they can create.\n\n4.6.1 Chart Builder\nTo create a graph in “Chart Builder”, first select the type of graph that you would like to create by dragging and dropping the appropriate graph image to the “Chart Preview” area. Once you select a chart, the Element Properties window will appear. The Element Properties window allows you to modify what is displayed in the graph\n\n\n\n\n\nTry it: Use section4_1_data.sav. Create a simple bar chart for “Region”.\n\n\n\n\n\n\n\n\n\n\n\n\n4.6.2 Legacy Dialogs\nThe “Legacy Dialogs” interface requires that you determine the type of graph you would like to create before providing a dialog box, which is similar to other procedures in SPSS. After you select the general type of graph or chart, SPSS will then prompt you to be more specific. If the general form is a scatter plot, for example, SPSS will ask you to then specify which type of scatter plot you would like to create. The software will present you with the graphing dialogue box once you specify the specific form for the graph.\n\n\n\n\n\n\n\n\n\n\nTry it: Use section4_1_data.sav. Create a simple bar chart for “Region”."
  },
  {
    "objectID": "04-stats.html#normality",
    "href": "04-stats.html#normality",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.7 Normality",
    "text": "4.7 Normality\nMany statistical procedures assume “normality”, which means the population which the data is from follows the Normal Distribution. You may know this as the “bell curve”.\n\n\n\n\n\nMany real-life variables follow a normal distribution such as height. If you were to collect a random sample of heights, most people would fall near the mean height for the population. Some people would be much taller or shorter, and a very limited number of people would be extremely short or extremely tall.\nThe normality assumption as written is usually quite strict; in practice we often loosen it. Rather than “The data comes from a normal population”, you can think of it as “The data comes from a population that’s not too badly non-normal.” Essentially, you’re looking for major violations of normality, rather than trying to determine whether the bell curve perfectly fits your data.\nFinally, a large sample size oftens “protects” you from normality violations; the larger the sample size, the more extreme a normality violation needs to be to be a concern.\nWhile there are formal tests of normality, typically assessment is done with a histogram (looking for that bell shape) or a QQ-plot, which looks for its values to fall along the 90° line. The histogram can be created from the Histogram Legacy Dialog, the QQ-plot is created under Analyze -&gt; Descriptive Statistics -&gt; QQPlot.\nTry it: Use section4_1_data.sav. Obtain a histogram for the variable “Age” and display the normal curve. Obtain a QQ plot for the variable “Age”. Hint: Analyze -&gt; Descriptive Statistics -&gt; QQPlot."
  },
  {
    "objectID": "04-stats.html#exercise-8-data-exploration-and-visualization",
    "href": "04-stats.html#exercise-8-data-exploration-and-visualization",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.8 Exercise 8 – Data Exploration and Visualization",
    "text": "4.8 Exercise 8 – Data Exploration and Visualization\nOpen exercise8_data.sav\nPart 1: Investigate the variable attributes. Determine which variables are categorical variables (nominal and ordinal), and which\nariables are continuous (scale). Obtain the appropriate descriptive statistics for each variable. Remember, continuous variables should be investigated with descriptives and categorical variables should be investigated with frequency tables.\nHint: Select more than one variable in the Analyze -&gt; Descriptive Statistics -&gt; Descriptives, or Analyze -&gt; Descriptive Statistics -&gt; Frequencies dialog boxes.\nPart 2: Assess the distribution of the Occupational Prestige Score (“prestg80”) with both a histogram (normal curve displayed) and a Q-Q plot. Is the assumption that the population of Occupational Prestige Scores is normally distributed reasonable?\nPart 3: Compare the average highest year of school completed (“educ”) for males and females.\nHint: First split the file by “sex” (Data -&gt; Split File), then calculate the descriptive statistics. Be sure to return to the Split File menu when you are done with this question and return the dialog box to “Analyze all cases”.\nPart 4: Produce a pie chart for the variable “region”. (We didn’t cover this, you can use either Chart Builder or Legacy Dialogs.)"
  },
  {
    "objectID": "04-stats.html#investigating-two-variables-at-a-time",
    "href": "04-stats.html#investigating-two-variables-at-a-time",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.9 Investigating Two Variables at a Time",
    "text": "4.9 Investigating Two Variables at a Time\nThe main purpose of any graphical and statistical procedure is to investigate a variable or the relationships between variables. We start by examining the relationship between variables using simple two-variable procedures. The type of independent and dependent variables that you would like to investigate determines the appropriate statistical or graphical procedure. Remember that the presence of a correlation between two variables DOES NOT imply that there is causation between them.\n\n4.9.1 Pearson Correlation Coefficient & Scatterplots\nThe Pearson Correlation Coefficient measures the linear association of two continuous variables. A scatterplot is an easy way to visually explore the association between two variables. When you plot the variables together, you obtain a clear sense of the overall relationship between the two variables.\nThe Pearson Correlation Coefficient (Pearson’s r) varies from -1 to +1. A value of zero indicates that there is no linear relationship between the two variables, a value of +1 indicates that there is a perfect positive linear relationship, and a value of -1 indicates that there is a perfect negative relationship. Positive relationships imply that variable 2 increases when variable 1 increases, and vice versa, while negative relationships imply variable 2 increases when variable 1 decreases, and vice versa.\nThe statistical significance of a correlation is the chance that you would observe a correlation that high or higher if there really was no correlation between the variables.\nFor the Pearson Correlation Coefficient in SPSS, select Analyze -&gt; Correlate -&gt; Bivariate.\n\n\n\n\n\nFor the Scatterplot in SPSS, select Graphs -&gt; Legacy Dialogs -&gt; Scatter/Dot, choose “Simple Scatter”, and click “Define”.\n\n\n\n\n\n\n\n\n\n\nTry it: Use section4_2_data.sav Investigate the correlation between the individual behavior intention scales.\n\nSelect Analyze -&gt; Correlate -&gt; Bivariate.\nSelect “BIndBehInt_Pre” and “BIndBehInt_Post”.\nSelect “OK”.\n\n\n\n\n\n\n\n\n\n\n\nThe table indicates that there is a significant correlation between the pre intervention and post intervention behavior scale scores. Our p-value (Sig (2-tailed)) is less than our predetermined 0.05 level of significance, so we reject the null hypothesis that there is not an association between these two variables. The correlation coefficient is positive, indicating that high scores for one variable correspond to high scores for the other variable. Conversely, low scores for one variable correspond to low scores for the other variable. Individuals who scored high on the pre-test also tended to score high on the post test.\nTo visually investigate this relationship, use a scatterplot:\n\nSelect Graphs -&gt; Legacy Dialogs -&gt; Scatter/Dot.\nSelect “Simple Scatter” and “Define”.\nSelect “BIndBehInt_Post” for the Y Axis.\nSelect “BIndBehInt_Pre” for the X Axis.\nSelect “OK”.\n\n\n\n\n\n\n\n\n\n\n\nThe scatterplot indicates a linear relationship between the two variables.\n\n\n4.9.2 Pearson Chi-Square Crosstabs and Test of Independence\nThe Chi-square test is very common way to explore the relationship between two categorical variables. This tests the null hypothesis that there is no relationship between the two variables, and rejecting the null hypothesis allows us to conclude that the variables have a statistically significant relationship with each other.\nSuppose that we’re interested in determining if there is a significant relationship between smoking status and lung cancer status. Our variables are:\n\nSmoking Status (1=Yes, 0=No) , and\nLung Cancer Status (1=Diagnosed, 2=Not Diagnosed).\n\nWe can summarize these variables in a 2x2 table called a crosstab where the cell values represent the counts in our data that fall in those particular categories. We can perform a Chi-square test to determine if there is a relationship between smoking and lung cancer.\nSelect Analyze -&gt; Descriptive Statistics -&gt; Crosstabs for the Chi-square test of independence and make sure to check the box “Chi-Square” under “Statistics”. You can produce a clustered bar chart to visualize this table by checking the box for “Display Clustered Bar Chart” in the “Crosstab” dialog box.\nTry it: Use section4_2_data.sav. Are females more likely to participate in jokes that are derogatory to any racial group? Investigate the data to see what types of variables we have to answer this question. We have the categorical variable “Sex” and the categorical variable “Joke”. Since we are comparing two categoricalvariables, we will use a Chi-square test.\n\nSelect Analyze -&gt; Descriptive Statistics -&gt; Crosstabs.\nSelect “Sex” for rows, “Joke” for columns, check the box to “Display clustered bar charts”.\nSelect “Statistics” and check the box for “Chi-Square”.\nSelect “Continue” and the select “OK”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe results above indicate that there is not a significant difference between how females and males answered the question “Would you participate in jokes that are derogatory to any racial group?” (p-value=0.397).\n\n\n4.9.3 Two-Sample T-Test and One-Way ANOVA\nThe purpose of the two-sample t-test, also known as the independent samples t-test, is to determine if mean values of a particular continuous variable are significantly different for two groups. The one-way analysis of variance (ANOVA) is mathematically equivalent to the two-sample t-test, and is appropriate when there are two or more groups.\nThere are 3 assumptions that must be met in order to perform these tests:\n\nNormality\nHomogeneity of variance for ANOVA\nIndependence of groups and observations\n\nYou can investigate normality with Q-Q plots or histograms and use Levene’s test to assess homogeneity of variance. You can also side-by-side box plots to investigate the relationship between a continuous dependent variable and a categorical predictor.\nIn SPSS, select Analyze -&gt; Compare Means to find the two-sample t-test and one-way ANOVA\n\n\n\n\n\n\n\n\n\n\nFor the side-by-side box plots, select Graphs -&gt; Legacy Dialogs -&gt; Boxplot, choose “Simple” and “Summaries for groups of cases”, and click “Define.” In the next dialog, move the continuous variable and the grouping variable from the left-hand list of variables to the “Variable” and “Category Axis” boxes.\n\n\n\n\n\n\n\n\n\n\nTry it: Use section4_2_data.sav. Is there a relationship between sex and the post intervention intension scale score? Sex is a categorical variable, the intension scale is continuous. We can use either an independent samples t-test or one-way ANOVA.\n\nSelect Analyze -&gt; Compare Means -&gt; Independent Samples T Test.\nSelect “BIndBehInt_Post” for TestVariable(s).\nSelect “Sex” for Grouping Variable.\nSelect “Define Groups…” and let group 1=1, group 2=2.\nSelect “Continue” and “OK”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe tables above indicate that the males and females have similar average intension scale scores (males=5.3, females=5.59). We fail to reject the null hypothesis for Levene’s test, so we will report the information for “Equal variances assumed”. Our p-value is .631, so we fail to reject the null hypothesis that males and females have similar average intention scale scores.\n\nSelect Analyze -&gt; Compare Means -&gt; One-Way ANOVA”.\nSelect “BIndBehInt_Post” for the dependent list.\nSelect “Sex” for the factor.\nSelect “OK”\n\n\n\n\n\n\n\n\n\n\n\nThe ANOVA table above yields the same p-value and conclusion as using the two-sample t-test.\n\nSelect Graphs -&gt; Legacy Dialogs -&gt; Boxplot.\nSelect “Simple” and “Summaries for groups of cases” and click “Define”.\nSelect the continuous dependent variable for “Variable” and the grouping variable for “Category Axis”.\nSelect “OK”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.9.4 Paired T-Test\nA paired t-test, also known as a repeated measures t-test or dependent samples t-test, is appropriate when there are two related observations (variables) and we want to determine if the average values of these variables differ from one another. The purpose of the paired t-test is to test the same units of observation under different treatment conditions to see if a treatment effect exists. The test compares the pre-treatment value to the post-treatment value for each case.\nThe null hypothesis is that the mean value of the differences for these two related variables is 0. If we reject this hypothesis, then we conclude that the difference is significantly different from 0. This test assumes that the sample mean of the differences is normally distributed. The test only considers cases with both pre-treatment and post-treatment values.\nIn SPSS, select Analyze -&gt; Compare Means -&gt; Paired Samples T-Test.\n\n\n\n\n\nTry it: Use section4_2_data.sav. Investigate whether or not the average intention scores are statistically different from each other. Since these variables are pre and post variables, it would be interesting to see if the intervention was successful in increasing the scores of participants. To investigate this, we will use a pairedt-test.\n\nSelect Analyze -&gt; Compare Means -&gt; Paired Samples T-Test.\nSelect “BIndBehInt_Pre” for Variable 1.\nSelect “BIndBehInt_Post” for Variable\nSelect “OK”.\n\n\n\n\n\n\n\n\n\n\n\nThe tables above indicate that there is a significant increase in average behavior intention score after the intervention (p-value&lt;.001)."
  },
  {
    "objectID": "04-stats.html#investigating-many-variables-at-a-time",
    "href": "04-stats.html#investigating-many-variables-at-a-time",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.10 Investigating Many Variables at a Time",
    "text": "4.10 Investigating Many Variables at a Time\nIt is often useful to investigate the relationship between one outcome variable and multiple predictor variables. The type of the outcome variable determines the appropriate model; general linear models are appropriate for continuous outcomes and generalized linear models are appropriate for categorical outcomes. General linear models include simple linear regression and multiple linear regression while generalized linear models include binary logistic regression and ordinal logistic regression. Linear regression and binary linear regression will be covered through EXERCISES in this workshop, time permitting."
  },
  {
    "objectID": "04-stats.html#repeated-measures-longitudinal-clustered-multilevel-mixed-procedures",
    "href": "04-stats.html#repeated-measures-longitudinal-clustered-multilevel-mixed-procedures",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.11 Repeated Measures, Longitudinal, Clustered, Multilevel, Mixed Procedures",
    "text": "4.11 Repeated Measures, Longitudinal, Clustered, Multilevel, Mixed Procedures\nIt is very common in many studies to take multiple measurements on a unit of analysis, typically a subject. These multiple measures may be occurring over time, conditions, regions, or the levels of any other variable. Depending on what the measurements are taking place over, there are many names we give these studies. It is also very common in many studies to have the units of analysis be clustered (i.e. grouped) into higher level clusters (i.e. groups). Sometimes the clusters themselves are further clustered into even higher level clusters, and so on.\nIn all of these studies, we must use more advanced statistical procedures that take into consideration the possible correlation of observations that are coming from the same unit of analysis. While using advanced procedures to analyze such data sets is beyond the scope of this workshop, you should be able to identify these multilevel data sets and discuss them with your statistician."
  },
  {
    "objectID": "04-stats.html#other-procedures-in-spss",
    "href": "04-stats.html#other-procedures-in-spss",
    "title": "4  Understanding Graphical & Statistical Procedures",
    "section": "4.12 Other Procedures in SPSS",
    "text": "4.12 Other Procedures in SPSS\nHere is a non-exhaustive list of other procedures in SPSS that you may use:\n\nTests for checking the assumptions of normality\nIntraclass correlation coefficient\nPartial correlations\nGeneral linear models\nGeneralized linear models\nCategorical data analysis\nRandomized clinical trials\nCase-control clinical trials\nMatching and propensity scores\nSurvival analysis\nCox regression\nTwo-stage least squares regression\nProbit regression\nCluster analysis\nDiscriminant analysis\nFactor analysis\nPrincipal components analysis\nReliability analysis\nPath analysis\nStructural equations modeling\nLatent class analysis\nMultidimensional scaling\nSpatial statistics\nTime series analysis\nComplex samples and survey methodology\nMissing data analysis and imputation\nGeographical information systems\nQualitative data analysis\nText mining\nReceiver operator characteristic (ROC) curve analysis\nFunctional data analysis\nData mining\nClassification and regression trees (CART)\nChi-square automatic interaction detection (CHAID)\nNeural networks"
  },
  {
    "objectID": "appendix.html#interpreting-interactions-in-a-regression-model-overview",
    "href": "appendix.html#interpreting-interactions-in-a-regression-model-overview",
    "title": "5  Appendix",
    "section": "5.1 Interpreting Interactions in a Regression Model Overview",
    "text": "5.1 Interpreting Interactions in a Regression Model Overview\n\n5.1.1 Two-Way Interactions\n\n5.1.1.1 General\nLet our regression model follow this form:\n\\[\nY = A + B + A*B\n\\]\nWhere Y represents our dependent/outcome variable and \\(A*B\\) represents the interaction between \\(A\\) and \\(B\\).\n\nThe regression coefficient for \\(A\\) shows the effect of \\(A\\) when \\(B=0\\).\nThe regression coefficient for \\(B\\) shows the effect of B when \\(A=0\\).\nThe regression coefficient for \\(A*B\\) demonstrates how \\(A\\) changes with a one unit increase in \\(B.\\) It also demonstrates how \\(B\\) changes with a one unit increase in \\(A\\).\n\n\n\n5.1.1.2 Two Categorical Variables\n\nLet \\(A\\) represent gender\n\n0=Female\n1=Male\n\nLet \\(B\\) represent treatment condition\n\n0=Control\n1=Experimental\n\nThe interaction regression coefficient shows whether the effect of treatment condition is different for males and females.\nThe regression coefficient for \\(A\\) shows the difference in \\(Y\\) between males and females for the ‘control’ treatment group.\nThe regression coefficient for \\(B\\) shows the difference in \\(Y\\) between treatment and control groups for females.\n\n\n\n5.1.1.3 One Categorical and One Continuous Variable\n\nLet \\(A\\) represent gender\n\n0=Female\n1=Male\n\nLet \\(B\\) represent a continuous variable: age in years.\nThe interaction regression coefficient shows if the effect of age on \\(Y\\) is different for males and females.\nThe regression coefficient for \\(A\\) shows the difference between males and females when age is equal to zero.\nThe regression coefficient for \\(B\\) shows the effect of age for females.\n\n\n\n5.1.1.4 Two Continuous Variables\n\nLet \\(A\\) represent a continuous variable: IQ score.\nLet \\(B\\) represent a continuous variable: Age.\nThe interaction regression coefficient shows\n\nif the relationship between age and \\(Y\\) differs according to IQ\nif the relationship between IQ and \\(Y\\) differs according to age.\n\nThe regression coefficient for \\(A\\) shows the relationship between IQ and \\(Y\\) when age equals zero.\nThe regression coefficient for \\(B\\) shows the relationship between age and \\(Y\\) when IQ equals zero.\n\n\n\n\n5.1.2 Three-Way Interactions\nThe same principles apply from above. The general model:\n\\[\n  Y = A + B + C + A*B + A*C + B*C + A*B*C\n\\]\n\nThe coefficient for \\(A\\) shows the effect of \\(A\\) on \\(Y\\) when both \\(B\\) and \\(C\\) are zero.\nThe coefficient for \\(B\\) shows the effect of \\(B\\) on \\(Y\\) when both \\(A\\) and \\(C\\) are zero.\nThe coefficient for \\(C\\) shows the effect of \\(C\\) on \\(Y\\) when both \\(A\\) and \\(B\\) are zero.\nThe coefficient for \\(A*B\\) shows the interaction between \\(A\\) and \\(B\\) when \\(C\\) is zero.\nThe coefficient for \\(A*C\\) shows the interaction between \\(A\\) and \\(C\\) when \\(B\\) is zero.\nThe coefficient for \\(B*C\\) shows the interaction between \\(B\\) and \\(C\\) when \\(A\\) is zero.\nThe interaction regression coefficient shows if the relationship between\n\n\\(A\\) and \\(Y\\) differs according to \\(B\\) and \\(C\\)\n\\(B\\) and \\(Y\\) differs according to \\(A\\) and \\(C\\)\n\\(C\\) and \\(Y\\) differs according to \\(A\\) and \\(B\\)."
  },
  {
    "objectID": "appendix.html#exercise-solutions",
    "href": "appendix.html#exercise-solutions",
    "title": "5  Appendix",
    "section": "5.2 Exercise Solutions",
    "text": "5.2 Exercise Solutions\n\n5.2.1 Exercise 1\nIn order to analyze data properly in SPSS, we need to follow the guidelines set out above. Open exercise1_data.sav and see what guidelines we have ignored.\n\n5.2.1.1 Exercise 1 Solution\n\n\n\n\n\nToo much information is contained in one variable (CTSSurgTypeCatCodeDesc, LOS, SURGLOS, DCDate, etc.)\nErrors can easily be found by sorting (errors in Year, AGE)\nThe same content is entered in differently for a single variable (SEX, HTN, SMOKING)\nAnything else?\n\n\n\n5.2.2 Exercise 2\nOpen exercise2_data.sav (an Excel file). Modify this Excel file such that it can be imported into SPSS properly. Save the file and close it.\nOpen the file in SPSS (import it). Export this file back into Excel, but only save the following variables: id, salary, minority.\n\n5.2.2.1 Exercise 2 Solution\n\n\n\n\n\n\nDelete the first three rows of data (remove heading)\nRemove rows 23 and 24 (contains summary information)\nRemove the formatting (fill color)\nSave the file as Exercise2_Data_Ready\n\n\n\n\n\n\n\nClose Exercise2_Data_Ready\nOpen SPSS\nSelect File -&gt; Open -&gt; Data\nUnder “Files of Type” select either “All Files” or “Excel” to view Exercise2_Data_Ready, select the file, then select “Open”\n\n\n\n\n\n\n\nA window appears\nCheck the box so the variable names will be imported\nSelect the sheet of the Excel file that you would like to be read in, then select “Ok”\n\n\n\n\n\n\n\nThe Excel data should now open in the Data Editor\nDelete any “blank” rows of data or columns of data (indicated by .) by highlighting, right click, select “cut”\n\n\n\n\n\n\n\nSelect File -&gt; Save As\nLet the file name be Exercise2_Data_Ready_short\nChange the file type to Excel 97 through 2003 (*.xls)\nSelect the “Variables…” button\nSelect the “Drop All” button\nUnder the “Keep” column, check the box for id, salary, minority\nSelect “Continue”\n\n\n\n\n\n\n\nSelect “Save”\nOpen the new file (Exercise2_Data_Ready_short) to investigate the results\n\n\n\n\n5.2.3 Exercise 3\nOpen exercise3_data.sav and go to Variable View. Practice defining the correct attributes to each variable by following the code book.\n\n\n\n\n\n\n\n\n\n\nName\nLabel\nValue Label\nMissing Values\nMeasure\n\n\n\n\nIDnum\n\n\n\nScale\n\n\nsex\nRespondent’s Sex\n1 = Male\n\nNominal\n\n\n\n\n2 = Female\n\n\n\n\nrace\nRace of Respondent\n1 = White\n\nNominal\n\n\n\n\n2 = Black\n\n\n\n\n\n\n3 = Other\n\n\n\n\nregion\nRegion of the United States\n1 = North East\n\nNominal\n\n\n\n\n2 = South East\n\n\n\n\n\n\n3 = West\n\n\n\n\nhappy\nGeneral Happiness\n0 = NAP\n0, 8, 9\nOrdinal\n\n\n\n\n1 = Very Happy\n\n\n\n\n\n\n2 = Pretty Happy\n\n\n\n\n\n\n3 = Not too Happy\n\n\n\n\n\n\n8 = DK\n\n\n\n\n\n\n9 = NA\n\n\n\n\nlife\nIs Life Exciting or Dull\n0 = NAP\n0, 8, 9\nOrdinal\n\n\n\n\n1 = Exciting\n\n\n\n\n\n\n2 = Routine\n\n\n\n\n\n\n3 = Dull\n\n\n\n\n\n\n8 = DK\n\n\n\n\n\n\n9 = NA\n\n\n\n\nsibs\nNumber of Brothers and Sisters\n98 = DK\n98, 99\nScale\n\n\n\n\n99 = NA\n\n\n\n\nchilds\nNumber of Children\n8 = Eight or More\n9\nScale\n\n\n\n\n9 = NA\n\n\n\n\nage\nAge of Respondent\n98 = DK\n0, 98, 99\nScale\n\n\n\n\n99 = NA\n\n\n\n\neduc\nHighest Year of School Completed\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\npaeduc\nHighest Year School, Father\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\nmaeduc\nHighest Year School, Mother\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\nseeduc\nHighest Year School, Spouse\n97 = NAP\n97, 98, 99\nScale\n\n\n\n\n98 = DK\n\n\n\n\n\n\n99 = NA\n\n\n\n\nprestg80\nOccupational Prestige Score\n0 = DK,NA,NAP\n0\nScale\n\n\nocccat80\nOccupational Category\n1 = Managerial and Professional\n\nNominal\n\n\n\n\n2 = Technical and Sales\n\n\n\n\n\n\n3 = Service\n\n\n\n\n\n\n4 = Farming, Forest, and Fishing\n\n\n\n\n\n\n5 = Production and Craft\n\n\n\n\n\n\n6 = General Labor\n\n\n\n\n\n\n5.2.3.1 Exercise 3 Solution\n\nIn Variable View, the first four columns do not need to be modified\nTo modify the variable label, click in the cell that you wish to edit and start tying in the label\nTo modify the value labels, click the cell that you wish to edit and then select the box with three small dots. The following window will appear:\n\n\n\n\n\n\n\nEnter the value and label, then select “Add”. Once all possible value labels are added, select “OK”\nWhen value labels (or other attributes such as label or missing) repeat for a variable, you can copy and paste the attribute values. Right click on the cell you want to copy, select copy. Then right click on the cell that you would like to paste in, and select paste.\n\n\n\n\n\n\n\nEnter in missing values in a similar fashion—here we have discrete missing values\nUse the drop down menu for “Measure” to specify the correct measurement type\n\n\n\n\n\n\n\n\n\n5.2.4 Exercise 4\nOpen exercise4_data.sav.\nCompute a new variable that is the change from beginning salary to current salary for each employee.\nRecode the education variable into a new variable according to the following\n\n1=High School or Less (educ&lt;=12)\n2=Some College (12&lt;educ&lt;=16)\n3=Bachelor’s Degree or Higher (educ&gt;=17)\n\n\n5.2.4.1 Exercise 4 Solution\nCompute a new variable that is the change from beginning salary to current salary for each employee.\n\nTransform -&gt; Compute Variable\nSelect “Reset”\nEnter the following information\nTarget Variable: salchange\nDouble click (or use the arrow) to move salary to the Numeric Expression window\nUse the calculator box below the numeric expression box to enter a minus sign (alternatively, you could type a minus sign) then select salbegin\nSelect OK, and the new variable will appear in the data set\n\n\n\n\n\n\nRecode the education variable into a new variable according to the following\n\n1=High School or Less (educ&lt;=12)\n2=Some College (12&lt;educ&lt;=16)\n3=Bachelor’s Degree or Higher (educ&gt;=17)\n\n\n\nTransform -&gt; Recode into different variables\nMove education (educ) into the Input Variable Output Variable window by double clicking on it or using the arrow\nName: EducRecode\nLabel: Leave Blank\nClick the change button\nUnder old value, select the radio dial for Range, LOWEST through value: enter 12\nUnder new value, select the radio dial for Value: enter 1\nSelect Add\nUnder old value, select the radio dial for Range: enter 13 through 15\nUnder new value, select the radio dial for Value: enter 2\nSelect Add\nUnder old value, select the radio dial for Range, value through HIGHEST: enter 16\nUnder new value, select the radio dial for Value: enter 3\nSelect Add\nSelect Continue\nSelect OK\nCheck the dataset in Data View\n\n\n\n\n\n\n\n\n\n5.2.5 Exercise 5\nOpen exercise5_data.sav.\nSelect male managers. What is their average age?\n(You can obtain the average age by choosing Analyze -&gt; Descriptive Statistics -&gt; Descriptives and moving “Age of Respondent (age)” to the right hand side.)\nUse the “Split File” procedure to get the average age for each job category.\n\n5.2.5.1 Exercise 5 Solution\nSelect male managers. What is their average age?\n\nCheck Values for sex and occat80 to see what values correspond to “male” and “manager” (it’s 1 and 1).\nData -&gt; Select Cases\nUnder Select: Select the If Condition is Satisfied radio dial and select the If button\n\n\n\n\n\n\n\nEnter the following information\n\nOpen box should read as follows: sex=1 & occcat80=1\nContinue\n\n\n\n\n\n\n\n\nUnder Output: Select Filter Out Unselected Cases\nSelect OK\nInspect the data in Data View\nAnalyze -&gt; Descriptive Statistics -&gt; Descriptives\n\n\n\n\n\n\n\nSelect the age variable, select OK\nTurn off the filter!\n\n\n\n\n\n\nUse the “Split File” procedure to get the average age for each job category.\n\nData -&gt; Split File\nSelect Compare Groups\nSelect occat80 (Occupational Category) and move it into the Groups Based On window by double clicking (or using the arrow)\nSelect Sort the File by Grouping Variables\nSelect Ok\n\n\n\n\n\n\n\nAnalyze -&gt; Descriptive Statistics -&gt; Descriptives\nSelect the age variable and OK\n\n\n\n\n\n\n\nTurn off the split file!\n\n\n\n\n\n\n\n\n\n5.2.6 Exercise 6\nConvert exercise6_data from “Wide” format to “Long” format\n\n5.2.6.1 Exercise 6 Solution\n\nOpen exercise6_data.sav\nSelect Data -&gt; Restructure to open the Wizard\nSelect “Restructure selected variables into cases” then “Next”\n\n\n\n\n\n\n\nHow many variable groups to you want to restructure? Select “One” then “Next”\n\n\n\n\n\n\n\nCase Group Identification should be changed to “Use selected variable” and the variable should be the ID variable\nVariables to be transposed: Move the X variables over (X1, X2, X3)\nFixed Variable(s): Move Group and Age over\nSelect “Next”\n\n\n\n\n\n\n\nHow many index variables do you want to create? Select “one” then “Next”\n\n\n\n\n\n\n\nWhat kind of index values? Select “Sequential Numbers” then select “Next”\n\n\n\n\n\n\n\nHandling of Variables not Selected: Select “Keep and treat as fixed variable(s)”\nSystem Missing or Blank Values in All Transposed Variables: Select “Create a case in the new file”\nLeave “Case Count Variable” unchecked\nSelect “Next”\n\n\n\n\n\n\n\nWhat do you want to do? Select “Restructure the data now”. In the future you may want to keep the syntax.\nSelect “Finish”\nThe following message appears, click “OK”\n\n\n\n\n\n\n\nInspect the data (and change “trans1” to “X”)\n\n\n\n\n\n\n\n\n\n5.2.7 Exercise 7\nConvert exercise7_data from “Long” format to “Wide” format\n\n5.2.7.1 Exercise 7 Solution\n\nOpen exercise7_data.sav\nSelect Data -&gt; Restructure to open the Wizard\n\n\n\n\n\n\n\nIdentifier Variable(s): ID\nIndex Variable(s): Index1\nSelect “Next”\n\n\n\n\n\n\n\nSort the current data? Yes\nSelect “Next”\n\n\n\n\n\n\n\nOrder of New Variable Groups: Group by original variable\nLeave the other options unchecked\nSelect “Next”\n\n\n\n\n\n\n\nSelect “Restructure the Data Now” and “Finish”\n\n\n\n\n\n\n\nThe following message will appear, select “OK”. Inspect the data and save!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.8 Exercise 8\nOpen exercise8_data.sav\nPart 1: Investigate the variable attributes. Determine which variables are categorical variables (nominal and ordinal), and which variables are continuous (scale).\nObtain the appropriate descriptive statistics for each variable. Remember, continuous variables should be investigated with Descriptives and categorical variables should be investigated with frequency tables.\nHint: Select more than one variable in the Analyze -&gt; Descriptive Statistics -&gt; Descriptives”, or Analyze -&gt; Descriptive Statistics -&gt; Frequencies dialog boxes.\nPart 2: Assess the distribution of the Occupational Prestige Score (“prestg80”) with both a histogram (normal curve displayed) and a Q-Q plot. Is the assumption that the population of Occupational Prestige Scores is normally distributed reasonable?\nPart 3: Compare the average highest year of school completed (“educ”) for males and females.\nHint: First split the file by “sex” (Data -&gt; Split File), then calculate the descriptive statistics. Be sure to return to the Split File menu when you are done with this question and return the dialog box to “Analyze all cases”.\nPart 4: Produce a pie chart for the variable “region”. (We didn’t cover this, you can use either Chart Builder or Legacy Dialogs.)\n\n5.2.8.1 Exercise 8 Solution\nOpen the dataset exercise8_data.sav\nPart 1\nInvestigate the variable attributes. Determine which variables are categorical variables (nominal and ordinal), and which variables are continuous (scale).\n\nSelect the “Variable View” tab\nInvestigate the labels and measure of each variable\n\n\n\n\n\n\nObtain the appropriate descriptive statistics for each variable in the dataset. Remember, continuous variables should be investigated with 5-point summary descriptives and categorical variables should be investigated with frequency tables.\n\nSelect Analyze -&gt; Descriptive Statistics -&gt; Descriptives\nSelect the following variables: sibs, childs, age, educ, paeduc, maeduc, speduc, prestg80\n\n\n\n\n\n\n\nSelect “OK”\nNotice there are only 519 respondents that have valid data points for all of the continuous variables.\n\n\n\n\n\n\nFrequency Tables:\n\nSelect Analyze -&gt; Descriptive Statistics -&gt; Frequencies\nSelect the following variables: sex, region, race, happy, life, occcat80\n\n\n\n\n\n\n\nInvestigate the output\n\nPart 2: Assess the distribution of the Occupational Prestige Score (“prestg80”) with both a histogram (normal curve displayed) and a Q-Q plot. Is the assumption that the population of Occupational Prestige Scores is normally distributed reasonable?\n\nHistogram in Legacy Dialogs\nSelect Graphs -&gt; Legacy Dialogs -&gt; Histogram\nVariable: prestg80\nCheck box to display normal curve\nSelect OK\n\n\n\n\n\n\nInvestigate the output\n\n\n\n\n\n\nQ-Q Plot\nSelect Analyze -&gt; Descriptive Statistics -&gt; Q-Q Plots\nSelect the variable prestg80\nSelect OK\n\n\n\n\n\n\n\nInvestigate the output\nLook to see how well the plotted points follow the solid diagonal line\nIt is particularly important to pay attention to the “tails”, or the left most and right most points to see if they follow the line\n\n\n\n\n\n\nPart 3: Compare the average highest year of school completed (“educ”) for males and females.\n\nSet up the dataset such that the output is split by groups based on sex\nSelect Data -&gt; Split File\nSelect “Compare Groups”\nSelect the variable sex for “Groups Based on:”\nSelect “OK”\n\n\n\n\n\n\n\nCompute the 5-Point Summary Descriptives for “educ”\nSelect Analyze -&gt; Descriptive Statistics -&gt; Descriptives\nSelect the variable “educ”\nSelect “OK”\n\n\n\n\n\n\n\nInvestigate the output\nMales have an average of 13.23 years of education\nFemales have an average of 12.63 years of education\n\n\n\n\n\n\n\nTurn the split file feature off\nSelect Data -&gt; Split File\nSelect “Analyze all cases, do not create groups” (Alternatively, “Reset” can be selected)\nSelect “OK”\n\nPart 4: Produce a pie chart for the variable “region”. Use “Legacy Dialogs”.\n\nSelect Graphs -&gt; Legacy Dialogs -&gt; Pie\nUnder “Data in Chart Are” select “Summaries for groups of cases”\nSelect “Define”\n\n\n\n\n\n\n\nSelect the variable “region” for “Define Slices by:”\nThe default for “Slices Represent” is “N of cases”, and leave this at the default\nSelect “OK”\n\n\n\n\n\n\n\nInvestigate the output"
  },
  {
    "objectID": "appendix.html#additional-exercises",
    "href": "appendix.html#additional-exercises",
    "title": "5  Appendix",
    "section": "5.3 Additional Exercises",
    "text": "5.3 Additional Exercises\n\n5.3.1 Exercise A1 – Categorical Data Analysis\nQuestion 1\nOpen exercisea1_data. What percent of respondents said they were “Very Happy”? What about “Not too happy”? “Pretty happy”? Use a graph to display the variable.\nQuestion 2\nDo women appear to be more or less happy than men? Would you say this apparent relationship is statistically significant?\nQuestion 3\nCreate a scatter plot of respondent’s education vs. their spouses’ education. Does this relationship appear to be linear? Add a linear regression line to the plot. Inspect the correlation between the respondent’s education and their spouses’ education. Is this correlation positive or negative? Is it statistically significant.\n\n\n5.3.2 Exercise A1 Solution\nQuestion 1\nOpen exercisea1_data. What percent of respondents said they were “Very Happy”? What about “Not too happy”? “Pretty happy”? Use a graph to display the variable.\nSolution: \n\nWe have one categorical variable that we would like to investigate…check the all on one page handout!\nAnalyze -&gt; Descriptive Statistics -&gt; Frequencies\n\n\n\n\n\n\n\nEnter the following information\n\nSelect happy\nSelect Charts\n\nUnder Chart Type, select Bar Chart\nUnder Chart Values, select Percentages\nSelect Continue\n\nSelect the box for Display Frequency Tables\nSelect OK\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2\nDo women appear to be more or less happy than men? Would you say this apparent relationship is statistically significant?\nSolution: \n\nWe are going to compare two categorical variables. From out handout, we will use Pearson Chi-Square crosstabs to do this!\nAnalyze -&gt; Descriptive Statistics -&gt; Crosstabs\n\n\n\nEnter the following information\n\nRows: sex\nColumns: happy\n\n\n\n\n\n\n\n\nSelect the Statistics button\n\nCheck the box for Chi-Square\nSelect Continue\n\n\n\n\n\n\n\n\nSelect the Cells button\n\nCheck the box for Row under Percentages (leave the rest as default)\nCheck the box for Adjusted Standardized Residuals under Residuals (leave the rest as default)\nSelect Continue\n\nSelect the box for Display Clustered Bar Charts\nSelect OK\n\n\n\n\n\n\n\nThe Pearson Chi-Square statistic indicates that the differences between men and women are statistically significant (pvalue/asymptotic significance&lt;.05).\nThe residuals, clustered bar chart, and row percentages can tell us where these differences arise\n\nAn adjusted standardized residual (absolute value) greater than two shows us where the differences between groups occur. Here, we see that “not too happy” for males and females has a residual greater than 2.\nThe row proportions indicate that there is a higher proportion of females that responded “not too happy” when compared to males.\nThe clustered bar chart also shows that there are greater numbers of women that indicate that they are “not too happy”.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\nCreate a scatter plot of respondent’s education vs. their spouses’ education. Does this relationship appear to be linear? Add a linear regression line to the plot. Inspect the correlation between the respondent’s education and their spouses’ education. Is this correlation positive or negative? Is it statistically significant.\nSolution:\n\nGraphs -&gt; Legacy Dialogues -&gt; Scatter/Dot\nSimple Scatter and Define\nEnter the following information\n\nY Axis: speduc\nX Axis: educ\nSelect OK\n\nCheck the output for the scatter plot\nDouble click the plot in the Output Viewer to open Chart Editor\nSelect the button for Add Fit Line at Total (first bar above the plot, axis with straight line plot)\nSelect Linear Fit, Apply, Close\nClose out of chart editor (red X in the upper right corner) and the updated chart will appear in the Output Viewer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyze -&gt; Correlate -&gt; Bivariate\nEnter the following information\n\nVariables: educ, speduc\nCorrelation coefficients: Pearson, Spearman\nSignificance: Two Tailed\nCheck the box for Flag significant correlations\nSelect OK\n\nThe output indicates that the correlation between education and spouses’ education is positive and statistically significant.\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.3 Exercise A2 – Continuous Data Analysis\nOpen exercisea2_data.sav.\nResearch Question 1: Is there a relationship between a student’s socio-economic status and whether or not the student would participate in a racially insensitive joke?\nWhat techniques would you use to investigate the relationship between SES and whether or not a student would participate in a racially insensitive joke?\nInvestigate this relationship graphically and statistically. What did you find?\nResearch Question 2: Is there a relationship between a student’s race and their post intervention behavior intention scale?\nWhat techniques would you use to investigate a student’s race and their post intervention behavior intention scale?\nInvestigate this relationship graphically and statistically. What did you find?\nResearch Question 3: Is there a relationship between the race of a student and their socio-economic status?\nWhat techniques would you use to investigate the relationship between race and SES?\nInvestigate this relationship graphically and statistically. What did you find?\n\n\n5.3.4 Exercise A2 Solution\nResearch Question 1: Is there a relationship between a student’s socio-economic status and whether or not the student would participate in a racially insensitive joke?\nWhat techniques would you use to investigate the relationship between SES and whether or not a student would participate in a racially insensitive joke?\nANSWER: SES is an ordinal variable with 4 levels that should be treated as a categorical variable. Whether or not a student would participate in a derogatory joke is measured with the “Joke” variable and it is a categorical variable. The appropriate statistical procedure to use to compare two categorical variables is the Chi-Square Test of Independence (crosstabs). The appropriate graphical procedure is a clustered bar chart.\nInvestigate this relationship graphically and statistically. What did you find?\nANSWER: There is not a statistically significant relationship between “SES” and “Joke”. We do not have enough evidence to say that there is a relationship between a student’s socio-economic status and whether or not the student would participate in a racially insensitive joke.\n\n\n\n\n\n\n\n\n\n\nResearch Question 2: Is there a relationship between a student’s race and their post intervention behavior intention scale? What techniques would you use to investigate a student’s race and their post intervention behavior intention scale?\nANSWER: “Race” is a categorical variable that can take on up to 9 values and a student’s post intervention behavior intention scale (“BIndBehint_post”) is a continuous variable. The appropriate statistical procedure is a one-way ANOVA. The appropriate graphical procedure is a side-by-side box plot.\nInvestigate this relationship graphically and statistically. What did you find?\nANSWER: There is not a statistically significant relationship between “Race” and “BIndBehint_Post”. We do not have enough evidence to say that there is a relationship between a student’s race and their post intervention behavior intention score.\n\n\n\n\n\n\n\n\n\n\nResearch Question 3: Is there a relationship between the race of a student and their socio-economic status? What techniques would you use to investigate the relationship between race and SES?\nANSWER: “Race” and “SES” are both categorical predictors. The appropriate statistical procedure to use to compare two categorical variables is the Chi-Square Test of Independence (crosstabs). The appropriate graphical procedure is a clustered bar chart.\nInvestigate this relationship graphically and statistically. What did you find?\nANSWER: There is a statistically significant relationship between “Race” and “SES”. There is a significant relationship between a student’s SES and race. Notice the error message under the Chi-Square results table—in this case, we need to verify our statistically significant results with Fisher’s Exact Test (pvalue=.025).\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.5 Exercise A3 – Methodology Choice Practice\nIn the below questions first determine what the appropriate analysis method is based on the variables of interest and carry out these methods within SPSS.\nA) From exercisea3_data_a.sav\n\nIs there a relationship between sex (gender) and job category (jobcat)?\nIs there a relationship between job category (jobcat) and minority status (minority)?\nIs there a relationship between job category (jobcat) and salary (salary)?\nIs there a relationship between experience (jobtime) and salary (salary)?\n\nB) From exercisea3_data_b.sav\n\nIs there a relationship between general happiness (happy) and occupational prestige score (prestg80)?\nIs there a relationship between age (age) and occupational prestige score (prestg80)?\nIs there a relationship between general happiness (happy) and perception of life being exciting or dull (life)?\n\nExercise A3 Hints!\nA)\n\nTwo Categorical VariablesClustered Bar Charts, Pearson Chi-Square Crosstabs\nTwo Categorical VariablesClustered Bar Charts, Pearson Chi-Square Crosstabs\nCategorical DV (3+Groups) & Continuous DVOne Way ANOVA, Side-by-Side Boxplot\nTwo Continuous VariablesPearson Correlation Coefficient, Scatterplot\n\nB)\n\nCategorical DV (3+Groups) & Continuous DVOne Way ANOVA, Side-by-Side Boxplot\nTwo Continuous VariablesPearson Correlation Coefficient, Scatterplot\nTwo Categorical VariablesClustered Bar Charts, Pearson Chi-Square Crosstabs\n\n\n\n5.3.6 Exercise A4 – Case Study I: Salary (Regression)\nOpen exercisea4_data.\nBackground\nThis data set contains information on faculty from Bowling Green State University for the 1993 to 1994 (DeMaris 2004). The purpose of the exercises below is to investigate whether there was any evidence of gender inequality in faculty salaries at BGSU.\nActivity 1: Describing the Dataset\nInvestigate the ‘Faculty’ data set using descriptive statistics, one variable graphing procedures, and bivariate procedures.\nInvestigate ‘Salary’ with descriptive statistics, box plot, and histogram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigate ‘Gender’ with a frequency table and bar chart\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigate the average salary for males and females separately (descriptive statistics, histogram, side-by-side box plot)\nRemember to split the file by the gender variable (‘male’).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe descriptive statistics table above indicates that males earn more than females on average.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlso remember to remove the ‘Split File’ option.\n\n\n\n\n\n\n\n\n\n\nThe Boxplot below indicates that males have a higher median salary than females, and both males and females have outliers (observation 148 and 58 respectively).\n\n\n\n\n\nPerform an independent samples t-test \nRemember that the dialogue box for the independent samples t-test is located under ‘Analyze’ then ‘Compare Means’.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe table above indicates that we cannot assume equal variances between males and females (Levene’s Test pvalue&lt;.05). Regardless, we see that the differences between average male and female salaries are large enough to be considered statistically significant (t=10.250, df=297.227, pvalue&lt;.001). The confidence interval for the mean difference between genders is [8550.79, 12614.47]. This is the plausible range of values for the difference between males and females.\nActivity 2: Simple Linear Regression\nThe independent samples t-test is one way to model the relationship between the faculty salary (dependent variable of interest) and gender (independent variable). Faculty salary may also be a function of the marketability of the discipline the faculty member is in.\nInvestigate the correlation between ‘salary’ and ‘market’ and investigate a scatter plot of the two variables\nIn SPSS, select Analyze -&gt; Correlate -&gt; Bivariate\n\n\n\n\n\n\n\n\n\n\nWe see from the table above that there is a statistically significant correlation between faculty salary and marketability of the discipline (r=.407, pvalue&lt;.001).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerform a simple linear regression where ‘salary’ is the dependent/outcome variable and ‘market’ is the independent/predictor variable\nThis can be done multiple ways in SPSS. The first way uses the regression menu from ‘Analyze’ while the second uses the ‘General Linear Model’ menu.\nSelect Analyze -&gt; Regression -&gt; Linear\n\n\n\n\n\n\n\n\n\n\nNotice that the regression menu provides the correlation between the variables included in the model.\nThe table below provides the R Square value and adjusted R Square value. The proportion of variance in faculty salary explained by marketability of discipline is 16.6%.\nThe table below indicates that the model fitted is significantly better than what we would expect by chance (F=101.771, pvalue&lt;.001). The null hypothesis is that there is no linear relationship between faculty salary and marketability, and we reject this hypothesis.\n\n\n\n\n\n\n\n\n\n\nThe table above provides the parameter estimates for our model. For every one unit increase in marketability, faculty salary increases by an average of $34,545. We could also interpret the beta coefficient for marketability the following way: the effect of a .1 point increase in marketability is associated with an estimated increase in mean salary of $3,454. The constant (intercept) for the model is interpreted as the estimated mean salary when marketability is equal to zero.\nRemember that the confidence intervals give us a range of reasonable values for an estimate. The 95% confidence interval for our estimate of market discipline is [$27817, $41272].\nThe hypothesis tests provided with the ‘t’ statistic and ‘Sig.’ columns help us decide if a particular value (usually zero) is a reasonable estimate. If our estimated beta coefficient for market discipline was zero, then market discipline would not have an effect/relationship with faculty salary. This is our null hypothesis, and we would like to reject this hypothesis. Here we find a significant relationship between market discipline and faculty salary (t=10.088, pvalue&lt;.001).\nThe second method for generating results for a simple linear regression is described below. Keep in mind that this method for performing a linear regression is preferred when there are categorical predictor/independent variables or interaction terms between independent variables.\nSelect Analyze -&gt; General Linear Model -&gt; Univariate\n\n\n\n\n\n\n\n\n\n\nThe table below provides the descriptive statistics for faculty salary.\n\n\n\n\n\nThe table above indicates that the overall regression model is significant (F=101.771, pvalue&lt;.001). This is indicated by the line for ‘Corrected Model’. The R Squared value is also listed in footnote a. for the table.\nThe parameter estimates table above provides the same information as the previous coefficients table.\nNotice that the results are the same between the two methods that can be used in SPSS to perform a regression. For the remainder of the workshop we will use the second method to obtain our regression results (Analyze -&gt; General Linear Model -&gt; Univariate).\nActivity 3: Simple Linear Regression Diagnostics\nPerform the necessary regression diagnostics for the regression from exercise 2.\n\n\n\n\n\n\n\n\n\n\nCheck the linearity and homogeneity of variance assumptions\nPlot the residuals against the predicted values from the model. The residuals should be randomly scattered around zero, and the variability should be constant in the plot.\n\n\n\n\n\n\n\n\n\n\nThe scatter plot below does not indicate that either assumption has been violated.\n\n\n\n\n\nCheck for influential points\nThe scatter plot from exercise 2 did not indicate that there were points of interest.\n\n\n\n\n\nA leverage point is an unusual point that has the potential to influence the fit of the model. Sort the data set by Leverage in descending order. A rule of thumb is a point is considered to have large leverage when the leverage value is greater than 2p/n where p equals the number of parameters in the model. Here we estimate the intercept and slope for market, so p=2. This means that high leverage values are greater than 2*2/514=4/514=.0078. There are 53 points with high leverage.\n\n\n\n\n\nAn influential point is one whose removal from the dataset would cause a large change in the fit of the regression model. An influential point may or may not be an outlier. Also, and influential point may or may not have large leverage. Usually an influential point will be an outlier and or may have large leverage. Sort the data set by the Cook’s distance variable in descending order. This will list the observations with the largest Cook’s distance first. Remember a distance greater than 1 or 4/n=4/514=.0078 is considered large. The first 16 observations have large Cook’s distances, but we do not have cause to remove them from the data set.\n\n\n\n\n\nCheck the normality assumption for the residuals\n\n\n\n\n\nThe plot below indicates that the normality assumption is reasonable.\n\n\n\n\n\nA QQ-plot can also be investigated (Analyze -&gt; Descriptive Statistics -&gt; QQ Plot)\n\n\n\n\n\n\n\n\n\n\nActivity 4: Multiple Regression with a Categorical Predictor\nFaculty salary appears to be a function of the marketability of the discipline the faculty member is in, but it also may be a function of gender.\nCreate a multiple regression model where salary is the dependent variable, and both marketability and gender are the predictors. \nSelect Analyze -&gt; General Linear Model -&gt; Univariate\nSelect ‘salary’ as the dependent variable, male as the fixed factor, and market as the covariate. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’.\n\n\n\n\n\nUnder ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’\n\n\n\n\n\nThe table below indicates the number of Males and Females in the data set, along with the code that denotes the genders.\n\n\n\n\n\nThe table above indicates that the average salary for males is greater than the average salary for females ($53,499.24 compared to $42,916.60).\nThe table above indicates that the model fitted is significantly better than what we would expect by chance (F=85.799, pvalue&lt;.001). The null hypothesis is that there is no linear relationship between faculty salary and the model predictors, and we reject this hypothesis. This is indicated by the line for ‘Corrected Model’. The R Squared value is also listed in footnote a. for the table. The proportion of variance in faculty salary explained jointly by marketability of discipline and gender is 25.1%. Notice that this is an increase from the previous model.\n\n\n\n\n\nThe table above provides the parameter estimates for the regression model. The difference in population mean salaries between men and women, when controlling for marketability is estimated to be $8,708.42.\nRemember that Dummy variables are always interpreted in relationship to the reference category. The reference category is denoted with a coefficient value of 0 and footnote a. Here, we interpret male=0 (Female) compared to male=1 (Males). Another interpretation of the gender variable: When controlling for marketability, faculty salaries are on average $8,708.42 less for females when compared to males.\nThe marketability coefficient now is interpreted as the effect of marketability after accounting gender. For every one unit increase in marketability, faculty salary increases by an average of $29,972.60 holding gender constant. We could also interpret the beta coefficient for marketability the following way: the effect of a .1 point increase in marketability is associated with an estimated increase in mean salary of $2,997 holding gender constant.\nNotice that all of the predictor variables in the model are highly significant.\nNote that the model fit above is also sometimes referred to as an analysis of covariance (ANCOVA) model. The inclusion of a continuous predictor (marketability) in addition to the factor gender makes this an ANCOVA model.\nCreate a multiple regression model where salary is the dependent variable, and marketability, time since degree (yearsdg), and gender are the predictors. Investigate the coefficients and R-squared. \nFirst investigate a scatter plot between salary and time since degree.\n\n\n\n\n\nSelect Analyze -&gt; General Linear Model -&gt; Univariate\nSelect ‘salary’ as the dependent variable, male as the fixed factor, and market and yearsdg as the covariates. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’.\n\n\n\n\n\nUnder ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’\n\n\n\n\n\nThe table below indicates that the R-squared value has increased from the last model to .684, and the model is significant (F=367.562, pvalue&lt;.001).\n\n\n\n\n\nThe estimated population mean salary for women is $2,040.21 less than men for a given marketability and time since degree. The estimated effect of time since degree is $949 more in mean salary per year (*a one unit increase is a year!) since degree when comparing faculty members of the same gender from disciplines with the same marketability. For a given time since degree and gender, a one unit increase in marketability is estimated to increase average salary by $38,402.\nNotice that all of the predictor variables in the model are highly significant.\n\n\n\n\n\nActivity 5: Multiple Regression with an Interaction\nFaculty salary appears to be a function of the marketability of the discipline, time since last degree, and gender. Starting salaries could be similar for men and women, but men might receive larger increases over time. An interaction between gender and time since last degree may capture this relationship. Remember, a significant interaction implies that the effect of each variable depends on the value of the other variable—that is to say the effect of time since degree depends on gender and the effect of gender depends on time since degree.\nCreate a multiple regression model where salary is the dependent variable, marketability, gender, time since degree, and the interaction between gender and time since degree are the predictors. \nCreate a scatter plot: Select Graphs -&gt; Legacy Dialogs -&gt; Scatter/Dot and choose ‘Simple’ and ‘Define’. Let the y-axis be ‘salary’, the x-axis be ‘yearsdg’, and set markers by ‘male’. Select the graph in chart editor and click the box for ‘Add fit line at subgroups’. The lines for males and females are not parallel, and this is what we are investigating with the proposed interaction term.\n\n\n\n\n\nSelect Analyze -&gt; General Linear Model -&gt; Univariate\n\n\n\n\n\nSelect ‘salary’ as the dependent variable, ‘male’ as the fixed factor, and ‘market’ and ‘yearsdg’ as the covariates. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’.\nUnder ‘Model’, select ‘Custom’. Under ‘Build Terms’ select ‘Main Effect’ and enter the variables male, market, yearsdg. Under ‘Build Terms’ select ‘Interaction’ and select both male and yearsdg to create the interaction term. Select ‘Continue’. Remember that main effects must always be included in a model that contains interaction terms.\n\n\n\n\n\nUnder ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’\n\n\n\n\n\nThe table below indicates that the model is significant (F=279.95, pvalue&lt;.001) and the R-squared has increased from the last model to .688.\n\n\n\n\n\nIn the presence of interaction terms, the main effect terms have different interpretations. The estimated gender gap when time since degree is zero is not significant. When time since degree is 0 years, the population mean salary for women after adjusting for the other covariates in the model is estimated to be $593 more than men. Notice the confidence intervals range from negative values (women earn less at time since degree=0) to positive values (women earn more at time since degree=0).\nThe interaction between gender and years since degree (the change in gender gap with years since degree) is significant. For every additional year since degree completion, we see the gender gap between males and females grows by $227.153 on average when adjusting for the other covariates in the model.\n\n\n\n\n\nActivity 6: Multiple Regression with Diagnostics\nThis exercise builds on the previous model. Add faculty rank (a three level categorical predictor) to the model and run the regression with diagnostics.\nCreate a multiple regression model where salary is the dependent variable, marketability, gender, time since degree, faculty rank, and the interaction between gender and time since degree are the predictors. \nCreate a side-by-side box plot for salary by rank.\n\n\n\n\n\n\n\n\n\n\nSelect Analyze -&gt; General Linear Model -&gt; Univariate\nSelect ‘salary’ as the dependent variable, ‘male’ and ‘rank’ as the fixed factors, and ‘market’ and ‘yearsdg’ as the covariates. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’.\n\n\n\n\n\nUnder ‘Model’, select ‘Custom’. Under ‘Build Terms’ select ‘Main Effect’ and enter the variables male, market, yearsdg, rank. Under ‘Build Terms’ select ‘Interaction’ and select both male and yearsdg to create the interaction term. Select ‘Continue’. Remember that main effects must always be included in a model that contains interaction terms.\n\n\n\n\n\nUnder ‘Save’ select ‘Unstandardized Predicted Values’ and ‘Standardized Residuals’. Under ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’\nThe table below displays the coding scheme used for the categorical predictors (factors).\n\n\n\n\n\nThe table below provides the descriptive statistics for salary broken out by gender and rank.\n\n\n\n\n\nThe table below indicates the model is significant (F=242.32, pvalue&lt;.001) and the R-squared value is .741 (an increase from the last model).\n\n\n\n\n\nWe can see from the table below that faculty rank is a significant predictor of salary. The table above indicates that rank=1=Assistant Professor, rank=2=Associate Professor, rank=3=Full Professor. The estimated difference in population mean salary between Assistant Professors and Full Professors is $11,168 after adjusting for the other covariates in the model. Put another way: Assistant professors earn on average $11,168 less than Full Professors, all else equal. The estimated difference in population mean salary between Associate Professors and Full professors is $7,819 after adjusting for the other covariates in the model. Put another way: Associate professors earn on average $7,819 less than Full Professors, all else equal.\n\n\n\n\n\nThe residual plot below is given from the output. First investigate the predicted (x axis) vs. std. residual plot to check for the constant variance assumption. There is not strong evidence that the assumption of constant variance has been violated. Linearity can also be assessed with this plot. Next investigate the plot of observed (x axis) and predicted values (y axis) to check the linearity assumption. The points should be symmetrically distributed on a diagonal (45 degree) line if the linearity assumption is not violated (this is approximately what we see here). Note that these plots could be made manually by creating scatter plots from the saved variables (predicted, residuals).\n\n\n\n\n\nThe GLM approach to regression doesn’t allow for VIF’s to be calculated directly. Multicollinearity can attempt to be assessed through investigating the correlations or calculating the VIF manually. Note that pairwise correlations do not fully capture multicollinearity.\n\n\n\n\n\n\n\n\n\n\nSelect Analyze -&gt; Descriptive Statistics -&gt; QQ Plot and select the residual variable. The plot below indicates that the distribution of the error terms is approximately normal. This can also be confirmed with a histogram.\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.7 Exercise A5 – Case Study II: AIDS (Logistic Regression)\nOpen exercisea5_data\nBackground\nThe data set for this exercise contains information on 109 countries with a number of characteristics measured for each country. The goal of the exercise is to identify whether there may be characteristics of a country that are related to AIDS rate classification. Countries are divided into one of two AIDS rate groupings: 0 = Less than 1 in 100,000 or 1 = More than 1 in 100,000. The variable in the data which holds this information is called aidscat2.\nWe will fit several models with AIDS rate category as our outcome to identify potential significant predictors of AIDS rate classification. Because the model outcome is no longer a continuous measure, but instead binary, a logistic regression model will be used. The outcome for this type of model isn’t actually the values of the variable (0 or 1) but instead a calculation of the probability of having the value of one of the two categories of the outcome. The model has the form:\n\\[\n    \\ln\\left( \\frac{p}{1 - p} \\right) = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{x} + \\ldots + \\beta_{p}x_{p}\\\n\\]\nwhere p is the probability of the outcome variable being equal to 1. The \\(\\ln\\left( \\frac{p}{1 - p} \\right)\\) outcome is known as the log-odds.\nNote: It is possible to change which level of the outcome variable the probability references, so you can model the probability that y=0 instead of y=1 if desired.\nIn all models for this exercise we will consider predicting the probability that a given country will have the higher AIDS rate classification (aidscat2=1). The objective of the models is to see whether the included predictors are significantly associated with the probability of having the higher AIDS rate classification.\nActivity 1: Logistic Regression with a Continuous Predictor\nFor the first example, we will look at a simple example of fitting logistic regression with a continuous predictor. We will consider a single continuous predictor (log base 10 of the gross domestic product per capita, LOG_GDP).\nPerform a simple logistic regression where ‘aidscat2’ is the outcome variable and ‘log_gdp’ is the independent/predictor variable.\nSelect Analyze -&gt; Regression -&gt; Binary Logistic’ to open the logistic regression dialogue box.\nSelect AIDSCAT2 as the binary dependent variable. Note that the category whose probability we want to model, “high” AIDS rate, is coded as a 1, and the other category, “low” AIDS rate, is coded as 0. SPSS automatically fits the highest valued category probability. If the opposite is desired the outcome variable should be recoded so the opposite category has a higher value. Select LOG_GDP as the only covariate, and click OK to fit the model. Results from fitting this model are included below.\n\n\n\n\n\nThe first table rovides some information regarding the cases (rows) used to fit that data. Note that three cases were lost in the analysis, due to missing data on the AIDSCAT2 variable. The final analysis sample size was 106.\n\n\n\n\n\nThe coding of the dependent variable is critical to understand. SPSS will model the probability that the “internal value” of the dependent variable is equal to 1. The “internal value” is the value that SPSS recodes the outcome to be to fit the model behind the scenes. This will not always match up to your original coding so check this table carefully. In our case the 0/1 internal coding that SPSS performs matches up with our original 0=less than 1 in 100,000 and 1=more than 1 in 100,000 coding so we will be modeling the probability of being in the “high” AIDS rate.\n\n\n\n\n\nThis initial classification table, located in “Block 0” of the output, shows how well we would do predicting by chance what the outcome will be (i.e., not using any covariates to predict the outcome). Because more countries have the higher classification, we would predict that classification for all of the countries, and we would be correct 64.2% of the time. This table isn’t all that informative by itself, we will compare it to a similar table in the next portion of the output.\n\n\n\n\n\nThis table, also in the “Block 0” portion of the output, shows the maximum likelihood estimate of the intercept term in a logistic regression model without any covariates. This is simply the computed log-odds of the dependent variable being equal to 1.\n\n\n\n\n\nWe’ll scroll down to the “Block 1” portion of the output, which will contain the maximum likelihood estimates of the parameters in our model. These estimates describe the relationship of LOG_GDP to the dependent variable (aidscat2). First, we examine the classification table for our outcome given that we are now considering the LOG_GDP variable as a predictor. This table is similar to predicted values in linear regression. For each country in the data set the predicted probability is computed using the fitted model and values of the country’s covariate. If the predicted probability is greater than 0.5 the country is classified into the ‘high’ AIDS rate group and if it is less than 0.5 it is classified into the ‘low’ AIDS rate group. These classifications are then compared with the actual observed classifications of the countries.\n\n\n\n\n\nNote that we are actually doing a worse job of predicting the AIDS rate when using LOG_GDP as a predictor (63.2% correct vs. 64.2% correct when we don’t consider any covariates). The predicted probabilities can be saved in the SPSS data set as an option if desired.\nNow, we examine the maximum likelihood estimate of the coefficient for LOG_GDP in the logistic regression model:\n\n\n\n\n\nThe estimate of the parameter that represents the coefficient for LOG_GDP in the model is equal to 0.491, with a standard error of 0.329. The Wald statistic reported by SPSS is the squared version of the T statistic (the coefficient divided by its standard error, squared), and is referred to a chi-square distribution with 1 degree of freedom. This Wald statistic has a p-value of 0.135, which suggests that we would not reject a null hypothesis that the coefficient for LOG_GDP is equal to 0. We really don’t have evidence of a significant relationship of LOG_GDP with the AIDS rate outcome.\nHowever, if the relationship were significant, we would conclude that a one-unit increase in LOG_GDP results in an expected increase of 0.491 in the log-odds of being in the higher AIDS rate category. The parameter estimates represent additive changes to the log-odds. If exponentiated we get the more common odds ratio, which is the multiplicative change to the odds. Here the Exp(B) column holds the exponentiated esimates, for log_gdp the odds ratio is equal to 1.634. This value has the meaning that the odds of being in the higher AIDS rate category are multiplied by 1.63 with every one-unit increase in LOG_GDP.\nActivity 2: Logistic Regression with a Categorical Predictor\nNow, we’ll consider an example of analyzing a single categorical predictor with two levels, whether or not the country is predominantly muslim (MUSLIM). MUSLIM is coded as 1 = yes and 0 = no, which we would recommend for any two-level predictors.\nSelect Analyze -&gt; Regression -&gt; Binary Logistic to re-enter the logistic regression dialogue box. Replace the log_gdp covariate with muslim. We need to identify the predictor as categorical so select the categorical button. Move the MUSLIM covariate into the ‘Categorical Covariates’ list.\n\n\n\n\n\nFit the logistic regression model by clicking on OK.\n\n\n\n\n\nLet’s jump down to Block 1 in the output and first examine the classification table based on the model including the MUSLIM variable:\n\n\n\n\n\nNote the substantial improvement in prediction accuracy by considering Muslim status! Now, we investigate the maximum likelihood estimate of the coefficient for MUSLIM:\n\n\n\n\n\nThe maximum likelihood estimate of the coefficient is -2.335, with a standard error of 0.537. The Wald statistic based on that estimate is 18.934, and the p-value for that Wald statistic is said to be 0.000 by SPSS (but should be reported as p &lt; 0.001). This p-value suggests that we should reject the null hypothesis that the coefficient is equal to 0, which tells us that Muslim status has a significant relationship with the probability of being in the higher AIDS rate category. Specifically, when MUSLIM is equal to 1 (as opposed to 0), the log-odds of being in the higher category are expected to decrease by -2.335.\nThis estimate corresponds to an odds ratio of 0.097 (the exponential version of the coefficient), which says that the odds of having a higher AIDS classification for a Muslim country is 0.097 times the odds of having a higher AIDS classification for a non-Muslim country. The expected odds are multiplied by 0.097 when a country is Muslim as opposed to non-Muslim. We can also interpret this as reducing the odds of being in the higher AIDS rate category by 90.03% for muslim countries. Notice here, when we see a decrease in the odds (odds ratio less than 1) we report 1-Odds Ratio as the percentage (1-.097=.9003).\nActivity 3: Logistic Regression with Multiple Predictors\nIn this analysis, we hope to find ways to categorize countries into one of two AIDS prevalence categories, based on other data for the countries. We will also discover which pieces of information are useful in predicting AIDS prevalence, and which appear to be unassociated with this prevalence.\nSet up a logistic regression model to predict AIDS prevalence category (aidscat2) by considering the following predictors: muslim, log_gdp, babymort, urban, lit_fema, lifeexpf, birth_rt, tropical. Have SPSS report confidence intervals for the odds ratios. (This is found under the ‘Options’ button in the Logistic Regression dialogue box.)\n\n\n\n\n\n\n\n\n\n\nWhich predictors appear useful in predicting AIDS category? Do Muslim countries still have lower odds of being in the higher AIDS prevalence category when controlling for the relationships of the other predictors with the outcome? How much lower are the odds of a Muslim country being in the higher AIDS category?\nThe first table shows us that only 83 countries are used to fit this model, 26 were removed from analysis due to missing data on any of the variables used.\n\n\n\n\n\nThe first classification table (Block 0: Beginning Block) in the output shows you the result of classifying cases strictly by predicting them to be in the category with the largest percentage in the data set (in this case, you would predict a random case to be in the higher AIDS category, since 64.2% of the cases with a valid AIDS category are in the higher AIDS category). We would only be correct 59% of the time predicting by chance.\n\n\n\n\n\nThe ‘Model Summary’ table shows the –2 log-likelihood statistic for our model, as well as two analogs of R2 in the multiple regression context for a logistic regression model. These are approximations of R-squared in linear regression models, and should not be reported as the same thing; they should really only be used to compare the fits of competing models fitted using the same cases. The Cox & Snell R Square approximation suggests that our predictors explain about 41% of the variation in our response (not bad). The Nagelkerke R Square is a rescaled approximation that is constrained to fall between 0 and 1.\n\n\n\n\n\nThe Block 1 classification table shows an increase in the percentage that is correctly classified (83.1% vs 59%) using the predicted probabilities and a ‘cut-off’ classification probability of 0.5.\n\n\n\n\n\nLet’s examine the estimated coefficients for the predictors included in our model:\n\n\n\n\n\nThe B column contains the estimated coefficients in the logistic regression model, which indicate the change in the log-odds of “success” (in this case, being in the higher AIDS category) associated with a one-unit increase in each predictor. So, for example, a one-unit increase in Muslim (or being in a Muslim country) decreases the log-odds of being in the higher AIDS category by 5.987, holding all other predictors constant.\nThe Sig. column provides the results of a significance test for each of the parameters (or coefficients) for the predictors in the model. This shows that Muslim, lit_fema, and tropical are significant predictors of being in the higher AIDS category. If a predictor is significant, changes in the predictor have a significant relationship with the log odds of “success.” The Exp(B) column indicates the factor by which the odds of “success” are multiplied when the predictor increases by one unit, holding the other predictors constant. So, for example, a one-unit increase in Muslim will multiply the odds of being in the higher AIDS category by 0.003, or reduce the odds of being in the higher AIDS category by 99.7%. The Exp(B) factor is known as an odds ratio. The 95% confidence interval for Exp(B) will not contain 1 if the predictor is significant. An odds ratio of 1 means that one-unit changes in the predictor multiply the odds of “success” by 1, or effectively do not change the odds."
  },
  {
    "objectID": "appendix.html#final-project",
    "href": "appendix.html#final-project",
    "title": "5  Appendix",
    "section": "5.4 Final Project",
    "text": "5.4 Final Project\nThe Data\nThe cars data sets contain data on specifications of 406 vehicles from 1970 to 1982. Among the variables in the data set are information on fuel consumption (mpg), horsepower, weight, acceleration, origin (Europe, Japan, U.S.), and number of cylinders.\nThe data set contains categorical variables (such as origin), numerical discrete variables (such as number of cylinders), and continuous variables (such as weight, and acceleration).\nGetting Started\n\nInvestigate cars_wave1.xls and cars_wave2.xls and prepare the data for SPSS\nOpen SPSS and import cars_wave1.xls and cars_wave2.xls from Microsoft Excel.\nMerge cars_wave1 and cars_wave2 (add cases).\nSave this new SPSS file!\nUsing the codebook below, define the proper attributes in Variable View\n\n\n\n\n\n\n\n\n\n\n\nVariable\nPosition\nLabel\nMeasurement Level\nMissing Values\n\n\n\n\nID\n1\nCar ID Number\nNominal\n\n\n\nmpg\n2\nMiles per Gallon\nScale\n999\n\n\nengine\n3\nEngine Discplacement (cu. Inches)\nScale\n\n\n\nhorse\n4\nHorsepower\nScale\n\n\n\nweight\n5\nWeight (lbs.)\nScale\n\n\n\naccel\n6\nTime to Accelerate from 0 to 60 mpg (sec)\nScale\n\n\n\nyear\n7\nModel Year (module 100)\nOrdinal\n\n\n\norigin\n8\nCountry of Origin\nNominal\n\n\n\ncylinder\n9\nNumber of Cylinders\nOrdinal\n\n\n\n\n\n\n\n\nValue\nLabel\n\n\n\n\norigin\n1\nAmerican\n\n\n\n2\nEuropean\n\n\n\n3\nJapanese\n\n\ncylinder\n3\n3 Cylinders\n\n\n\n4\n4 Cylinders\n\n\n\n5\n5 Cylinders\n\n\n\n6\n6 Cylinders\n\n\n\n8\n8 Cylinders\n\n\n\nWorking with Variables\n\nRecode Origin such that 1=Domestic, 0=Foreign. Remember to recode into a different variable. Give this new variable the proper attributes in variable view.\nConvert Miles Per Gallon (MPG) to Liters Per 100 Kilometers\n\nUse the Compute function\nThe formula to use: LP100K=(100*3.785)/(1.609*MPG)\n\nExport this SPSS data set to Microsoft Excel (it’s always good to have a back up!). Export all of the variables.\n\nOne Variable Procedures\n\nGet descriptive statistics for all scale variables in the data set.\nGet frequency tables for all categorical variables (ordinal or nominal) in the data set.\nCreate a histogram of Horsepower.\nCreate a histogram of Weight.\nCreate a QQ-Plot for Weight (Analyze Descriptive Statistics QQ Plot Select Weight, leave others as default settings OK)\nCreate a bar chart for Origin.\nOrganize the output by Year (Analyzing groups of cases separately, compare groups). Before proceeding, select only cases with Year not = 0.\n\nInvestigate Horesepower (descriptive statistics)\nInvestigate Weight (descriptive statistics)\nWhat do you see?\nRemember to turn the Split File command off before proceeding!\n\n\nRelationship Between Continuous Y (Horsepower) and Continuous X (Weight)\n\nCreate a Scatter Plot with Horsepower as the Y variable and Weight as the X variable.\n\nAdd a Linear fit line.\nWhat is the relationship between Horsepower and Weight as shown in this graph?\n\nCalculate the Pearson and Spearman Correlation coefficients for the relationship between Horsepower and Vehicle Weight.\n\nWhat is the p-value for the Pearson correlation?\nWhat is the actual p-value, as opposed to the p-value that is displayed? To display the actual p-value for the Pearson correlation, double-click on the Pearson correlation output table and double-click on the p-value. (Remember, p-values cannot actually be equal to zero. The p-value you will see displayed, after double-clicking, will be in scientific notation.)\n\n\nRelationship Between Continuous Y and Numerical Discrete/Ordinal X\n\nBefore doing any analyses, select only cases with Year not = 0.\nCreate a side-by-side boxplot of MPG vs. Year. Choose MPG as the “variable” and Year as the “category axis”.\nWhat is the general trend of MPG across years?\n\nRelationship Between Continuous Y and Nominal X\n\nCreate a side-by-side boxplot of Miles per gallon vs Country of Origin (ORIGIN). (Note: even though Origin is numeric in the data set, its values are nominal: American, European, Japanese).\nWhat is the general relationship between MPG and the Origin of the car?\nCreate a side-by-side Boxplot of Miles per gallon vs. the recoded Country of Origin (1=Domestic, 0=Foreign).\n\nFinal Steps\n\nExport the SPSS output into Microsoft Excel\nSelect a few tables and/or charts that you would like to present and paste them into Microsoft Word\n\n\n5.4.1 Final Project Solution\nThe Data:\nThe cars data sets contain data on specifications of 406 vehicles from 1970 to 1982. Among the variables in the data set are information on fuel consumption (mpg), horsepower, weight, acceleration, origin (Europe, Japan, U.S.), and number of cylinders.\nThe data set contains categorical variables (such as origin), numerical discrete variables (such as number of cylinders), and continuous variables (such as weight, and acceleration).\nGetting Started\n\nInvestigate cars_wave1.xls and cars_wave2.xls and prepare the data for SPSS\n\nRemove the first couple rows that contain a heading\nRemove the last row that contains summary information\nSave and exit\n\nOpen SPSS and import cars_wave1.xls and cars_wave2.xls from Microsoft Excel.\n\nOpen SPSS\nFile -&gt; Open -&gt; Data Select “Excel” under File Type\nBrowse for the Excel files and select Open\nKeep the box checked for “Read variable names from the first row of data”\nLeave the worksheet selected as the default\nSelect OK\n\nMerge cars_wave1 and cars_wave2 (add cases).\n\nData -&gt; Merge Files -&gt; Add Cases\nSelect the open data file, then select Continue\nThe Add Cases dialog will appear\nThere should not be any “unpaired” variables\nSelect OK\nYour active data file should now have 406 cases\nSave this data file and close the “non active” file\n\nSave this new SPSS file!\nUsing the codebook below, define the proper attributes in Variable View\n\nBe sure to include the missing value code for MPG\nYou only need to modify the measurement type, variable labels, variable values, and missing values.\n\n\nWorking with Variables:\n\nRecode Origin such that 1=Domestic, 0=Foreign. Remember to recode into a different variable. Give this new variable the proper attributes in variable view.\n\nTransform -&gt; Recode into different variables\nSelect Country of Origin (ORIGIN)\nName = Domestic\nLabel = Domestic Car?\nSelect the Change button\nSelect the Old and New Values button\nOld Value: Value: 1\nNew Value: Value: 1\nSelect Add\nOld Value: Value: 2\nNew Value: Value: 0\nSelect Add\nOld Value: Value: 3\nNew Value: Value: 0\nSelect Add\nOld Value: Value: System or User Missing\nNew Value: Value: System Missing\nSelect Add\nSelect Continue\nSelect OK\nGo to Variable View and enter 1=Domestic, 0=Foreign under Values for this new variable. Also adjust the decimal place to 0.\n\nConvert Miles Per Gallon (MPG) to Liters Per 100 Kilometers\n\nUse the Compute function\nThe formula to use: LP100K=(100*3.785)/(1.609*MPG)\n\nTransform -&gt; Compute Variable\nTarget Variable = LP100K\nNumerical Expression: (100*3.785)/(1.609*MPG)\nSelect OK\nGo to Variable View and give this variable a label (Liters Per 100 Kilometers)\n\n\nExport this SPSS data set to Microsoft Excel (it’s always good to have a back up!). Export all of the variables.\n\nFile -&gt; Save As\nChange Files of Type to Excel\nGive a name and select location to save\nSave\n\n\nOne Variable Procedures:\n\nGet descriptive statistics for all scale variables in the data set.\n\nAnalyze -&gt; Descriptive Statistics -&gt; Descriptives\nSelect\n\nmpg\nengine\nhorse\nweight\naccel\nlp100k\n\nSelect OK\n\n\n\n\n\n\n\n\nGet frequency tables for all categorical variables (nominal/ordinal) in the data set.\n\nAnalyze -&gt; Descriptive Statistics -&gt; Frequencies\nSelect\n\nyear\norigin\ncylinder\ndomestic\n\nSelect OK\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a histogram of Horsepower.\n\nGraphs -&gt; Legacy Dialogs -&gt; Histogram\nVariable: Horsepower\nCheck the box to display normal curve\nSelect OK\nInvestigate output\n\n\n\n\n\n\n\n\nCreate a histogram of Weight.\n\nGraphs -&gt; Legacy Dialogs -&gt; Histogram\nVariable: Weight\nCheck the box to display normal curve\nSelect OK\nInvestigate output\n\n\n\n\n\n\n\n\nCreate a QQ-Plot for Weight (to help assess normality)\n\nAnalyze -&gt; Descriptive Statistics -&gt; QQ Plot\nSelect Weight, leave others as default settings\nSelect OK\n\n\n\n\n\n\n\n\nCreate a bar chart for Origin.\n\nGraphs -&gt; Legacy Dialogs -&gt; Bar\nSimple, summaries for groups of cases\nSelect Define\nSelect Origin for the Category Axis\nSelect OK\n\n\n\n\n\n\n\n\nOrganize the output by Year (Analyzing groups of cases separately, compare groups). Before proceeding, select only cases with Year not = 0.\n\nInvestigate Horsepower (descriptive statistics)\n\nData -&gt; Select Cases\nSelect If Condition is Satisfied (select If button)\nEnter this condition: year ~= 0\nSelect Continue\nOutput: Filter out unselected cases\nSelect OK\nData -&gt; Split File\nSelect Compare Groups\nSelect Model Year (YEAR) for “Groups Based On”\nSelect “Sort the file by grouping variable”\nSelect OK\nAnalyze -&gt; Descriptive Statistics -&gt; Descriptives\nSelect Horsepower\nSelect OK\n\n\n\n\n\n\n\n\n\nInvestigate Weight (descriptive statistics)\n\nAnalyze -&gt; Descriptive Statistics -&gt; Descriptives\nSelect Weight\nSelect OK\n\n\n\n\n\n\n\n\nWhat do you see happening in these two variables over time?\n\nIt appears that the average horsepower and average weight are decreasing over time\n\nRemember to turn the Split File command off before proceeding!\n\nData -&gt; Split File\nSelect Reset\nSelect OK\n\n\nRelationship Between Continuous Y (Horsepower) and Continuous X (Weight):\n\nCreate a Scatter Plot with Horsepower as the Y variable and Weight as the X variable.\n\nAdd a Linear fit line.\n\nGraphs -&gt; Legacy Dialog -&gt; Scatter/Dot\nSimple Scatter\nSelect Define\nY Axis: Horsepower\nX Axis: Weight\nSelect OK\nDouble click on the chart in the Output Viewer to open Chart Editor\nSelect “Add Fit Line at Total” Button (lowest row, 5th object inward)\nThe defaults are sufficient, so close out of the “Add Fit Line at Total” dialog\nClose out of chart editor\n\n\n\n\n\n\n\n\n\nWhat is the relationship between Horsepower and Weight as shown in this graph?\n\nThere is a strong positive linear relationship\n\n\n\n\nCalculate the Pearson and Spearman Correlation coefficients for the relationship between Horsepower and Vehicle Weight.\n\nWhat is the p-value for the Pearson correlation?\n\nAnalyze -&gt; Correlate -&gt; Bivariate\nSelect Horsepower and Weight\nSelect Ok\nThe pvalue is listed as .000\n\nWhat is the actual p-value, as opposed to the p-value that is displayed? To display the actual p-value for the Pearson correlation, double-click on the Pearson correlation output table and double-click on the p-value. (Remember, p-values cannot actually be equal to zero. The p-value you will see displayed, after double-clicking, will be in scientific notation.)\n\n1.18068E-120\n\n\n\nRelationship Between Continuous Y and Numerical Discrete/Ordinal X:\n\nBefore doing any analyses, select only cases with Year not = 0.\n\nData -&gt; Select Cases\nSelect If Condition is Satisfied (select If button)\nEnter this condition: year ~= 0\nSelect Continue\nOutput: Filter out unselected cases\nSelect OK\n\nCreate a side-by-side boxplot of MPG vs. Year. Choose MPG as the “variable” and Year as the “category axis”.\n\nGraphs -&gt; Legacy Dialogs -&gt; Boxplot\nSimple, Summaries for groups of cases\nSelect Define\nVariable: MPG\nCategory Axis: Year\nSelect OK\n\n\n\n\n\n\n\n\nWhat is the general trend of MPG across years?\n\nThe median MPG appears to increase over time\n\n\nRelationship Between Continuous Y and Nominal X:\n\nCreate a side-by-side boxplot of Miles per gallon vs. Country of Origin (ORIGIN). (Note: even though Origin is numeric in the data set, its values are nominal: American, European, and Japanese).\n\nGraphs -&gt; Legacy Dialogs -&gt; Boxplot\nSimple, Summaries for groups of cases\nSelect Define\nVariable: MPG\nCategory Axis: ORIGIN\nSelect OK\n\n\n\n\n\n\n\n\nWhat is the general relationship between MPG and the Origin of the car?\n\nThe median MPG appears to be larger for European and Japanese cars when compared to American cars\n\nCreate a side-by-side Boxplot of Miles per gallon vs. the recoded Country of Origin (1=Domestic, 0=Foreign).\n\nGraphs -&gt; Legacy Dialogs -&gt; Boxplot\nSimple, Summaries for groups of cases\nSelect Define\nVariable: MPG\nCategory Axis: RecodeOrigin\nSelect OK\n\n\n\n\n\n\n\n\nCreate a correlation matrix and scatter plot matrix for Horsepower, Weight, and Year. How strongly are these variables correlated?\n\nGraphs -&gt; Legacy Dialogs -&gt; Scatter/Dot\nMatrix Scatter\nDefine\nSelect Horsepower, Weight, Year under Matrix Variables\nSelect OK"
  }
]