[
["index.html", "Introduction to SPSS Chapter 1 Overview of the Workshop 1.1 Contact information 1.2 Acknowledgments 1.3 Images 1.4 Data", " Introduction to SPSS CSCAR Staff 2020-01-20 Chapter 1 Overview of the Workshop There are four sections to this workshop: Chapter 2: The Basics of SPSS Chapter 3: Working with Variables Chapter 4: Understanding Data Management Tasks Chapter 5: Understanding Graphical &amp; Statistical Procedures, Msc. These sections will generally be presented in sequence. The discussion will alternate between theory and practice. The format will alternate between lecture and lab sessions. Please ask questions as soon as they arise in your mind. Please provide feedback or voice concerns. 1.1 Contact information 1.1.1 CSCAR Office Hours: Monday-Friday 9am to 5pm (Closed Tuesday 12-1pm) Phone: 734.764.7828 Statistical Assistance: stats-consulting@umich.edu Data Science Assistance: ds-consulting@umich.edu High Performance Computing: hpc-consulting@umich.edu http://cscar.research.umich.edu/ 1.2 Acknowledgments These notes have evolved over the years thanks to many CSCAR statisticians, including Corey Powell, Josh Errickson, Giselle Kolenic, and Missy Plegue. This material was created for use in workshops and short courses presented by faculty and staff from the Consulting for Statistics, Computing &amp; Analytics Research (CSCAR) at the University of Michigan. No part of this material may be used for other purposes, copied, changed, or sold. 1.3 Images All images embedded within the document should link to a full-size version of the image. 1.4 Data There are a number of data sets used in these notes; some used for the examples, others for the execises. data.zip - This zip files contains all data used within the notes. 1.4.1 Example Data Section 3: section3_data.sav Section 4: section4_data.sav Section 5: section5_1_data.sav, section5_2_data.sav 1.4.2 Exercise Data Exercise 0: exercise0_data.sav, exercise0_output.spv, exercise0_syntax.sps (You may need to right-click &amp; Save As for the .sps file) Exercise 1: exercise1_data.sav Exercise 2: exercise2_data.xls Exercise 3: exercise3_data.sav Exercise 4: exercise4_data.sav Exercise 5: exercise5_data.sav Exercise 6: exercise6_data.sav Exercise 7: exercise7_data.sav Exercise 8: exercise8_data.sav 1.4.3 Additional Exercises These are for the additional exercises and final project found in the appendix. Exercise A1: exercisea1_data.sav Exercise A2: exercisea2_data.sav Exercise A3: exercisea3_data_a.sav, exercisea3_data_b.sav Exercise A4: exercisea4_data.sav Exercise A5: exercisea5_data.sav Final Project: cars_wave1.xls, cars_wave2.xls "],
["the-basics-of-spss.html", "Chapter 2 The Basics of SPSS 2.1 What does SPSS Stand For? 2.2 SPSS Compared to Other Statistical Software Packages 2.3 The Three Parts of SPSS 2.4 Good to Know 2.5 Tips for Preparing an Excel File for Use with SPSS 2.6 Exercise 1 – Properly Formatted Data 2.7 Importing Data into SPSS 2.8 Exporting Data from SPSS 2.9 Exercise 2 – Importing/Exporting Excel 2.10 Getting Help from SPSS", " Chapter 2 The Basics of SPSS 2.1 What does SPSS Stand For? Originally, SPSS stood for Statistical Package for the Social Sciences. Now, it stands for Statistical Product and Service Solutions. SPSS has also been known as “PASW” which stands for Predictive Analytics Software. 2.2 SPSS Compared to Other Statistical Software Packages We can think of statistical software packages on a spectrum organized by difficulty and complexity. On one end we have Excel which is easy and familiar to most people. On the other end we have C++ which is difficult and unfamiliar. All software packages are somewhere in between. SPSS is closer to the Excel end of the spectrum which makes is convenient to use. SPSS builds on what you already know from Excel, which makes the transition from Excel to a more powerful statistical software package easier. Easiest: Excel SPSS Minitab JMP Stata,SAS R/S-Plus Matlab Hardest: C++ SPSS requires that data, code, and output are in separate places, unlike Excel. These differences seem big at first, but they are a small price to pay for the additional data management, graphical, and statistical capabilities that SPSS will give you over Excel. While SPSS seems to be more restrictive than Excel, the restrictions it sets ensure that your data set is ready for statistical analysis. 2.3 The Three Parts of SPSS There are three parts to SPSS, each with its own window: Data Editor, Output Viewer, and Syntax Window. The sections below describe each of these parts in detail. Data Editor Enter and View Data Values, files end in .sav or.por Output Viewer View Statistical Results, files end in .spv Syntax Window Write &amp; Run Syntax Command, files end in .sps 2.3.1 Data Editor The Data Editor is visible when SPSS starts up. There are two views of the Data Editor: Data View and Variable View. In Data View, each row represents one case (e.g., one survey respondent), while each column represents one variable (one piece of information, e.g. age). By using the scroll bars to go up and down, you can examine any case in the sample. By using the scroll bars to go right and left, you can see any variable. The first step in an SPSS session is to open a data file or start entering data in a new data file. A data file is a binary file ending in the extension .sav or .por, which contains a given data set. Any requested statistics or analyses that are performed pertain to this data set. 2.3.1.1 Open a Data File To open a data file, go to “File” at the upper left of the menu bar. Click “Open” then “Data”. Locate the file that you want to open and double-click on it. Try it: Open exercise0_data.sav Start a New Data File To start a new data file, go to “File” at the upper left of the menu bar. Click “New” then “Data”. 2.3.2 Output Viewer The output viewer is a window where any statistical results, including tables or graphs, can be viewed. The output window does not appear until the first time SPSS is asked to provide some sort of results. The output viewer will also record the syntax used to generate the results. Try it: Open exercise0_output.spv The output viewer is divided into two parts: on the left, a narrow window shows an outline which organizes all the results. The outline can be used to delete certain portions of the output, rearrange pieces of the output, jump to specific results, and temporarily hide (or make visible) certain parts of the output. More on this later. The actual results themselves are in the larger window to the right. When printing the output, only the information in this window is printed. Once the viewer has been opened, it will remain open even if all the output is deleted and the output window is empty. Occasionally the results from a procedure will be quite lengthy, and only the first portion will appear in the window. In these cases, a small red triangle pointing down will appear at the bottom of this visible portion. To see those results in their entirety, double-click on that section of output. Scroll bars will appear which pertain to that piece of output; scroll down to see the remainder. 2.3.2.1 Labels in Output Variable labels and value labels will be used in place of the actual variable names or values, by default. This can be changed under the Edit - Options - Output tab. SPSS can display labels only, the actual names or values only, or both. 2.3.2.2 Tables &amp; Charts Results are commonly presented in the output viewer in table form or chart (graph) form. To edit a table, double-click on that table (anywhere will do). An editing window is set up around that table, indicated by a rough gray outline. New menus appear in the menu bar at the top. Once this editing mode is begun, double-clicking in any cell in a table will allow you to change the names, labels, or values in those cells. Helpful Hint: To remove scientific notation in a table, double-click on the table and highlight the columns or rows containing the notation. Under Format - Cell Properties and select a new numeric format, such as #,###.##. The number of decimal places can be increased or decreased here as well. Editing a chart is similar to editing a table. Begin by double-clicking anywhere on the chart and the Chart Editor window will appear. Once in the Chart Editor, many things can be altered simply by double-clicking and changing fields in the dialogue boxes which appear. Try it: Double click on the Descriptive Statistics table for the salary variable. Change the Std. Deviation to have only two digits to the right of the decimal point. 2.3.2.3 Export Output You can save the output file for future use or to send to colleagues. In order to open a SPSS output file, your computer must have SPSS. Sometimes it is useful to export the information from your output file into another format, such as Microsoft Excel or Microsoft Word. Excel is a great platform to export to—tables turn out very nicely. To export, select File - Export and the export wizard will appear. Select the file type and the location to save the file, then select “OK”. Try it: Export the output table as an Excel file and investigate the Excel file. Starting with SPSS Version 11.5, selected output objects, such as charts and tables, can also be exported in an Excel or Word format. This is a very useful feature that can be used to export selected tables from the Output Viewer into an Excel format, for additional work such as creation of custom graphs. To export charts, select the charts in the output window by clicking once on them, and then go to File - Export and select “Selected” where it asks what objects to export. Choose the “html” file type for charts, and under the Graphics portion of the dialogue box a drop down menu allows one to access the various types of image files available. The bitmap image format is one option. Although these images are somewhat large in terms of kilobytes, they can be read by a great many programs, including Word, Power Point and others. One last option for exporting SPSS output is to copy and paste all output into a Word file. The steps are as follows: Click once to select the piece(s) of output to move. Go to Edit - Copy, press the short-cut ctrl-C, or right-click and select “Copy”). In Word, place the cursor where the output will go. Under “Edit”, click “Paste”, or use the short-cut ctrl-V. You can then resize and move around the pasted objects in Word. The same process outlined above should work for other Microsoft programs, such as Power Point or Excel. While pasted objects can be edited in theory, this is usually difficult. It is best to do all editing in SPSS before pasting to Word. 2.3.3 Syntax Window The Syntax Window looks like the Output Viewer, but it is a text editing window in which SPSS commands can be written out by hand. It allows users to type commands in the right-hand side window rather than use menus. Commands executed using written code are no different from commands executed using the pull-down menus and dialogue boxes. There are some rare instances when something is available only by writing syntax, and cannot be found in any menu. The syntax window provides these advantages: It allows a user to do repetitive tasks more quickly, using copy &amp; paste. It provides a written record of data management and analyses performed. It can be sent to other SPSS users to help in setting up data files or to re-create your analyses. Try it: Open exercise0_syntax.sps (Right-click &amp; Save-as) You can generate syntax in a few different ways: Write out the syntax by hand. Use the “Paste” button inside a dialogue box. Copy and paste the syntax from the output viewer. The “Paste” button in dialogue boxes causes the written syntax equivalent of a command to be entered into the syntax window. A new syntax window will open if no syntax window was open previously. 2.3.3.1 Run Syntax To run commands in the syntax window, highlight the commands of interest and go to Run - Selection. Alternatively, you can click on the toolbar button that looks like a “Play” symbol on a CD player or press ctrl-R as a short-cut. You can also run all commands in the syntax window by using Run - All. Try it: In the Syntax Window, highlight number 3 and run the selection highlighted below. Check the Output Viewer. Repetitive Commands As a simple example of repetitive commands, consider a user who needs to take logs of thirty different variables. To go through the menus and do thirty computations would be quite time-consuming. This is a case where using syntax would be easier, because cut, copy, and paste commands are available in the Syntax Window. If you pasted one such computation command to the syntax window, you could then copy the command out thirty times. You would only need to edit the variable names in each line. The steps for using syntax for repetitive commands are: Paste one example command into the syntax window. Copy this command by highlighting it and typing ctrl-C or by right clicking and copying. Paste the command repeatedly using ctrl-V or right clicking and pasting. Edit each line by changing the variable names. Run the commands! Once again, the cut, copy, and paste commands have these short-cuts: Cut ctrl-X Copy ctrl-C Paste ctrl-V Helpful Hint: If you want to start setting up a data set, by formatting variables, recoding, etc., you can begin before you receive all the data. Test your data management commands on the cases you do have, and save the syntax file. When you receive the final data delivery, you can re-run the syntax one last time and be ready to go! Try it: Highlight Number 5, copy and paste the syntax. Modify the syntax such that VARIABLES=salbegin. 2.3.3.2 Reading in Raw Data with Syntax Reading in raw data files is another common use of the syntax window. Many organizations will provide large, publicly available data sets by distributing the raw data and a SPSS syntax file which reads in and formats that data. If you receive a raw data file and a SPSS syntax file, sometimes referred to as data definition statements, then follow these steps to get a copy of the data file in SPSS format: Start SPSS, but do not open any data file yet. Open the syntax file containing the commands to read the data. At the top of the syntax, find the “FILE HANDLE” statement. Change the path and the name of the file to match the current file location and name (the file should contain instructions as well). Select Run - All . 2.3.3.3 Syntax Examples 1) Accessing an SPSS data file and rename the dataset GET FILE = \\&#39;C:\\\\SPSS\\\\data\\\\example.sav\\&#39;. EXECUTE. DATASET NAME example. 2) Entering new variables and data DATA LIST LIST / age (F2.0) sex (A1) income (F2.1) ethnic (F1.0). BEGIN DATA 45 F 60.9 2 52 M 22.3 1 34 M 45.8 3 67 F 34.5 1 END DATA. 3) Creating new numeric or string variables NUMERIC ses (F1.0) / numkids yrsmarr (F2.0). STRING state (A2) / region (A1) / citycode (A4). 4) Labeling variables VARIABLE LABELS age \\&quot;Age\\&quot; sex \\&quot;Sex\\&quot; income \\&quot;Annual income in thousands\\&quot; ethnic \\&quot;Ethnic category\\&quot;. 5) Labeling values of a variable VALUE LABELS sex \\&#39;M\\&#39; \\&quot;Male\\&quot; \\&#39;F\\&#39; \\&quot;Female\\&quot; / ethnic 1 \\&quot;European American\\&quot; 2 \\&quot;African American\\&quot; 3 \\&quot;Asian American\\&quot;. 6) Defining missing values MISSING VALUES sex (&#39;X&#39;) ethnic (8,9) income (7777) age (0). 7) Calculating a new variable using a function COMPUTE log10inc = LG10(income). EXECUTE. 8) Calculating a new variable using “if then” logic IF (sex=\\&#39;M\\&#39; and age \\&gt;= 65) olderman=1. IF (sex=\\&#39;F\\&#39; or age \\&lt; 65) olderman=0. EXECUTE. or: COMPUTE olderman = (sex=\\&#39;M\\&#39; and age \\&gt;= 65). EXECUTE. 9) Recoding a variable RECODE ethnic (1=0) (2=1) (3=1). EXECUTE. 10) Recoding into a new variable, keeping the original intact RECODE ethnic (1=0) (2=1) (3=1) INTO wh\\_nonwh. EXECUTE. RECODE income (LOWEST THRU 25 = 1) (26 THRU 44 = 2) (45 THRU HIGHEST=3) INTO incomcat. EXECUTE. 11) Obtaining descriptive statistics for continuous variables DESCRIPTIVES VARIABLES=income age /STATISTICS=MEAN STDDEV VARIANCE MIN MAX SEMEAN. 12) Getting frequencies for categorical variables FREQUENCIES VARIABLES=sex ethnic olderman. 13) Obtaining a cross-tabulation between two categorical variables CROSSTABS /TABLES = jobcat BY gender /STATISTIC = CHISQ /CELLS = COUNT ROW COLUMN. 14) Producing a histogram GRAPH /HISTOGRAM(NORMAL)=income /TITLE= \\&#39;Histogram of Income\\&#39;. 15) Creating side-by-side box-plots EXAMINE VARIABLES=income BY ethnic /PLOT=BOXPLOT /STATISTICS=NONE /NOTOTAL. 16) Generating a scatter plot GRAPH /SCATTERPLOT(BIVAR)=age WITH income /MISSING=LISTWISE. 17) Obtaining a line graph GRAPH /LINE(SIMPLE)=MEAN(income) BY ethnic. 18) Getting a line graph with multiple lines (e.g. one for women, one for men) GRAPH /LINE(MULTIPLE)=MEAN(income) BY ethnic BY sex. 19) Choosing a subset of the data to analyze or examine COMPUTE filt\\_var=(gender=\\&#39;m\\&#39;). FILTER BY filt\\_var. EXECUTE. 20) Returning to the entire sample after looking at a subset FILTER OFF. EXECUTE. 21) Splitting the observations into strata, so that future analyses will be repeated for each stratum separately SORT CASES BY ethnic. SPLIT FILE BY ethnic. 2.3.3.4 Writing Syntax Tips Each command must begin on a new line and must end with a period. A comment can be included in a syntax file. The comment starts with an asterisk (*) and can go beyond one line. A period (.) is required in the end of the last line to terminate the comment. SPSS syntax is case insensitive. Capitalized words are used to indicate keywords and command names in SPSS documentation, while lowercase letters indicate user-specified words; this is only a convention. String values must be enclosed in single or double quotes. Commands, sub-commands, and keywords can be abbreviated to three letters, but use four or five to avoid ambiguities. Variable names must always be typed out in full. Numbers and underscores are valid in a variable name if they are not the first letter. The use of capitals will not distinguish two variable names; name and NAME are identical. Sub-commands are preceded by a forward slash (/); they need not begin on a new line. However, lines of code can’t be more than 80 characters long. The word EXECUTE and a period (.) should be included after each command, such as COMPUTE and RECODE, that requires changes to the data set. Adding in EXECUTE. will never hurt anything; if in doubt, include it. Labels and other items enclosed in quotes must not run onto the next line. The word “then” never appears in “if then” types of commands. 2.4 Good to Know 2.4.1 Dialogue Boxes The main way that a user tells SPSS what to do is through dialogue boxes. These are windows that pop up when you click on an item in a menu or double-click on particular objects. Try it: In Data View for exercise0_data.sav, select Analyze - Descriptive Statistics - Descriptives. While dialogue boxes vary according to the task involved, they all have at least some of the following buttons: “OK” Carries out the procedure; executes the command now. “Continue” Returns to the main dialogue box after specifying an option. “Paste” Writes out the syntax for the procedure in a syntax window. “Reset” Returns the dialogue box to its original blank state. “Cancel” Closes the dialogue box without taking any action. “Help” Opens up a help window specific to that procedure. In most dialogue boxes, you select certain variables from the list on the left and move these variables into the active variable box on the right. Here are some tips: Click on any variable in the variable list, then type the first few letters of a variable name to zoom to that name in the list. Hold down shift and click on any two variables to select every variable in between. Hold down ctrl and click to select multiple variables that are not necessarily adjacent in the list. You could choose to display either variable labels or names in the variable list. For example, if you want the names to be displayed, go to then “Edit” menu and click “Options”. When a new window comes up, click on the tab labeled “General”. In the “Variable Lists” section, choose option “Display names” or “Display labels” for variable labels. 2.4.2 Adding Comments You can add descriptive comments to data files by going to Utilities - Data File Comments. 2.5 Tips for Preparing an Excel File for Use with SPSS Place the variable names in the first row. Be sure the names follow these rules: variable names should be no more than 64 characters long (and no longer than 8 characters is usually recommended) variable names must start with a letter variable names may only have letters, numbers, or underscores in them the following characters must not appear in variable names: %,$,#,@,!,+,*,~,\",-,. no blank spaces can appear in variable names each variable name must be unique, with no duplicate variable names variable names can be on one row only Only include the raw, un-summarized data. Delete extraneous data in your Excel file, like row or column totals, graphs, etc. Include an identifying number for each case that is unique. If you have several spreadsheets for one person, include the identifier on each sheet. Only include one value per cell. Don’t enter data such as “120/80” for blood pressure. Enter systolic blood pressure as one variable, and diastolic blood pressure as another variable. Don't leave blank rows in the data. Don’t mix numeric and character values, such as names and ID numbers, in the same column. Character variables are allowed in statistical packages but are not as flexible as numeric variables. Use numeric values when feasible. If you have missing values, you can indicate them with a numeric code, such as 99 or 999, or you can leave the cell blank. Be sure, if you use a missing value code, that it is not a plausible real data value. Save the spreadsheet with values only – not formulas. An ideal Excel data set might look like this: 2.6 Exercise 1 – Properly Formatted Data In order to analyze data properly in SPSS, we need to follow the guidelines set out in the course notes. Open exercise1_data.sav and see what guidelines we have ignored. 2.7 Importing Data into SPSS SPSS can easily read in data from Excel, SAS or Stata, as well as several lesser used options. To open a file from another program, go to File - Open. Under “File Type” find the program the data file was created in. Select this type and find the file you’d like to open. Click “Open”. It’s that easy – the data file should appear. If your data is not stored in a format that SPSS can read, then first convert the file to Excel format. Excel is a useful liaison between other programs and SPSS. Try it: Select File - Open. Investigate the different file types that you can open. Data files that are in TEXT FORMAT (.txt) are either delimited or divided into columns of fixed length. SPSS provides a wizard that asks questions and makes intelligent guesses in order to import your text data. This facility is somewhat like Excel’s data-reading wizard. Delimited files have rows of values that are separated by tabs, commas, or spaces. The first rows of data from a tab-delimited file might look like (where the first row identifies variable names, the second row is the first row of data): Name Age Gender Occupation Yearly Salary Jim 25 Male Accountant 65,000 A row of data from a comma-delimited file might look like: Name,Age,Gender,Occupation,Yearly,Salary Jim,25,Male,Accountant,65,000 Read delimited files into SPSS by going to File - Read Text Data. First, locate the name of the text file and click Open. Answer the questions as you go along, clicking Next to move on to the next question. Be sure to choose the Delimited file type, and identify the character (comma, space, tab, etc) that acts as the delimiter. Similarly, read fixed-column data files by going to File - Read Text Data. Open the file containing the text data. Follow along with the questions, clicking Next to move along. Be sure to select the Fixed width option. You may name the variables for either delimited or fixed width files during the import procedure, or after the data have already been read into the Data Editor. Sometimes the variable names are already in the top row of the text file. You will be able to tell SPSS whether these names are present or absent in the text file. Note that for fixed width data, particularly when many variables are involved, it may be easier to use syntax commands rather than the menus. This will provide a record of how the data were imported, and it will allow you to stop and resume the import process in a later SPSS session. When using the menus, there is no way to stop halfway through and save your work. 2.8 Exporting Data from SPSS To save files in a certain format so that you can move data from SPSS to another program (this is exporting from SPSS), make certain you are in the Data Editor window, and go to File -&gt; Save As and then select “File Type”. Be sure to give this new file a name. You can export to most of the same file types as you can import. You can also select a subset of variables to save in a new data file by selecting the “Variables…” button in the “Save Data As” window. Once you have selected the variables that you want for the new data file, select “Continue” then “Save”. Try it: Select File - Save As. Investigate the different file types. Select the “Variables” button and investigate. 2.9 Exercise 2 – Importing/Exporting Excel Open exercise2_data.xls (an Excel file). Modify this Excel file such that it can be imported into SPSS properly. Save the file and close it. Open the file in SPSS (import it). Export this file back into Excel, but only save the following variables: id, salary, minority. 2.10 Getting Help from SPSS Underneath the help menu are several different options. Here are a few: “Topics” Search for a word or command “Tutorial” Get an introduction to some SPSS basics “Case Studies” Look at some example analyses using SPSS “Statistics Coach” Get help in choosing the right statistical procedure “Syntax Reference” View syntax manuals in their complete form (.pdf) “SPSS Home Page” Open an internet browser and go to www.spss.com “About” View version number and license expiration date “Product Registration” Renew the license once it has expired When looking at a help entry for a statistical procedure, there will usually be a link labeled “Show Me”, which provides explicit instructions for carrying out the procedure via an example. The “Command Syntax Reference” menu allows users to access the entire text that can be found in the hard-copy manuals. The on-line manuals open in Adobe Acrobat Reader and come with an index of topics. Click on any page number to go instantly to that page. Helpful Hint: when examining the on-line syntax guides, click the small button at the bottom marked “100%” and choose 150% or 200% for easier reading. "],
["working-with-variables.html", "Chapter 3 Working with Variables 3.1 Variable View in Data Editor 3.2 Exercise 3 – Variable Attributes 3.3 Creating New Variables and Defining the Correct Attributes 3.4 Computing Variables 3.5 Automatic Recoding 3.6 Conditional Transformations with If/Then Logic 3.7 Rank Cases 3.8 Exercise 4 – Computing and Transforming Variables", " Chapter 3 Working with Variables Data for this section: section3_data.sav 3.1 Variable View in Data Editor Variables in SPSS vary in length and may consist of letters, numbers, dates, or dollar values. Some values, such as “don’t know” replies on a survey, may be codes for missing values. SPSS allows you to label variables and values with more meaningful phrases that can appear in the output for greater clarity. To view or edit the current format for a variable, double-click on the variable’s name in the Data Editor. Doing this will open the Variable View tab in the Data Editor window. Alternatively, select the “Variable View” tab at the bottom left corner of the data editor window. Try it: Open section3_data.sav. Select “Variable View”. There are eleven columns in the Variable View, containing values that are attributes for the variables that you can change: Name The name of each variable in the data set Type The type (numeric, character, date, etc) and length Width The amount of information in bytes stored in memory Decimals The number of decimals displayed for numeric vars Label A specific label for a variable Values Variable value labels Missing Missing value codes Columns Column width for variable display Align The alignment of values within a cell Measure The measurement scale for a variable Input The role of the variable when analyzing the data 3.1.1 Variable Name Be sure the names follow these rules: Variable names should be no more than 64 characters long, and preferably no more than 8 characters long. Variable names must start with a letter. Variable names may only have letters, numbers, or underscores in them. Variable names may not have the following characters: %,$,#,@,!,+,*,~,\",-,.. Variable names may not have blank spaces. Each variable name must be unique; the same variable name can’t appear twice. Variable names must be on one row only. 3.1.2 Variable Type The most fundamental characteristic of a variable is its type. These are the four most important types: Numeric includes comma, dot, and scientific notation types String also called character, alpha, or alpha-numeric Dollar includes custom currency type but is still numeric Date is still numeric but displayed using hours, minutes, and seconds Most statistical analyses use only numeric variables. SPSS can handle a short string variable, such as gender coded as “m” and “f”, when that variable defines groups for a t-test or an analysis of variance (ANOVA). The Dollar type changes the way the values appear in the data editor and the output, but all analyses treat the Dollar type as numeric. The appearance of a date variable does not affect the way that the .sav file stores the date. SPSS understands date/time variables as the number of seconds since midnight, October 14, 1582 which is a significant date marking a change in the Gregorian calendar. If you subtract one date from the other to create a new variable, the result will be in seconds. To change back to days, hours, or years, it is necessary to use a function to turn the information into a more usable, practical form. See the section Computing New Variables for more information. Try it: Use section3_data.sav. Change the Variable Type for the ID variable from Dollar to Numeric. 3.1.3 Variable Labels Variable labels attach a description to a variable, and this description can show up in the output. To enter a variable label, click in the Label cell for a given variable in Variable View, and enter a description for the variable. Variable labels can be up to 255 characters as of Version 15.0. Try it: Use section3_data.sav. Provide a label for DepScale (Depression Scale 1998). 3.1.4 Value Labels Value labels are similar, except that they refer to specific values within that variable. You don’t have to enter labels for all values. A value label can be up to 120 bytes long. Suppose the following question was in a survey: Which of the following describes your political beliefs best? 1) Democrat 2) Republican 3) Libertarian 4) Other You will enter the responses as 1, 2, 3, or 4. These numbers are arbitrarily, however, and some users may not know or may forget their meaning. Value labels allow the user to attach meaning to the numbers. Value labels are absolutely critical in large data files. Like variable labels, value labels will appear in many of the results provided by SPSS. To assign value labels, click on the Values cell for a given variable, and click on the small grey box. Enter a number in the Value box, then the corresponding label in the Value Label box. Then press “Add”. If you do not press “Add”, the information you have typed for that value will be ignored. Try it: Use section3_data.sav. Enter in value labels for variable Education: 1: High School or Less 2: Some College 3: College Graduate 3.1.5 Missing Value Labels There are two kinds of missing values: system-missing, in which the cell is empty, and user-missing, which flags a value as an invalid response. There often could be several reasons that a value is not available, and user-missing values allow us to discriminate between them. Examples of user-defined missing values are: 99 “Don’t Know” reply on a survey 777 Inapplicable, such as with number of births for a male respondent -999 Respondent refused to answer, which often occurs with income Enter user-missing values just like any other response during data entry. You need to tag the value as missing, however, so that SPSS does not include it in any computations. Consider the repercussions if we forgot to specify the 777 in the above example as Inapplicable, and then attempted to calculate the average number of births! You can specify user-missing values by clicking on the cell in the Missing column for a given variable, and then clicking on the small grey box that appears as “(…)”. You may specify single values or a range of values. Try it: Use section3_data.sav.Enter missing value codes for Education (99). 3.1.6 Columns &amp; Alignment You can change the alignment of the data by changing the Columns or Align attributes. You can use the Align attribute to center values or align them to the right or left of the cell in the Data Editor. Additionally, you can decrease or increase the width of the columns using the Columns attribute. A shortcut is to place the mouse at the right edge of a variable name, click on the border, and drag the column to be wider or narrower. Asterisks (*) in the cells within a particular column mean that the column is not wide enough to display the data values. Simply increase the column width and the values should appear properly in the Data Editor. Another possible problem might be that the width is too small to display all of the information for a variable. The Columns and Align attributes have no effect on the data; they only affect the way you see the data in the editor. 3.1.7 Measure Each variable in SPSS may be designated as Scale a continuous variable Ordinal a categorical variable with natural ordering Nominal categorical without any natural ordering Graphs from the Interactive graphics method use this information. This field has no bearing for most procedures. Try it: Use section3_data.sav. Change the Measure for the Education variable from Scale to Ordinal. 3.1.8 Copy and Paste Variable Attributes You can set up any of the attributes discussed above, such as type, labels, missing values, and column format, and apply them to numerous variables all at once. Suppose a researcher has a series of 50 variables that all have values 1 through 5 as follows: 1 Strongly disagree 2 Disagree 3 Neutral 4 Agree 5 Strongly agree Value labels would be useful for these variables, but it would be extremely tedious to set up value labels for all 50 variables. Set up the value labels for one of the 50 variables, and then click on the cell containing the value labels for that variable. Select “Copy” from the “Edit” menu or hit CTRL + C, and then highlight the value labels cells for the remaining 49 variables by clicking on the first empty cell and dragging downward. Select “Paste” from the “Edit” menu or hit CTRL + V, and the value labels will be applied to the remaining 49 variables instantly. You can also right-click and use the copy and paste functions. You can use this same copy and paste feature for other variable attributes and save a great deal of time! Try it: Use section3_data.sav. Copy and paste the missing value code from Education to DepScale. 3.2 Exercise 3 – Variable Attributes Open exercise3_data.sav and go to Variable View. Practice defining the correct attributes to each variable by following the code book below. Name Label Value Label Missing Values Measure IDnum Scale sex Respondent’s Sex 1 = Male Nominal 2 = Female race Race of Respondent 1 = White Nominal 2 = Black 3 = Other region Region of the United States 1 = North East Nominal 2 = South East 3 = West happy General Happiness 0 = NAP 0, 8, 9 Ordinal 1 = Very Happy 2 = Pretty Happy 3 = Not too Happy 8 = DK 9 = NA life Is Life Exciting or Dull 0 = NAP 0, 8, 9 Ordinal 1 = Exciting 2 = Routine 3 = Dull 8 = DK 9 = NA sibs Number of Brothers and Sisters 98 = DK 98, 99 Scale 99 = NA childs Number of Children 8 = Eight or More 9 Scale 9 = NA age Age of Respondent 98 = DK 0, 98, 99 Scale 99 = NA educ Highest Year of School Completed 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA paeduc Highest Year School, Father 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA maeduc Highest Year School, Mother 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA seeduc Highest Year School, Spouse 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA prestg80 Occupational Prestige Score 0 = DK,NA,NAP 0 Scale occcat80 Occupational Category 1 = Managerial and Professional Nominal 2 = Technical and Sales 3 = Service 4 = Farming, Forest, and Fishing 5 = Production and Craft 6 = General Labor 3.3 Creating New Variables and Defining the Correct Attributes To create a new variable in SPSS for entering data, simply double-click on an empty column’s heading, or start entering data directly into the column in Data View. To enter values, first click in an empty cell; then type each value and press either return or the down arrow. During data entry, be aware that the order of cases in an SPSS data file can change because certain procedures require that cases be sorted. Therefore, be careful to match values with an ID variable. The case that occupied the first row in the file a week ago may not be in the first row any longer! New variables, including those created by computation or recoding, appear at the far right of the data file. Use the scroll bar at the bottom to verify that a new variable was properly created. Cut, copy, or paste a variable or insert a new empty column by right clicking on a variable name. A pasted variable is not inserted in between existing variables. It replaces the highlighted column entirely, and could over-write an existing variable. Be sure to create a new, blank column and paste on top of that. Try it: Use section3_data.sav. Create a new variable called NewVar. 3.4 Computing Variables You can use the COMPUTE command to create new numeric or string variables by: Assigning a particular value to all cases, or a subset of cases Transforming a variable by taking a log, or another mathematical function Creating a sum, average, or other summary of several existing variables Helpful Hint: You can use the COMPUTE procedure to edit or overwrite an existing variable, but we highly recommend that you create new variables. If you do over-write an existing variable, be aware that some old values may not be overwritten. If some of the necessary information is missing for a certain case in the file, and the software cannot compute the new value, then the value from the old variable will remain. Select Transform - Compute Variable and enter a name for the new variable in the upper left box, labeled “Target Variable.” SPSS will automatically create the new variable when it executes the compute command. By default, SPSS assumes that the user wants to compute a numeric variable. If you want to create a string variable, click “Type &amp; Label” underneath the new variable name, and select “String.” In the box titled “Numeric Expression”, provide the actual formula or value for the new variable. You may write the numeric expressions by hand or insert variables and functions using the mouse. Helpful Hint: Click on the function name to get a function description in the dialogue box. If you want to create new dollar or date variables, then proceed as if creating a numeric variable. The type can be changed after the compute command is used. Note that seconds are the units of measurement for date variables. To create date variables, we must use functions specifically designed for the date variable type. See the List of Functions below for more information. 3.4.1 Dealing with Missing Data Applying a function to a variable containing missing values will result in a variable with corresponding system-missing values. When taking the mean or sum of a set of variables, be sure to use the mean() and sum() functions. SPSS only evaluates formulas such as “(var1 + var2 + var3 + var4)/4” if all four variables have valid, non-missing values. By contrast, the software evaluates the formula “mean(var1, var2, var3, var4)” as long as an individual has at least one valid response. You can also stipulate that SPSS perform the calculation only when there are a minimum number of valid responses. The formula “mean.3(var1, var2, var3, var4, var5)”, for example, would mean that an individual must have answered at least 3 of the 5 questions. The new variable will have a missing value otherwise. Try it: Use section3_data.sav. Calculate the average depression score using DepScale_01, DepScale_02, DepScale_3. First use the function “mean”. Next write the expression by hand. Investigate the differences. 3.4.2 List of Functions Available in the Compute Command Arithmetic Operators: + Addition - Subtraction * Multiplication / Division ** Exponentiation Arithmetic Functions: ABS Absolute value RND Round TRUNC Truncate MOD Modulus (remainder) SQRT Square root EXP Exponential LG10 Base 10 log LN Natural log ARSIN Arcsin ARTAN Arctangent SIN Sine COS Cosine Statistical Functions: SUM(.n) Sum of arguments MEAN(.n) Mean of arguments SD(.n) Standard deviation of arguments VARIANCE(.n) Variance of arguments CFVAR(.n) Coefficient of variation of arguments MIN(.n) Minimum of arguments MAX(.n) Maximum of arguments Missing Values Functions: MISSING True if the value is missing NMISS Number of missing values across variables but within cases NVALID Number of non-missing values across variables but within cases Across-case Function: LAG Value from previous case, or from n cases earlier if there is a second argument n Date and Time Functions: CTIME.xxx SPSS time values to common units DATE.xxx Common units to SPSS date values TIME.xxx Common units to SPSS time values XDATE.xxx SPSS date values to common units Other Functions: RV.UNIFORM Uniform pseudorandom no. RV.NORMAL Normal pseudorandom no. CDF.NORMAL Standard normal cumulative dis. Logical Functions: RANGE True if value is within range ANY True if any value matches String Functions: ANY Same as for numeric values CONCAT Concatenate INDEX Index from left LAG Same as for numeric values LENGTH Defined length LOWER Convert to lower case LPAD Pad left LTRIM Trim left MAX Greatest value MIN Least value NUMBER Convert to a number RANGE Same as for numeric values RINDEX Index from right RPAD Pad right RTRIM Trim right STRING Convert to a string SUBSTR Substring UPCASE Convert to upper case 3.4.3 Count Values One useful way to compute new variables is through the “Count Values within Cases” procedure. This procedure counts how many times particular values occur, within each case, across certain variables. Suppose we have a data set of students where we recorded their scores on ten separate quizzes over the course of a semester. We could use “Count Values within Cases” to tally up the number of A’s each student earned. To use the Count Values within Cases procedure: Go to Transform - Count Values within Cases. Specify a new variable name under “Target Variable”. Place the variables to be examined in the “Variables” box. Click “Define Values”, and type the values to be counted. Click “Continue”, then “OK”. Recoding Variables Recoding a variable means changing or “mapping” its values to new ones. Often, you will need to convert string variables into numeric variables in order to use them in a certain statistical procedure. Recoding is also a way to collapse a continuous variable into categories. Below are representations of some possible recodes: “Male” – 1 “Female” – 0 1 – 0 2 – 1 3 – 2 4:15 – 9 3.4.4 Manual Recoding There are two ways to recode in SPSS: Recode Into Same Variables Not Recommended Recode Into Different Variables Recommended By using “Recode Into Different Variables”, your original variable will not change, which is not the case with “Recode Into Same Variables”. “Recode Into Same Variables” is risky since you will not be able to undo the changes if you make a mistake. Select Transform - Recode into Different Variables\" In the “Recode Into Different Variables” dialogue box: Select the old (original) variable. Specify a new variable name, and click “Change”. Click “Old and New Values”. Specify each old value, or range of values, on the left side of the box and each new number you want assigned on the right side of the box. Click “Add” each time. Make sure you include every original value. Unmentioned original values become missing values in the new variable. Click “Continue”. Click “OK”. Note that when using “Recode Into Different Variables”, it is also possible to recode a numeric variable into a character (string) variable, or vice-versa: Check the box marked “Output variables are strings” to change from numeric to string in the “Old and New Values” window Check the box marked “Convert numeric strings to numbers” to change from string to numeric in the “Old and New Values” window. Try it: Use section3_data.sav. Recode Gender with F=1 and M=2. Inspect the output. [ 3.5 Automatic Recoding The Automatic Recode procedure recodes any variable’s values into consecutive integers 1, 2, 3, etc…. The software codes the lowest numeric value, or the first value in alphabetical order in the case of string variables, to a 1 by default. The next lowest number or next item in alphabetical order becomes a 2, and so forth. Optionally, the recoding can begin with the highest number of the last string value in alphabetical order. Automatic Recode always creates a new variable. Helpful Hint: Automatic Recode is a quick way to make string variables (e.g., gender) ready for statistical procedures that require numeric variables. To use Automatic Recode: Go to Transform - Automatic Recode. Choose the original variable to be recoded. Specify a new variable name and click “Add New Name”. Select the order – start numbering from smallest or largest values. Helpful Hint: If you had assigned value labels for the old variable, those labels will carry over to the corresponding new values. If there were no value labels, then the old values themselves become the new labels. Try it: Use section3_data.sav. Use Automatic Recode to recode Gender. Call this new variable AutoGender. 3.6 Conditional Transformations with If/Then Logic The “If” button, which appears in the Compute, Recode, and Count dialogue boxes, represents an important feature in variable transformations. Using the “If” option, users can tell SPSS to perform calculations or recodes only if cases meet certain conditions. For example, suppose we surveyed women regarding the number of times they had given birth, but women who had never been pregnant skipped that section of the questionnaire. We might now want to assign a “0” for the number of births for those women who had never been pregnant, to replace the missing entry they currently have. Assuming that we have a string variable called “everpreg” coded “Y” and “N” for yes and no, and that our number of births variable is called “numbirth”, we would proceed as follows: Go to Transform - Compute Variable Put numbirth in the “Target Variable” box. Place a 0 in the “Numeric Expression” box. Click “If”. Click “Include if case satisfies condition”. Type everpreg = “N” in the condition box. Click “Continue” and “OK”. This “If” button, which allows transformations to take place for selected cases only, works exactly the same in the Compute, Recode, and Count procedures. You can use the words and, or, and not within the If box to help write your criteria. Some examples of If expressions are as follows: sex = \"f\" and age &gt; 50 - women over 50 not missing(income) - participants whose income is known educat = 5 or educat = 6 - respondents with a BA or MA 3.7 Rank Cases You can perform variable transformations based on the ranked value for a particular variable. It may be more convenient to analyze the quartiles, for example, than the variables themselves. Select “Transform” and then “Rank Cases” to recode a continuous variable into a new variable based on rank. Select the variable of interest and then click “Rank Types”. You can select quartiles in this dialogue box by checking the box for Ntiles and placing the number 4 in the blank space. SPSS will create a new categorical variable and add it to the end of the original dataset. 3.8 Exercise 4 – Computing and Transforming Variables Open exercise4_data.sav. Compute a new variable that is the change from beginning salary to current salary for each employee. Recode the education variable into a new variable according to the following 1=High School or Less (educ&lt;=12) 2=Some College (12&lt;educ&lt;=16) 3=Bachelor’s Degree or Higher (educ&gt;=17) "],
["understanding-data-management-tasks.html", "Chapter 4 Understanding Data Management Tasks 4.1 Sorting Cases 4.2 Analyzing Subsets of Data 4.3 Analyzing Groups of Data Separately 4.4 Exercise 5 – Subsetting Data 4.5 Converting Data Formats 4.6 Exercise 6 – Restructuring I (Wide to Long) 4.7 Exercise 7 – Restructuring II (Long to Wide)", " Chapter 4 Understanding Data Management Tasks Data for this section: section4_data.sav 4.1 Sorting Cases Sorting cases based on a particular variable is often necessary when managing data sets. Go to Data - Sort Cases to place the cases in order. Choose the variable that determines the ordering, and choose “Ascending” or “Descending”. Selecting the ID variable and choosing “Ascending” will place the subject with the smallest ID number in the top row. The bottom row will contain data on the subject with the largest (highest) ID number. When sorting by more than one variable, SPSS sorts the data initially based on the first variable. Within each value of that first variable, it sorts again based on the second variable. Make sure to select “Ascending” or “Descending” for each variable when you are sorting by multiple variables. Highlight the variable by clicking on it, and choose the correct ordering. Suppose we want to sort by gender and then by age, with both in ascending order. Suppose the codes for gender are as follows: 0: male 1: female SPSS would first put males at the top of the file and females at the bottom. SPSS would then sort by age within each gender group. The first rows of the data set would contain the youngest men in the sample and the last subjects at the bottom would be the oldest women in the sample. 4.2 Analyzing Subsets of Data You can use the “Select Cases” command to instruct the software to calculate statistical results or summaries based on only some of the cases in the data set. You can define the subset by certain characteristics, such as women over age 40, or you can instruct the software to select a random sample of cases with size that you specify. Note: The Select Cases procedure affects which cases that SPSS includes in analysis and output only. It has no effect on transformations of the data, such as computing, recoding, or counting. Selecting cases involves turning on a filter that handles the inclusion of certain cases and the exclusion of others. When the filter is on, analyses or summaries will only use the selected cases. There will be a message “Filter On” at the bottom right of the Data Editor window whenever SPSS is using only selected cases. The first time you invoke the “Select Cases” procedure, the software creates a variable called filter_$ in the data set. This variable is equal to 0 for excluded cases and 1 for included cases. SPSS deletes and then re-creates the filter_$ variable each time you run “Select Cases”. Users can specify their own filter variable. He or she can use any variable as a filter as long as a value of 0 for that variable indicates exclusion and a value of 1 inclusion. Click the “Use filter variable” option under Data - Select Cases to do this; move your filter variable into the box. 4.2.1 If Condition is Satisfied Go to Data - Select Cases\" to use only some of the cases. Click “If condition is satisfied….” to select cases based on certain criteria. Then click the “If…” button to pull up a window in which you will state the condition. Some example conditions are: gender = 'm' - selects men only age &lt;= 12 and sex = 2 - selects children 12 and under of one sex only marital = 0 -selects all never married respondents You can return to the data editor by clicking “Continue” and “OK”. Notice that certain rows have been “scratched” out by SPSS. SPSS has filtered out these cases because they did not satisfy the specified condition. Analyses will only use those cases that are not scratched out. To return to the entire sample, go to Data - Select Cases, choose the radio button next to “All Cases,” and then click “OK”. The “Filter On” message will disappear and all results from that point on refer to the entire data set. 4.2.2 Randomly Selecting Subsets You may examine a randomly selected portion of the data by clicking “Random Sample of Cases” in the “Select Cases” window. Then click the “Sample…” button. You can then give an approximate percentage. If you want to take an exact number of cases, first determine the total number of cases (rows) and place this number in the “from the first --- cases” segment of the dialogue box. If you would like to take a precise number of cases from, say, all women, or all children under twelve, then sort the data first so that the cases of interest occupy the first rows. Determine the last row that refers to a female, or to a child under twelve, and proceed as above. Note: When SPSS selects cases randomly, repeated selections will be different even when everything specified by the user has stayed the same. An approximate 30% sample of cases will result in a different 30% each time the user repeats the procedure. Helpful Hint: To use the same random selection of cases over and over again, first take the initial random sample. Then re-name the filter_$ variable to any name of your choosing. SPSS will leave the variable alone, and you can re-use the filter in consecutive SPSS sessions. 4.2.3 Output Options At the bottom of the “Select Cases” dialogue box are three options: Filter out unselected cases (recommended) Copy selected cases to a new dataset (recommended) Delete unselected cases (NOT RECOMMENDED) If you set this to “Filter out unselected cases”, the unselected cases remain in the data set but the software temporarily excludes them from all analyses. If you choose the second option, SPSS copies the selected cases to a new dataset and you can save the dataset on your disk by assigning a file name. The content of your original dataset remains untouched with these two options. If the you change the option to “Delete unselected cases”, unselected cases disappear from the data entirely. Be careful when permanently deleting cases, because you CANNOT undo the deletion. Make sure to first save your data file under a different name if you wish to permanently delete cases. Try it: Use section4_data.sav. Select only observations with Education = 1 for analysis. 4.3 Analyzing Groups of Data Separately When analyzing groups of cases separately, such as men and women, the Split File command spares you from having to repeatedly select different groups of cases. The Split File command first sorts the data into groups based on a specified variable. After that, SPSS generates any requested output for each group separately. If we split the file based on gender and then request the mean current salary, we would receive a mean current salary for men and a mean current salary for women. A flag at the bottom right of the data editor will read “Split File On” when you are using this option. You can use multiple variables to divide the data. If you use both gender and job category as grouping variables, for example, then SPSS will give all output for each job category group within each gender. To use Split File: Go to Data - Split File. Click on “Compare Groups” or “Organize Output by Groups”. Select variable(s) which divide the data into groups. Click OK. To turn off the Split File command, return to Data - Split File and click on “Analyze all cases, do not create groups”. Try it: Use section4_data.sav. Obtain the descriptive statistics for DepScale_01 for males and females separately. Hint: Select Analyze - Descriptive Statistics - Descriptives. 4.4 Exercise 5 – Subsetting Data Open exercise5_data.sav. Select male managers. What is their average age? (You can obtain the average age by choosing Analyze - Descriptive Statistics - Descriptives and moving “Age of Respondent (age)” to the right hand side.) Use the “Split File” procedure to get the average age for each job category. 4.5 Converting Data Formats Different statistical methods frequently require different data formats. A repeated measures analysis of variance, for example, requires that data be in Wide format, while a linear mixed model requires that the data be in Long format. SPSS makes it easy to convert between the two formats. The examples below demonstrate how to use the wizard in SPSS. To convert a dataset from one format to the other, first select “Data” and then “Restructure”. SPSS uses terminology that differs from conventional phrasing. Wide to Long Variables into Cases Long to Wide Cases into Variables We will briefly discuss these two variations, before doing exercises together which include the instructions. 4.5.1 Wide to Long (AKA “Variables into Cases”) There are seven steps in this Wizard: Identify the restructuring plan to be from “Variables into Cases”. Select the number of variable groups. Select variables. Create index variables (usually one). Create one index variable. Choose options. Finish. 4.5.2 Long to Wide (AKA “Cases into Variables”) There are five steps in this Wizard: Identify the restructuring plan as “Cases into Variables”. Select variables. Sort the data. Choose options. Finish. 4.6 Exercise 6 – Restructuring I (Wide to Long) Convert exercise6_data.sav from “Wide” format to “Long” format 4.7 Exercise 7 – Restructuring II (Long to Wide) Convert exercise7_data.sav from “Long” format to “Wide” format (Both exercises to be done together.) "],
["understanding-graphical-statistical-procedures.html", "Chapter 5 Understanding Graphical &amp; Statistical Procedures 5.1 Thinking About Statistics 5.2 Correlation vs. Causation 5.3 Everything On One Page Handout 5.4 Parametric vs. Non-parametric Tests 5.5 Basic Summary Statistics (Investigate One Variable at a Time) 5.6 Visualizations 5.7 Normality 5.8 Exercise 8 – Data Exploration and Visualization 5.9 Investigating Two Variables at a Time 5.10 Investigating Many Variables at a Time 5.11 Repeated Measures, Longitudinal, Clustered, Multilevel, Mixed Procedures 5.12 Other Procedures in SPSS", " Chapter 5 Understanding Graphical &amp; Statistical Procedures Data for this section: section5_1_data.sav, section5_2_data.sav 5.1 Thinking About Statistics Statistics is in a sense a giant toolbox containing a collection of graphical and statistical procedures. Each graphical or statistical procedure is good for a particular situation we may run into while doing data analysis. The main purpose of any graphical and statistical procedure is to investigate a variable or the relationships between variables. That is a very important concept! THE MAIN PURPOSE OF ANY GRAPHICAL OR STATISTICAL PROCEDURE IS TO INVESTIGATE A VARIABLE OR THE RELATIONSHIPS BETWEEN VARIABLES. Keep in mind that graphical procedures can be more valuable to you than statistical procedures. You should try to express your results in graphs whenever you can. It is not hard to implement or interpret any graphical or statistical procedure once you understand and can explain the procedure. SPSS is very helpful in both regards. The biggest challenge facing any researcher is to know the most appropriate procedure to apply in any particular situation. The types of the independent and dependent variables (predictors and outcome) will guide your choice for the appropriate graphical and statistical procedure. Just like in many things in life, the 80/20 rule somewhat applies to statistics. There are a small number of procedures that you will use more repeatedly than others. Here, we will divide those essential procedures, graphical and statistical, into 4 major classifications: One Variable Only Procedures One-on-One Procedures investigating two variables at a time Many-on-One Procedures Repeated, Longitudinal, Clustered, Multilevel, and Mixed Procedures 5.2 Correlation vs. Causation The presence of a correlation between two variables DOES NOT imply that there is causation between them. Any of the three scenarios below could explain the correlation between two variables A and B. We can’t tell using statistics alone which scenario it is. A causes B B causes A C causes both A and B 5.3 Everything On One Page Handout The chart below lays out the essential graphical and statistical procedures by type and classification. 5.4 Parametric vs. Non-parametric Tests There are varying assumptions that underlie the validity of each statistical procedure. A common assumption for statistical procedures is that the samples being analyzed should come from an underlying normal distribution. If this is not a reasonable assumption, you can use non-parametric tests. Non-parametric tests do not have this distributional assumption, and generally use ranks in the place of the raw scores. The table below gives non-parametric tests that are equivalent to common parametric tests. 5.5 Basic Summary Statistics (Investigate One Variable at a Time) As the name implies, One-Variable-Only Procedures help us investigate a single variable at a time. They can tell us about the frequency distribution of a categorical variable (Frequency Table, Mode, Bar Graph, Pie Chart, etc.). They can give us insight into the central tendency of a continuous variable (Mean, Median, Mode, etc.). They can help us test a hypothesis about the mean of a variable (One Sample t-test). They can give us insight into the dispersion of a variable (Standard Deviation, Range, Inter-Quartile Range, Boxplots, Error Bar Plots, etc.). They can also give us insight into the relative position of any data point with respect to the other data points in a variable (Percentiles, Quartiles, Boxplots, etc.). In SPSS, there are two procedures which provide simple descriptive statistics. You can find both procedures under Analyze - Descriptive Statistics. Frequencies procedure provides the number and % of cases which have each value of a variable (e.g., 46% male, 54% female). You can request other output by clicking Statistics. Frequencies are most useful for categorical variables. Try it: Use section5_1_data.sav. Obtain the frequency (descriptive) statistics for the variable Sex. Descriptives provides the mean, standard deviation, minimum, maximum and non-missing sample size by default. Other statistics are available by clicking Options. Descriptives are most useful for continuous variables, and sometimes useful for ordinal data (categorical data with ordering, e.g., small, medium, large) alongside the frequencies. Try it: Use section5_1_data.sav. Obtain the descriptive statistics for the variable Age. As a first step in data analysis, one might run frequencies on all categorical variables and descriptives on all continuous variables. Obtaining descriptive statistics is an important step to detect possible data entry errors. 5.6 Visualizations There are two methods for creating charts in SPSS, Chart Builder and Legacy Dialogs. (There is a third method, in which other analysis methods create their own graphics, but we’re covering only direct creation of graphics here.) The newer approach is Chart Builder, which is a more free-form approach. It has a steeper learning curve but is ultimately more powerful. The classic approach is legacy dialogs which are much easier to use, but more restrictive in the types of plots they can create. 5.6.1 Chart Builder To create a graph in “Chart Builder”, first select the type of graph that you would like to create by dragging and dropping the appropriate graph image to the “Chart Preview” area. Once you select a chart, the Element Properties window will appear. The Element Properties window allows you to modify what is displayed in the graph Try it: Use section5_1_data.sav. Create a simple bar chart for “Region”. 5.6.2 Legacy Dialogs The “Legacy Dialogs” interface requires that you determine the type of graph you would like to create before providing a dialog box, which is similar to other procedures in SPSS. After you select the general type of graph or chart, SPSS will then prompt you to be more specific. If the general form is a scatter plot, for example, SPSS will ask you to then specify which type of scatter plot you would like to create. The software will present you with the graphing dialogue box once you specify the specific form for the graph. Try it: Use section5_1_data.sav. Create a simple bar chart for “Region”. 5.7 Normality Many statistical procedures assume “normality”, which means the population which the data is from follows the Normal Distribution. You may know this as the “bell curve”. Many real-life variables follow a normal distribution such as height. If you were to collect a random sample of heights, most people would fall near the mean height for the population. Some people would be much taller or shorter, and a very limited number of people would be extremely short or extremely tall. The normality assumption as written is usually quite strict; in practice we often loosen it. Rather than “The data comes from a normal population”, you can think of it as “The data comes from a population that’s not too badly non-normal.” Essentially, you’re looking for major violations of normality, rather than trying to determine whether the bell curve perfectly fits your data. Finally, a large sample size oftens “protects” you from normality violations; the larger the sample size, the more extreme a normality violation needs to be to be a concern. While there are formal tests of normality, typically assessment is done with a histogram (looking for that bell shape) or a QQ-plot, which looks for its values to fall along the 90° line. The histogram can be created from the Histogram Legacy Dialog, the QQ-plot is created under Analyze - Descriptive Statistics - QQPlot. Try it: Use section5_1_data.sav. Obtain a histogram for the variable “Age” and display the normal curve. Obtain a QQ plot for the variable “Age”. Hint: Analyze - Descriptive Statistics - QQPlot. 5.8 Exercise 8 – Data Exploration and Visualization Open exercise8_data.sav Part 1: Investigate the variable attributes. Determine which variables are categorical variables (nominal and ordinal), and which variables are continuous (scale). Obtain the appropriate descriptive statistics for each variable. Remember, continuous variables should be investigated with descriptives and categorical variables should be investigated with frequency tables. *Hint: Select more than one variable in the “Analyze”,“Descriptive Statistics”,“Descriptives”, or “Frequencies” dialog boxes. Part 2: Assess the distribution of the Occupational Prestige Score (“prestg80”) with both a histogram (normal curve displayed) and a Q-Q plot. Is the assumption that the population of Occupational Prestige Scores is normally distributed reasonable? Part 3: Compare the average highest year of school completed (“educ”) for males and females. *Hint: First split the file by “sex” (Data - Split File), then calculate the descriptive statistics. Be sure to return to the Split File menu when you are done with this question and return the dialog box to “Analyze all cases”. Part 4: Produce a pie chart for the variable “region”. (We didn’t cover this, you can use either Chart Builder or Legacy Dialogs.) 5.9 Investigating Two Variables at a Time The main purpose of any graphical and statistical procedure is to investigate a variable or the relationships between variables. We start by examining the relationship between variables using simple two-variable procedures. The type of independent and dependent variables that you would like to investigate determines the appropriate statistical or graphical procedure. Remember that the presence of a correlation between two variables DOES NOT imply that there is causation between them. 5.9.1 Pearson Correlation Coefficient &amp; Scatterplots The Pearson Correlation Coefficient measures the linear association of two continuous variables. A scatterplot is an easy way to visually explore the association between two variables. When you plot the variables together, you obtain a clear sense of the overall relationship between the two variables. The Pearson Correlation Coefficient (Pearson’s r) varies from -1 to +1. A value of zero indicates that there is no linear relationship between the two variables, a value of +1 indicates that there is a perfect positive linear relationship, and a value of -1 indicates that there is a perfect negative relationship. Positive relationships imply that variable 2 increases when variable 1 increases, and vice versa, while negative relationships imply variable 2 increases when variable 1 decreases, and vice versa. The statistical significance of a correlation is the chance that you would observe a correlation that high or higher if there really was no correlation between the variables. For the Pearson Correlation Coefficient in SPSS, select Analyze - Correlate - Bivariate. For the Scatterplot in SPSS, select Graphs - Legacy Dialogs - Scatter/Dot, choose “Simple Scatter”, and click “Define”. Try it: Use section5_2_data.sav Investigate the correlation between the individual behavior intention scales. Select Analyze - Correlate - Bivariate. Select “BIndBehInt_Pre” and “BIndBehInt_Post”. Select “OK”. The table indicates that there is a significant correlation between the pre intervention and post intervention behavior scale scores. Our p-value (Sig (2-tailed)) is less than our predetermined 0.05 level of significance, so we reject the null hypothesis that there is not an association between these two variables. The correlation coefficient is positive, indicating that high scores for one variable correspond to high scores for the other variable. Conversely, low scores for one variable correspond to low scores for the other variable. Individuals who scored high on the pre-test also tended to score high on the post test. To visually investigate this relationship, use a scatterplot: Select Graphs - Legacy Dialogs - Scatter/Dot. Select “Simple Scatter” and “Define”. Select “BIndBehInt_Post” for the Y Axis. Select “BIndBehInt_Pre” for the X Axis. Select “OK”. The scatterplot indicates a linear relationship between the two variables. 5.9.2 Pearson Chi-Square Crosstabs and Test of Independence The Chi-square test is very common way to explore the relationship between two categorical variables. This tests the null hypothesis that there is no relationship between the two variables, and rejecting the null hypothesis allows us to conclude that the variables have a statistically significant relationship with each other. Suppose that we’re interested in determining if there is a significant relationship between smoking status and lung cancer status. Our variables are: Smoking Status (1=Yes, 0=No) , and Lung Cancer Status (1=Diagnosed, 2=Not Diagnosed). We can summarize these variables in a 2x2 table called a crosstab where the cell values represent the counts in our data that fall in those particular categories. We can perform a Chi-square test to determine if there is a relationship between smoking and lung cancer. Select Analyze - Descriptive Statistics - Crosstabs for the Chi-square test of independence and make sure to check the box “Chi-Square” under “Statistics”. You can produce a clustered bar chart to visualize this table by checking the box for “Display Clustered Bar Chart” in the “Crosstab” dialog box. Try it: Use section5_2_data.sav. Are females more likely to participate in jokes that are derogatory to any racial group? Investigate the data to see what types of variables we have to answer this question. We have the categorical variable “Sex” and the categorical variable “Joke”. Since we are comparing two categorical variables, we will use a Chi-square test. Select “Analyze” “Descriptive Statistics” “Crosstabs”. Select “Sex” for rows, “Joke” for column, check the box to “Display clustered bar charts”. Select “Statistics” and check the box for “Chi-Square”. Select “Continue” and the select “OK”. The results above indicate that there is not a significant difference between how females and males answered the question “Would you participate in jokes that are derogatory to any racial group?” (p-value=0.397). Two-Sample T-Test and One-Way ANOVA The purpose of the two-sample t-test, also known as the independent samples t-test, is to determine if mean values of a particular continuous variable are significantly different for two groups. The one-way analysis of variance (ANOVA) is mathematically equivalent to the two-sample t-test, and is appropriate when there are two or more groups. There are 3 assumptions that must be met in order to perform these tests: Normality Homogeneity of variance for ANOVA Independence of groups and observations You can investigate normality with Q-Q plots or histograms and use Levene’s test to assess homogeneity of variance. You can also side-by-side box plots to investigate the relationship between a continuous dependent variable and a categorical predictor. In SPSS, select Analyze - Compare Means to find the two-sample t-test and one-way ANOVA For the side-by-side box plots, select Graphs- Legacy Dialogs - Boxplot, choose “Simple” and “Summaries for groups of cases”, and click “Define.” In the next dialog, move the continuous variable and the grouping variable from the left-hand list of variables to the “Variable” and “Category Axis” boxes. Try it: Use section5_2_data.sav. Is there a relationship between sex and the post intervention intension scale score? Sex is a categorical variable, the intension scale is continuous. We can use either an independent samples t-test or one-way ANOVA. Select Analyze - Compare Means - Independent Samples T Test. Select “BIndBehInt_Post” for Test Variable(s). Select “Sex” for Grouping Variable. Select “Define Groups…” and let group 1=1, group 2=2. Select “Continue” and “OK”. The tables above indicate that the males and females have similar average intension scale scores (males=5.3, females=5.59). We fail to reject the null hypothesis for Levene’s test, so we will report the information for “Equal variances assumed”. Our p-value is .631, so we fail to reject the null hypothesis that males and females have similar average intention scale scores. Select Analyze - Compare Means - One-Way ANOVA“. Select”BIndBehInt_Post\" for the dependent list. Select “Sex” for the factor. Select “OK” The ANOVA table above yields the same p-value and conclusion as using the two-sample t-test. Select Graphs - Legacy Dialogs - Boxplot. Select “Simple” and “Summaries for groups of cases” and click “Define”. Select the continuous dependent variable for “Variable” and the grouping variable for “Category Axis”. Select “OK”. Paired T-Test A paired t-test, also known as a repeated measures t-test or dependent samples t-test, is appropriate when there are two related observations (variables) and we want to determine if the average values of these variables differ from one another. The purpose of the paired t-test is to test the same units of observation under different treatment conditions to see if a treatment effect exists. The test compares the pre-treatment value to the post-treatment value for each case. The null hypothesis is that the mean value of the differences for these two related variables is 0. If we reject this hypothesis, then we conclude that the difference is significantly different from 0. This test assumes that the sample mean of the differences is normally distributed. The test only considers cases with both pre-treatment and post-treatment values. In SPSS, select Analyze - Compare Means - Paired Samples T-Test. Try it: Use section5_2_data.sav. Investigate whether or not the average intention scores are statistically different from each other. Since these variables are pre and post variables, it would be interesting to see if the intervention was successful in increasing the scores of participants. To investigate this, we will use a paired t-test. Select Analyze - Compare Means - Paired Samples T-Test. Select “BIndBehInt_Pre” for Variable 1. Select “BIndBehInt_Post” for Variable 2. Select “OK”. The tables above indicate that there is a significant increase in average behavior intention score after the intervention (p-value&lt;.001). 5.10 Investigating Many Variables at a Time It is often useful to investigate the relationship between one outcome variable and multiple predictor variables. The type of the outcome variable determines the appropriate model; general linear models are appropriate for continuous outcomes and generalized linear models are appropriate for categorical outcomes. General linear models include simple linear regression and multiple linear regression while generalized linear models include binary logistic regression and ordinal logistic regression. Linear regression and binary linear regression will be covered through EXERCISES in this workshop, time permitting. 5.11 Repeated Measures, Longitudinal, Clustered, Multilevel, Mixed Procedures It is very common in many studies to take multiple measurements on a unit of analysis, typically a subject. These multiple measures may be occurring over time, conditions, regions, or the levels of any other variable. Depending on what the measurements are taking place over, there are many names we give these studies. It is also very common in many studies to have the units of analysis be clustered (i.e. grouped) into higher level clusters (i.e. groups). Sometimes the clusters themselves are further clustered into even higher level clusters, and so on. In all of these studies, we must use more advanced statistical procedures that take into consideration the possible correlation of observations that are coming from the same unit of analysis. While using advanced procedures to analyze such data sets is beyond the scope of this workshop, you should be able to identify these multilevel data sets and discuss them with your statistician. 5.12 Other Procedures in SPSS Here is a non-exhaustive list of other procedures in SPSS that you may use: Tests for checking the assumptions of normality Intraclass correlation coefficient Partial correlations General linear models Generalized linear models Categorical data analysis Randomized clinical trials Case-control clinical trials Matching and propensity scores Survival analysis Cox regression Two-stage least squares regression Probit regression Cluster analysis Discriminant analysis Factor analysis Principal components analysis Reliability analysis Path analysis Structural equations modeling Latent class analysis Multidimensional scaling Spatial statistics Time series analysis Complex samples and survey methodology Missing data analysis and imputation Geographical information systems Qualitative data analysis Text mining Receiver operator characteristic (ROC) curve analysis Functional data analysis Data mining Classification and regression trees (CART) Chi-square automatic interaction detection (CHAID) Neural networks "],
["appendix.html", "Chapter 6 Appendix 6.1 Interpreting Interactions in a Regression Model Overview 6.2 Execise Solutions 6.3 Additional Exercises 6.4 Final Project", " Chapter 6 Appendix 6.1 Interpreting Interactions in a Regression Model Overview 6.1.1 Two-Way Interactions 6.1.1.1 General Let our regression model follow this form: \\[ Y = A + B + A*B \\] Where Y represents our dependent/outcome variable and \\(A*B\\) represents the interaction between \\(A\\) and \\(B\\). The regression coefficient for \\(A\\) shows the effect of \\(A\\) when \\(B=0\\). The regression coefficient for \\(B\\) shows the effect of B when \\(A=0\\). The regression coefficient for \\(A*B\\) demonstrates how \\(A\\) changes with a one unit increase in \\(B.\\) It also demonstrates how \\(B\\) changes with a one unit increase in \\(A\\). 6.1.1.2 Two Categorical Variables Let \\(A\\) represent gender 0=Female 1=Male Let \\(B\\) represent treatment condition 0=Control 1=Experimental The interaction regression coefficient shows whether the effect of treatment condition is different for males and females. The regression coefficient for \\(A\\) shows the difference in \\(Y\\) between males and females for the ‘control’ treatment group. The regression coefficient for \\(B\\) shows the difference in \\(Y\\) between treatment and control groups for females. 6.1.1.3 One Categorical and One Continuous Variable Let \\(A\\) represent gender 0=Female 1=Male Let \\(B\\) represent a continuous variable: age in years. The interaction regression coefficient shows if the effect of age on \\(Y\\) is different for males and females. The regression coefficient for \\(A\\) shows the difference between males and females when age is equal to zero. The regression coefficient for \\(B\\) shows the effect of age for females. 6.1.1.4 Two Continuous Variables Let \\(A\\) represent a continuous variable: IQ score. Let \\(B\\) represent a continuous variable: Age. The interaction regression coefficient shows if the relationship between age and \\(Y\\) differs according to IQ if the relationship between IQ and \\(Y\\) differs according to age. The regression coefficient for \\(A\\) shows the relationship between IQ and \\(Y\\) when age equals zero. The regression coefficient for \\(B\\) shows the relationship between age and \\(Y\\) when IQ equals zero. 6.1.2 Three-Way Interactions The same principles apply from above. The general model: \\[ Y = A + B + C + A*B + A*C + B*C + A*B*C \\] The coefficient for \\(A\\) shows the effect of \\(A\\) on \\(Y\\) when both \\(B\\) and \\(C\\) are zero. The coefficient for \\(B\\) shows the effect of \\(B\\) on \\(Y\\) when both \\(A\\) and \\(C\\) are zero. The coefficient for \\(C\\) shows the effect of \\(C\\) on \\(Y\\) when both \\(A\\) and \\(B\\) are zero. The coefficient for \\(A*B\\) shows the interaction between \\(A\\) and \\(B\\) when \\(C\\) is zero. The coefficient for \\(A*C\\) shows the interaction between \\(A\\) and \\(C\\) when \\(B\\) is zero. The coefficient for \\(B*C\\) shows the interaction between \\(B\\) and \\(C\\) when \\(A\\) is zero. The interaction regression coefficient shows if the relationship between \\(A\\) and \\(Y\\) differs according to \\(B\\) and \\(C\\) \\(B\\) and \\(Y\\) differs according to \\(A\\) and \\(C\\) \\(C\\) and \\(Y\\) differs according to \\(A\\) and \\(B\\). 6.2 Execise Solutions 6.2.1 Exercise 1 In order to analyze data properly in SPSS, we need to follow the guidelines set out above. Open exercise1_data.sav and see what guidelines we have ignored. 6.2.1.1 Exercise 1 Solution Too much information is contained in one variable (CTSSurgTypeCatCodeDesc, LOS, SURGLOS, DCDate, etc.) Errors can easily be found by sorting (errors in Year, AGE) The same content is entered in differently for a single variable (SEX, HTN, SMOKING) Anything else? 6.2.2 Exercise 2 Open exercise2_data.sav (an Excel file). Modify this Excel file such that it can be imported into SPSS properly. Save the file and close it. Open the file in SPSS (import it). Export this file back into Excel, but only save the following variables: id, salary, minority. 6.2.2.1 Exercise 2 Solution Delete the first three rows of data (remove heading) Remove rows 23 and 24 (contains summary information) Remove the formatting (fill color) Save the file as Exercise2_Data_Ready Close Exercise2_Data_Ready Open SPSS Select File - Open - Data Under “Files of Type” select either “All Files” or “Excel” to view Exercise2_Data_Ready, select the file, then select “Open” A window appears Check the box so the variable names will be imported Select the sheet of the Excel file that you would like to be read in, then select “Ok” The Excel data should now open in the Data Editor Delete any “blank” rows of data or columns of data (indicated by “.”) by highlighting, right click, select “cut” Select File - Save As Let the file name be Exercise2_Data_Ready_short Change the file type to Excel 97 through 2003 (*.xls) Select the “Variables…” button Select the “Drop All” button Under the “Keep” column, check the box for id, salary, minority Select “Continue” Select “Save” Open the new file (Exercise2_Data_Ready_short) to investigate the results 6.2.3 Exercise 3 Open exercise3_data.sav and go to Variable View. Practice defining the correct attributes to each variable by following the code book. Name Label Value Label Missing Values Measure IDnum Scale sex Respondent’s Sex 1 = Male Nominal 2 = Female race Race of Respondent 1 = White Nominal 2 = Black 3 = Other region Region of the United States 1 = North East Nominal 2 = South East 3 = West happy General Happiness 0 = NAP 0, 8, 9 Ordinal 1 = Very Happy 2 = Pretty Happy 3 = Not too Happy 8 = DK 9 = NA life Is Life Exciting or Dull 0 = NAP 0, 8, 9 Ordinal 1 = Exciting 2 = Routine 3 = Dull 8 = DK 9 = NA sibs Number of Brothers and Sisters 98 = DK 98, 99 Scale 99 = NA childs Number of Children 8 = Eight or More 9 Scale 9 = NA age Age of Respondent 98 = DK 0, 98, 99 Scale 99 = NA educ Highest Year of School Completed 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA paeduc Highest Year School, Father 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA maeduc Highest Year School, Mother 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA seeduc Highest Year School, Spouse 97 = NAP 97, 98, 99 Scale 98 = DK 99 = NA prestg80 Occupational Prestige Score 0 = DK,NA,NAP 0 Scale occcat80 Occupational Category 1 = Managerial and Professional Nominal 2 = Technical and Sales 3 = Service 4 = Farming, Forest, and Fishing 5 = Production and Craft 6 = General Labor 6.2.3.1 Exercise 3 Solution In Variable View, the first four columns do not need to be modified To modify the variable label, click in the cell that you wish to edit and start tying in the label To modify the value labels, click the cell that you wish to edit and then select the box with three small dots. The following window will appear: Ender the value and label, then select “Add”. Once all possible value labels are added, select “OK” When value labels (or other attributes such as label or missing) repeat for a variable, you can copy and paste the attribute values. Right click on the cell you want to copy, select copy. Then right click on the cell that you would like to paste in, and select paste. Enter in missing values in a similar fashion—here we have discrete missing values Use the drop down menu for “Measure” to specify the correct measurement type 6.2.4 Exercise 4 Open exercise4_data.sav. Compute a new variable that is the change from beginning salary to current salary for each employee. Recode the education variable into a new variable according to the following 1=High School or Less (educ&lt;=12) 2=Some College (12&lt;educ&lt;=16) 3=Bachelor’s Degree or Higher (educ&gt;=17) 6.2.4.1 Exercise 4 Solution Compute a new variable that is the change from beginning salary to current salary for each employee. Transform - Compute Variable Select “Reset” Enter the following information Target Variable: salchange Double click (or use the arrow) to move salary to the Numeric Expression window Use the calculator box below the numeric expression box to enter a minus sign (alternatively, you could type a minus sign) then select salbegin Select OK, and the new variable will appear in the data set Recode the education variable into a new variable according to the following 1=High School or Less (educ&lt;=12) 2=Some College (12&lt;educ&lt;=16) 3=Bachelor’s Degree or Higher (educ&gt;=17) Transform- Recode into different variables Move education (educ) into the Input Variable Output Variable window by double clicking on it or using the arrow Name: EducRecode Label: Leave Blank Click the change button Under old value, select the radio dial for Range, LOWEST through value: enter 12 Under new value, select the radio dial for Value: enter 1 Select Add Under old value, select the radio dial for Range: enter 13 through 15 Under new value, select the radio dial for Value: enter 2 Select Add Under old value, select the radio dial for Range, value through HIGHEST: enter 16 Under new value, select the radio dial for Value: enter 3 Select Add Select Continue Select OK Check the dataset in Data View 6.2.5 Exercise 5 Open exercise5_data.sav. Select male managers. What is their average age? (You can obtain the average age by choosing Analyze - Descriptive Statistics - Descriptives and moving “Age of Respondent (age)” to the right hand side.) Use the “Split File” procedure to get the average age for each job category. 6.2.5.1 Exercise 5 Solution Select male managers. What is their average age? Check Values for sex and occat80 to see what values correspond to “male” and “manager” (it’s 1 and 1). Data - Select Cases Under Select: Select the If Condition is Satisfied radio dial and select the If button Enter the following information Open box should read as follows: sex=1 &amp; occcat80=1 Continue Under Output: Select Filter Out Unselected Cases Select OK Inspect the data in Data View Analyze - Descriptive Statistics - Descriptives Select the age variable, select OK Turn off the filter! Use the “Split File” procedure to get the average age for each job category. Data - Split File Select Compare Groups Select occat80 (Occupational Category) and move it into the Groups Based On window by double clicking (or using the arrow) Select Sort the File by Grouping Variables Select Ok Analyze - Descriptive Statistics - Descriptives Select the age variable and OK Turn off the split file! 6.2.6 Exercise 6 Convert exercise6_data from “Wide” format to “Long” format 6.2.6.1 Exercise 6 Solution Open exercise6_data.sav Select Data - Restructure to open the Wizard Select “Restructure selected variables into cases” then “Next” How many variable groups to you want to restructure? Select “One” then “Next” Case Group Identification should be changed to “Use selected variable” and the variable should be the ID variable Variables to be transposed: Move the X variables over (X1, X2, X3) Fixed Variable(s): Move Group and Age over Select “Next” How many index variables do you want to create? Select “one” then “Next” What kind of index values? Select “Sequential Numbers” then select “Next” Handling of Variables not Selected: Select “Keep and treat as fixed variable(s)” System Missing or Blank Values in All Transposed Variables: Select “Create a case in the new file” Leave “Case Count Variable” unchecked Select “Next” What do you want to do? Select “Restructure the data now”. In the future you may want to keep the syntax. Select “Finish” The following message appears, click “OK” Inspect the data (and change “trans1” to “X”) 6.2.7 Exercise 7 Convert exercise7_data from “Long” format to “Wide” format 6.2.7.1 Exercise 7 Solution Open exercise7_data.sav Select Data - Restructure to open the Wizard Identifier Variable(s): ID Index Variable(s): Index1 Select “Next” Sort the current data? Yes Select “Next” Order of New Variable Groups: Group by original variable Leave the other options unchecked Select “Next” Select “Restructure the Data Now” and “Finish” The following message will appear, select “OK”. Inspect the data and save! 6.2.8 Exercise 8 Open exercise8_data.sav Part 1: Investigate the variable attributes. Determine which variables are categorical variables (nominal and ordinal), and which variables are continuous (scale). Obtain the appropriate descriptive statistics for each variable. Remember, continuous variables should be investigated with descriptives and categorical variables should be investigated with frequency tables. *Hint: Select more than one variable in the “Analyze”,“Descriptive Statistics”,“Descriptives”, or “Frequencies” dialog boxes. Part 2: Assess the distribution of the Occupational Prestige Score (“prestg80”) with both a histogram (normal curve displayed) and a Q-Q plot. Is the assumption that the population of Occupational Prestige Scores is normally distributed reasonable? Part 3: Compare the average highest year of school completed (“educ”) for males and females. *Hint: First split the file by “sex” (Data - Split File), then calculate the descriptive statistics. Be sure to return to the Split File menu when you are done with this question and return the dialog box to “Analyze all cases”. Part 4: Produce a pie chart for the variable “region”. (We didn’t cover this, you can use either Chart Builder or Legacy Dialogs.) 6.2.8.1 Exericse 8 Solution Open the dataset exercise8_data.sav Part 1 Investigate the variable attributes. Determine which variables are categorical variables (nominal and ordinal), and which variables are continuous (scale). Select the “Variable View” tab Investigate the labels and measure of each variable Obtain the appropriate descriptive statistics for each variable in the dataset. Remember, continuous variables should be investigated with 5-point summary descriptives and categorical variables should be investigated with frequency tables. Select Analyze - Descriptive Statistics - Descriptives Select the following variables: sibs, childs, age, educ, paeduc, maeduc, speduc, prestg80 Select “OK” Notice there are only 519 respondents that have valid data points for all of the continuous variables. Frequency Tables: Select Analyze - Descriptive Statistics - Frequencies Select the following variables: sex, region, race, happy, life, occcat80 Investigate the output Part 2: Assess the distribution of the Occupational Prestige Score (“prestg80”) with both a histogram (normal curve displayed) and a Q-Q plot. Is the assumption that the population of Occupational Prestige Scores is normally distributed reasonable? Histogram in Legacy Dialogs Select Graphs - Legacy Dialogs - Histogram Variable: prestg80 Check box to display normal curve Select OK Investigate the output Q-Q Plot Select Analyze - Descriptive Statistics - Q-Q Plots Select the variable prestg80 Select OK Investigate the output Look to see how well the plotted points follow the solid diagonal line It is particularly important to pay attention to the “tails”, or the left most and right most points to see if they follow the line Part 3: Compare the average highest year of school completed (“educ”) for males and females. Set up the dataset such that the output is split by groups based on sex Select Data - Split File Select “Compare Groups” Select the variable sex for “Groups Based on:” Select “OK” Compute the 5-Point Summary Descriptives for “educ” Select Analyze - Descriptive Statistics - Descriptives Select the variable “educ” Select “OK” Investigate the output Males have an average of 13.23 years of education Females have an average of 12.63 years of education Turn the split file feature off Select Data - Split File Select “Analyze all cases, do not create groups” (Alternatively, “Reset” can be selected) Select “OK” Part 4: Produce a pie chart for the variable “region”. Use “Legacy Dialogs”. Select Graphs - Legacy Dialogs - Pie Under “Data in Chare Are” select “Summaries for groups of cases” Select “Define” Select the variable “region” for “Define Slices by:” The default for “Slices Represent” is “N of cases”, and leave this at the default Select “OK” Investigate the output 6.3 Additional Exercises 6.3.1 Exercise A1 – Categorical Data Analysis Question 1 Open exercisea1_data. What percent of respondents said they were “Very Happy”? What about “Not too happy”? “Pretty happy”? Use a graph to display the variable. Question 2 Do women appear to be more or less happy than men? Would you say this apparent relationship is statistically significant? Question 3 Create a scatter plot of respondent’s education vs. their spouses’ education. Does this relationship appear to be linear? Add a linear regression line to the plot. Inspect the correlation between the respondent’s education and their spouses’ education. Is this correlation positive or negative? Is it statistically significant. 6.3.2 Exercise A1 Solution Question 1 Open exercisea1_data. What percent of respondents said they were “Very Happy”? What about “Not too happy”? “Pretty happy”? Use a graph to display the variable. Solution: We have one categorical variable that we would like to investigate…check the all on one page handout! Analyze - Descriptive Statistics - Frequencies Enter the following information Select happy Select Charts Under Chart Type, select Bar Chart Under Chart Values, select Percentages Select Continue Select the box for Display Frequency Tables Select OK Question 2 Do women appear to be more or less happy than men? Would you say this apparent relationship is statistically significant? Solution: We are going to compare two categorical variables. From out handout, we will use Pearson Chi-Square crosstabs to do this! Analyze - Descriptive Statistics - Crosstabs Enter the following information Rows: sex Columns: happy Select the Statistics button Check the box for Chi-Square Select Continue Select the Cells button Check the box for Row under Percentages (leave the rest as default) Check the box for Adjusted Standardized Residuals under Residuals (leave the rest as default) Select Continue Select the box for Display Clustered Bar Charts Select OK The Pearson Chi-Square statistic indicates that the differences between men and women are statistically significant (pvalue/asymptotic significance&lt;.05). The residuals, clustered bar chart, and row percentages can tell us where these differences arise An adjusted standardized residual (absolute value) greater than two shows us where the differences between groups occur. Here, we see that “not too happy” for males and females has a residual greater than 2. The row proportions indicate that there is a higher proportion of females that responded “not too happy” when compared to males. The clustered bar chart also shows that there are greater numbers of women that indicate that they are “not too happy”. Question 3 Create a scatter plot of respondent’s education vs. their spouses’ education. Does this relationship appear to be linear? Add a linear regression line to the plot. Inspect the correlation between the respondent’s education and their spouses’ education. Is this correlation positive or negative? Is it statistically significant. Solution: Graphs - Legacy Dialogues - Scatter/Dot Simple Scatter and Define Enter the following information Y Axis: speduc X Axis: educ Select OK Check the output for the scatter plot Double click the plot in the Output Viewer to open Chart Editor Select the button for Add Fit Line at Total (first bar above the plot, axis with straight line plot) Select Linear Fit, Apply, Close Close out of chart editor (red X in the upper right corner) and the updated chart will appear in the Output Viewer. “Analyze” “Correlate” “Bivariate” Enter the following information Variables: educ, speduc Correlation coefficients: Pearson, Spearman Significance: Two Tailed Check the box for Flag significant correlations Select OK The output indicates that the correlation between education and spouses’ education is positive and statistically significant. 6.3.3 Exercise A2 – Continuous Data Analysis Open exercisea2_data.sav. Research Question 1: Is there a relationship between a student’s socio-economic status and whether or not the student would participate in a racially insensitive joke? What techniques would you use to investigate the relationship between SES and whether or not a student would participate in a racially insensitive joke? Investigate this relationship graphically and statistically. What did you find? Research Question 2: Is there a relationship between a student’s race and their post intervention behavior intention scale? What techniques would you use to investigate a student’s race and their post intervention behavior intention scale? Investigate this relationship graphically and statistically. What did you find? Research Question 3: Is there a relationship between the race of a student and their socio-economic status? What techniques would you use to investigate the relationship between race and SES? Investigate this relationship graphically and statistically. What did you find? 6.3.4 Exercise A2 Solution Research Question 1: Is there a relationship between a student’s socio-economic status and whether or not the student would participate in a racially insensitive joke? What techniques would you use to investigate the relationship between SES and whether or not a student would participate in a racially insensitive joke? ANSWER: SES is an ordinal variable with 4 levels that should be treated as a categorical variable. Whether or not a student would participate in a derogatory joke is measured with the “Joke” variable and it is a categorical variable. The appropriate statistical procedure to use to compare two categorical variables is the Chi-Square Test of Independence (crosstabs). The appropriate graphical procedure is a clustered bar chart. Investigate this relationship graphically and statistically. What did you find? ANSWER: There is not a statistically significant relationship between “SES” and “Joke”. We do not have enough evidence to say that there is a relationship between a student’s socio-economic status and whether or not the student would participate in a racially insensitive joke. Research Question 2: Is there a relationship between a student’s race and their post intervention behavior intention scale? What techniques would you use to investigate a student’s race and their post intervention behavior intention scale? ANSWER: “Race” is a categorical variable that can take on up to 9 values and a student’s post intervention behavior intention scale (“BIndBehint_post”) is a continuous variable. The appropriate statistical procedure is a one-way ANOVA. The appropriate graphical procedure is a side-by-side box plot. Investigate this relationship graphically and statistically. What did you find? ANSWER: There is not a statistically significant relationship between “Race” and “BIndBehint_Post”. We do not have enough evidence to say that there is a relationship between a student’s race and their post intervention behavior intention score. Research Question 3: Is there a relationship between the race of a student and their socio-economic status? What techniques would you use to investigate the relationship between race and SES? ANSWER: “Race” and “SES” are both categorical predictors. The appropriate statistical procedure to use to compare two categorical variables is the Chi-Square Test of Independence (crosstabs). The appropriate graphical procedure is a clustered bar chart. Investigate this relationship graphically and statistically. What did you find? ANSWER: There is a statistically significant relationship between “Race” and “SES”. There is a significant relationship between a student’s SES and race. Notice the error message under the Chi-Square results table—in this case, we need to verify our statistically significant results with Fisher’s Exact Test (pvalue=.025). 6.3.5 Exercise A3 – Methodology Choice Practice In the below questions first determine what the appropriate analysis method is based on the variables of interest and carry out these methods within SPSS. A. From exercisea3_data_a.sav Is there a relationship between sex (gender) and job category (jobcat)? Is there a relationship between job category (jobcat) and minority status (minority)? Is there a relationship between job category (jobcat) and salary (salary)? Is there a relationship between experience (jobtime) and salary (salary)? B. From exercisea3_data_b.sav Is there a relationship between general happiness (happy) and occupational prestige score (prestg80)? Is there a relationship between age (age) and occupational prestige score (prestg80)? Is there a relationship between general happiness (happy) and perception of life being exciting or dull (life)? Exercise A3 Hints! A1. Two Categorical VariablesClustered Bar Charts, Pearson Chi-Square Crosstabs A2. Two Categorical VariablesClustered Bar Charts, Pearson Chi-Square Crosstabs A3. Categorical DV (3+Groups) &amp; Continuous DVOne Way ANOVA, Side-by-Side Boxplot A4. Two Continuous VariablesPearson Correlation Coefficient, Scatterplot B1. Categorical DV (3+Groups) &amp; Continuous DVOne Way ANOVA, Side-by-Side Boxplot B2. Two Continuous VariablesPearson Correlation Coefficient, Scatterplot B3. Two Categorical VariablesClustered Bar Charts, Pearson Chi-Square Crosstabs 6.3.6 Exercise A4 – Case Study I: Salary (Regression) Open exercisea4_data. Background This data set contains information on faculty from Bowling Green State University for the 1993 to 1994 (DeMaris 2004). The purpose of the exercises below is to investigate whether there was any evidence of gender inequality in faculty salaries at BGSU. Activity 1: Describing the Dataset Investigate the ‘Faculty’ data set using descriptive statistics, one variable graphing procedures, and bivariate procedures. Investigate ‘Salary’ with descriptive statistics, box plot, and histogram Investigate ‘Gender’ with a frequency table and bar chart Investigate the average salary for males and females separately (descriptive statistics, histogram, side-by-side box plot) Remember to split the file by the gender variable (‘male’). The descriptive statistics table above indicates that males earn more than females on average. Also remember to remove the ‘Split File’ option. The Boxplot below indicates that males have a higher median salary than females, and both males and females have outliers (observation 148 and 58 respectively). Perform an independent samples t-test Remember that the dialogue box for the independent samples t-test is located under ‘Analyze’ then ‘Compare Means’. The table above indicates that we cannot assume equal variances between males and females (Levene’s Test pvalue&lt;.05). Regardless, we see that the differences between average male and female salaries are large enough to be considered statistically significant (t=10.250, df=297.227, pvalue&lt;.001). The confidence interval for the mean difference between genders is [8550.79, 12614.47]. This is the plausible range of values for the difference between males and females. Activity 2: Simple Linear Regression The independent samples t-test is one way to model the relationship between the faculty salary (dependent variable of interest) and gender (independent variable). Faculty salary may also be a function of the marketability of the discipline the faculty member is in. Investigate the correlation between ‘salary’ and ‘market’ and investigate a scatter plot of the two variables In SPSS, select Analyze - Correlate - Bivariate We see from the table above that there is a statistically significant correlation between faculty salary and marketability of the discipline (r=.407, pvalue&lt;.001). Perform a simple linear regression where ‘salary’ is the dependent/outcome variable and ‘market’ is the independent/predictor variable This can be done multiple ways in SPSS. The first way uses the regression menu from ‘Analyze’ while the second uses the ‘General Linear Model’ menu. Select Analyze - Regression - Linear Notice that the regression menu provides the correlation between the variables included in the model. The table below provides the R Square value and adjusted R Square value. The proportion of variance in faculty salary explained by marketability of discipline is 16.6%. The table below indicates that the model fitted is significantly better than what we would expect by chance (F=101.771, pvalue&lt;.001). The null hypothesis is that there is no linear relationship between faculty salary and marketability, and we reject this hypothesis. The table above provides the parameter estimates for our model. For every one unit increase in marketability, faculty salary increases by an average of $34,545. We could also interpret the beta coefficient for marketability the following way: the effect of a .1 point increase in marketability is associated with an estimated increase in mean salary of $3,454. The constant (intercept) for the model is interpreted as the estimated mean salary when marketability is equal to zero. Remember that the confidence intervals give us a range of reasonable values for an estimate. The 95% confidence interval for our estimate of market discipline is [$27817, $41272]. The hypothesis tests provided with the ‘t’ statistic and ‘Sig.’ columns help us decide if a particular value (usually zero) is a reasonable estimate. If our estimated beta coefficient for market discipline was zero, then market discipline would not have an effect/relationship with faculty salary. This is our null hypothesis, and we would like to reject this hypothesis. Here we find a significant relationship between market discipline and faculty salary (t=10.088, pvalue&lt;.001). The second method for generating results for a simple linear regression is described below. Keep in mind that this method for performing a linear regression is preferred when there are categorical predictor/independent variables or interaction terms between independent variables. Select Analyze - General Linear Model - Univariate The table below provides the descriptive statistics for faculty salary. The table above indicates that the overall regression model is significant (F=101.771, pvalue&lt;.001). This is indicated by the line for ‘Corrected Model’. The R Squared value is also listed in footnote a. for the table. The parameter estimates table above provides the same information as the previous coefficients table. Notice that the results are the same between the two methods that can be used in SPSS to perform a regression. For the remainder of the workshop we will use the second method to obtain our regression results (Analyze - General Linear Model - Univariate). Activity 3: Simple Linear Regression Diagnostics Perform the necessary regression diagnostics for the regression from exercise 2. Check the linearity and homogeneity of variance assumptions Plot the residuals against the predicted values from the model. The residuals should be randomly scattered around zero, and the variability should be constant in the plot. The scatter plot below does not indicate that either assumption has been violated. Check for influential points The scatter plot from exercise 2 did not indicate that there were points of interest. A leverage point is an unusual point that has the potential to influence the fit of the model. Sort the data set by Leverage in descending order. A rule of thumb is a point is considered to have large leverage when the leverage value is greater than 2p/n where p equals the number of parameters in the model. Here we estimate the intercept and slope for market, so p=2. This means that high leverage values are greater than 2*2/514=4/514=.0078. There are 53 points with high leverage. An influential point is one whose removal from the dataset would cause a large change in the fit of the regression model. An influential point may or may not be an outlier. Also, and influential point may or may not have large leverage. Usually an influential point will be an outlier and or may have large leverage. Sort the data set by the Cook’s distance variable in descending order. This will list the observations with the largest Cook’s distance first. Remember a distance greater than 1 or 4/n=4/514=.0078 is considered large. The first 16 observations have large Cook’s distances, but we do not have cause to remove them from the data set. Check the normality assumption for the residuals The plot below indicates that the normality assumption is reasonable. A QQ plot can also be investigated (Analyze - Descriptive Statistics - QQ Plot) Activity 4: Multiple Regression with a Categorical Predictor Faculty salary appears to be a function of the marketability of the discipline the faculty member is in, but it also may be a function of gender. Create a multiple regression model where salary is the dependent variable, and both marketability and gender are the predictors. Select Analyze - General Linear Model - Univariate Select ‘salary’ as the dependent variable, male as the fixed factor, and market as the covariate. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’. Under ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’ The table below indicates the number of Males and Females in the data set, along with the code that denotes the genders. The table above indicates that the average salary for males is greater than the average salary for females ($53,499.24 compared to $42,916.60). The table above indicates that the model fitted is significantly better than what we would expect by chance (F=85.799, pvalue&lt;.001). The null hypothesis is that there is no linear relationship between faculty salary and the model predictors, and we reject this hypothesis. This is indicated by the line for ‘Corrected Model’. The R Squared value is also listed in footnote a. for the table. The proportion of variance in faculty salary explained jointly by marketability of discipline and gender is 25.1%. Notice that this is an increase from the previous model. The table above provides the parameter estimates for the regression model. The difference in population mean salaries between men and women, when controlling for marketability is estimated to be $8,708.42. Remember that Dummy variables are always interpreted in relationship to the reference category. The reference category is denoted with a coefficient value of 0 and footnote a. Here, we interpret male=0 (Female) compared to male=1 (Males). Another interpretation of the gender variable: When controlling for marketability, faculty salaries are on average $8,708.42 less for females when compared to males. The marketability coefficient now is interpreted as the effect of marketability after accounting gender. For every one unit increase in marketability, faculty salary increases by an average of $29,972.60 holding gender constant. We could also interpret the beta coefficient for marketability the following way: the effect of a .1 point increase in marketability is associated with an estimated increase in mean salary of $2,997 holding gender constant. Notice that all of the predictor variables in the model are highly significant. Note that the model fit above is also sometimes referred to as an analysis of covariance (ANCOVA) model. The inclusion of a continuous predictor (marketability) in addition to the factor gender makes this an ANCOVA model. Create a multiple regression model where salary is the dependent variable, and marketability, time since degree (yearsdg), and gender are the predictors. Investigate the coefficients and R-squared. First investigate a scatter plot between salary and time since degree. Select Analyze - General Linear Model - Univariate Select ‘salary’ as the dependent variable, male as the fixed factor, and market and yearsdg as the covariates. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’. Under ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’ The table below indicates that the R-squared value has increased from the last model to .684, and the model is significant (F=367.562, pvalue&lt;.001). The estimated population mean salary for women is $2,040.21 less than men for a given marketability and time since degree. The estimated effect of time since degree is $949 more in mean salary per year (*a one unit increase is a year!) since degree when comparing faculty members of the same gender from disciplines with the same marketability. For a given time since degree and gender, a one unit increase in marketability is estimated to increase average salary by $38,402. Notice that all of the predictor variables in the model are highly significant. Activity 5: Multiple Regression with an Interaction Faculty salary appears to be a function of the marketability of the discipline, time since last degree, and gender. Starting salaries could be similar for men and women, but men might receive larger increases over time. An interaction between gender and time since last degree may capture this relationship. Remember, a significant interaction implies that the effect of each variable depends on the value of the other variable—that is to say the effect of time since degree depends on gender and the effect of gender depends on time since degree. Create a multiple regression model where salary is the dependent variable, marketability, gender, time since degree, and the interaction between gender and time since degree are the predictors. Create a scatter plot: Select Graphs - Legacy Dialogs - Scatter/Dot and choose ‘Simple’ and ‘Define’. Let the y-axis be ‘salary’, the x-axis be ‘yearsdg’, and set markers by ‘male’. Select the graph in chart editor and click the box for ‘Add fit line at subgroups’. The lines for males and females are not parallel, and this is what we are investigating with the proposed interaction term. Select Analyze - General Linear Model - Univariate Select ‘salary’ as the dependent variable, ‘male’ as the fixed factor, and ‘market’ and ‘yearsdg’ as the covariates. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’. Under ‘Model’, select ‘Custom’. Under ‘Build Terms’ select ‘Main Effect’ and enter the variables male, market, yearsdg. Under ‘Build Terms’ select ‘Interaction’ and select both male and yearsdg to create the interaction term. Select ‘Continue’. Remember that main effects must always be included in a model that contains interaction terms. Under ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’ The table below indicates that the model is significant (F=279.95, pvalue&lt;.001) and the R-squared has increased from the last model to .688. In the presence of interaction terms, the main effect terms have different interpretations. The estimated gender gap when time since degree is zero is not significant. When time since degree is 0 years, the population mean salary for women after adjusting for the other covariates in the model is estimated to be $593 more than men. Notice the confidence intervals range from negative values (women earn less at time since degree=0) to positive values (women earn more at time since degree=0). The interaction between gender and years since degree (the change in gender gap with years since degree) is significant. For every additional year since degree completion, we see the gender gap between males and females grows by $227.153 on average when adjusting for the other covariates in the model. Activity 6: Multiple Regression with Diagnostics This exercise builds on the previous model. Add faculty rank (a three level categorical predictor) to the model and run the regression with diagnostics. Create a multiple regression model where salary is the dependent variable, marketability, gender, time since degree, faculty rank, and the interaction between gender and time since degree are the predictors. Create a side-by-side box plot for salary by rank. Select Analyze - General Linear Model - Univariate Select ‘salary’ as the dependent variable, ‘male’ and ‘rank’ as the fixed factors, and ‘market’ and ‘yearsdg’ as the covariates. Remember that any categorical predictor in a basic regression model should be entered in as a ‘fixed factor’, while any continuous prediction is considered a ‘covariate’. Under ‘Model’, select ‘Custom’. Under ‘Build Terms’ select ‘Main Effect’ and enter the variables male, market, yearsdg, rank. Under ‘Build Terms’ select ‘Interaction’ and select both male and yearsdg to create the interaction term. Select ‘Continue’. Remember that main effects must always be included in a model that contains interaction terms. Under ‘Save’ select ‘Unstandardized Predicted Values’ and ‘Standardized Residuals’. Under ‘Options’, select ‘Descriptive Statistics’, ‘Parameter Estimates’, ‘Residual Plot’ The table below displays the coding scheme used for the categorical predictors (factors). The table below provides the descriptive statistics for salary broken out by gender and rank. The table below indicates the model is significant (F=242.32, pvalue&lt;.001) and the R-squared value is .741 (an increase from the last model). We can see from the table below that faculty rank is a significant predictor of salary. The table above indicates that rank=1=Assistant Professor, rank=2=Associate Professor, rank=3=Full Professor. The estimated difference in population mean salary between Assistant Professors and Full Professors is $11,168 after adjusting for the other covariates in the model. Put another way: Assistant professors earn on average $11,168 less than Full Professors, all else equal. The estimated difference in population mean salary between Associate Professors and Full professors is $7,819 after adjusting for the other covariates in the model. Put another way: Associate professors earn on average $7,819 less than Full Professors, all else equal. The residual plot below is given from the output. First investigate the predicted (x axis) vs. std. residual plot to check for the constant variance assumption. There is not strong evidence that the assumption of constant variance has been violated. Linearity can also be assessed with this plot. Next investigate the plot of observed (x axis) and predicted values (y axis) to check the linearity assumption. The points should be symmetrically distributed on a diagonal (45 degree) line if the linearity assumption is not violated (this is approximately what we see here). Note that these plots could be made manually by creating scatter plots from the saved variables (predicted, residuals). The GLM approach to regression doesn’t allow for VIF’s to be calculated directly. Multicollinearity can attempt to be assessed through investigating the correlations or calculating the VIF manually. Note that pair wise correlations do not fully capture multicollinearity. Select ‘Analyze’ ‘Descriptive Statistics’ ‘QQ Plot’ and select the residual variable. The plot below indicates that the distribution of the error terms is approximately normal. This can also be confirmed with a histogram. 6.3.7 Exercise A5 – Case Study II: AIDS (Logistic Regression) Open exercisea5_data Background The data set for this exercise contains information on 109 countries with a number of characteristics measured for each country. The goal of the exercise is to identify whether there may be characteristics of a country that are related to AIDS rate classification. Countries are divided into one of two AIDS rate groupings: 0 = Less than 1 in 100,000 or 1 = More than 1 in 100,000. The variable in the data which holds this information is called aidscat2. We will fit several models with AIDS rate category as our outcome to identify potential significant predictors of AIDS rate classification. Because the model outcome is no longer a continuous measure, but instead binary, a logistic regression model will be used. The outcome for this type of model isn’t actually the values of the variable (0 or 1) but instead a calculation of the probability of having the value of one of the two categories of the outcome. The model has the form: \\[\\ln\\left( \\frac{p}{1 - p} \\right) = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{x} + \\ldots + \\beta_{p}x_{p}\\ \\] where p is the probability of the outcome variable being equal to 1. The \\[\\ln\\left( \\frac{p}{1 - p} \\right)\\] outcome is known as the log-odds. Note: It is possible to change which level of the outcome variable the probability references, so you can model the probability that y=0 instead of y=1 if desired. In all models for this exercise we will consider predicting the probability that a given country will have the higher AIDS rate classification (aidscat2=1). The objective of the models is to see whether the included predictors are significantly associated with the probability of having the higher AIDS rate classification. Activity 1: Logistic Regression with a Continuous Predictor For the first example, we will look at a simple example of fitting logistic regression with a continuous predictor. We will consider a single continuous predictor (log base 10 of the gross domestic product per capita, LOG_GDP). Perform a simple logistic regression where ‘aidscat2’ is the outcome variable and ‘log_gdp’ is the independent/predictor variable. Select Analyze - Regression - Binary Logistic’ to open the logistic regression dialogue box. Select AIDSCAT2 as the binary dependent variable. Note that the category whose probability we want to model, “high” AIDS rate, is coded as a 1, and the other category, “low” AIDS rate, is coded as 0. SPSS automatically fits the highest valued category probability. If the opposite is desired the outcome variable should be recoded so the opposite category has a higher value. Select LOG_GDP as the only covariate, and click OK to fit the model. Results from fitting this model are included below. The first table rovides some information regarding the cases (rows) used to fit that data. Note that three cases were lost in the analysis, due to missing data on the AIDSCAT2 variable. The final analysis sample size was 106. The coding of the dependent variable is critical to understand. SPSS will model the probability that the “internal value” of the dependent variable is equal to 1. The “internal value” is the value that SPSS recodes the outcome to be to fit the model behind the scenes. This will not always match up to your original coding so check this table carefully. In our case the 0/1 internal coding that SPSS performs matches up with our original 0=less than 1 in 100,000 and 1=more than 1 in 100,000 coding so we will be modeling the probability of being in the “high” AIDS rate. This initial classification table, located in “Block 0” of the output, shows how well we would do predicting by chance what the outcome will be (i.e., not using any covariates to predict the outcome). Because more countries have the higher classification, we would predict that classification for all of the countries, and we would be correct 64.2% of the time. This table isn’t all that informative by itself, we will compare it to a similar table in the next portion of the output. This table, also in the “Block 0” portion of the output, shows the maximum likelihood estimate of the intercept term in a logistic regression model without any covariates. This is simply the computed log-odds of the dependent variable being equal to 1. We’ll scroll down to the “Block 1” portion of the output, which will contain the maximum likelihood estimates of the parameters in our model. These estimates describe the relationship of LOG_GDP to the dependent variable (aidscat2). First, we examine the classification table for our outcome given that we are now considering the LOG_GDP variable as a predictor. This table is similar to predicted values in linear regression. For each country in the data set the predicted probability is computed using the fitted model and values of the country’s covariate. If the predicted probability is greater than 0.5 the country is classified into the ‘high’ AIDS rate group and if it is less than 0.5 it is classified into the ‘low’ AIDS rate group. These classifications are then compared with the actual observed classifications of the countries. Note that we are actually doing a worse job of predicting the AIDS rate when using LOG_GDP as a predictor (63.2% correct vs. 64.2% correct when we don’t consider any covariates). The predicted probabilities can be saved in the SPSS data set as an option if desired. Now, we examine the maximum likelihood estimate of the coefficient for LOG_GDP in the logistic regression model: The estimate of the parameter that represents the coefficient for LOG_GDP in the model is equal to 0.491, with a standard error of 0.329. The Wald statistic reported by SPSS is the squared version of the T statistic (the coefficient divided by its standard error, squared), and is referred to a chi-square distribution with 1 degree of freedom. This Wald statistic has a p-value of 0.135, which suggests that we would not reject a null hypothesis that the coefficient for LOG_GDP is equal to 0. We really don’t have evidence of a significant relationship of LOG_GDP with the AIDS rate outcome. However, if the relationship were significant, we would conclude that a one-unit increase in LOG_GDP results in an expected increase of 0.491 in the log-odds of being in the higher AIDS rate category. The parameter estimates represent additive changes to the log-odds. If exponentiated we get the more common odds ratio, which is the multiplicative change to the odds. Here the Exp(B) column holds the exponentiated esimates, for log_gdp the odds ratio is equal to 1.634. This value has the meaning that the odds of being in the higher AIDS rate category are multiplied by 1.63 with every one-unit increase in LOG_GDP. Activity 2: Logistic Regression with a Categorical Predictor Now, we’ll consider an example of analyzing a single categorical predictor with two levels, whether or not the country is predominantly muslim (MUSLIM). MUSLIM is coded as 1 = yes and 0 = no, which we would recommend for any two-level predictors. Select ‘Analyze’-&gt;‘Regression’-&gt;‘Binary Logistic’ to re-enter the logistic regression dialogue box. Replace the log_gdp covariate with muslim. We need to identify the predictor as categorical so select the categorical button. Move the MUSLIM covariate into the ‘Categorical Covariates’ list. Fit the logistic regression model by clicking on OK. Let’s jump down to Block 1 in the output and first examine the classification table based on the model including the MUSLIM variable: Note the substantial improvement in prediction accuracy by considering Muslim status! Now, we investigate the maximum likelihood estimate of the coefficient for MUSLIM: The maximum likelihood estimate of the coefficient is -2.335, with a standard error of 0.537. The Wald statistic based on that estimate is 18.934, and the p-value for that Wald statistic is said to be 0.000 by SPSS (but should be reported as p &lt; 0.001). This p-value suggests that we should reject the null hypothesis that the coefficient is equal to 0, which tells us that Muslim status has a significant relationship with the probability of being in the higher AIDS rate category. Specifically, when MUSLIM is equal to 1 (as opposed to 0), the log-odds of being in the higher category are expected to decrease by -2.335. This estimate corresponds to an odds ratio of 0.097 (the exponential version of the coefficient), which says that the odds of having a higher AIDS classification for a Muslim country is 0.097 times the odds of having a higher AIDS classification for a non-Muslim country. The expected odds are multiplied by 0.097 when a country is Muslim as opposed to non-Muslim. We can also interpret this as reducing the odds of being in the higher AIDS rate category by 90.03% for muslim countries. Notice here, when we see a decrease in the odds (odds ratio less than 1) we report 1-Odds Ratio as the percentage (1-.097=.9003). Activity 3: Logistic Regression with Multiple Predictors In this analysis, we hope to find ways to categorize countries into one of two AIDS prevalence categories, based on other data for the countries. We will also discover which pieces of information are useful in predicting AIDS prevalence, and which appear to be unassociated with this prevalence. Set up a logistic regression model to predict AIDS prevalence category (aidscat2) by considering the following predictors: muslim, log_gdp, babymort, urban, lit_fema, lifeexpf, birth_rt, tropical. Have SPSS report confidence intervals for the odds ratios. (This is found under the ‘Options’ button in the Logistic Regression dialogue box.) Which predictors appear useful in predicting AIDS category? Do Muslim countries still have lower odds of being in the higher AIDS prevalence category when controlling for the relationships of the other predictors with the outcome? How much lower are the odds of a Muslim country being in the higher AIDS category? The first table shows us that only 83 countries are used to fit this model, 26 were removed from analysis due to missing data on any of the variables used. The first classification table (Block 0: Beginning Block) in the output shows you the result of classifying cases strictly by predicting them to be in the category with the largest percentage in the data set (in this case, you would predict a random case to be in the higher AIDS category, since 64.2% of the cases with a valid AIDS category are in the higher AIDS category). We would only be correct 59% of the time predicting by chance. The ‘Model Summary’ table shows the –2 log-likelihood statistic for our model, as well as two analogs of R2 in the multiple regression context for a logistic regression model. These are approximations of R-squared in linear regression models, and should not be reported as the same thing; they should really only be used to compare the fits of competing models fitted using the same cases. The Cox &amp; Snell R Square approximation suggests that our predictors explain about 43% of the variation in our response (not bad). The Nagelkerke R Square is a rescaled approximation that is constrained to fall between 0 and 1. The Block 1 classification table shows an increase in the percentage that is correctly classified (89.2% vs 59%) using the predicted probabilities and a ‘cut-off’ classification probability of 0.5. Let’s examine the estimated coefficients for the predictors included in our model: The B column contains the estimated coefficients in the logistic regression model, which indicate the change in the log-odds of “success” (in this case, being in the higher AIDS category) associated with a one-unit increase in each predictor. So, for example, a one-unit increase in Muslim (or being in a Muslim country) decreases the log-odds of being in the higher AIDS category by 6.553, holding all other predictors constant. The Sig. column provides the results of a significance test for each of the parameters (or coefficients) for the predictors in the model. This shows that Muslim, lit_fema, and tropical are significant predictors of being in the higher AIDS category. If a predictor is significant, changes in the predictor have a significant relationship with the log odds of “success.” The Exp(B) column indicates the factor by which the odds of “success” are multiplied when the predictor increases by one unit, holding the other predictors constant. So, for example, a one-unit increase in Muslim will multiply the odds of being in the higher AIDS category by 0.001, or reduce the odds of being in the higher AIDS category by 99.9%. The Exp(B) factor is known as an odds ratio. The 95% confidence interval for Exp(B) will not contain 1 if the predictor is significant. An odds ratio of 1 means that one-unit changes in the predictor multiply the odds of “success” by 1, or effectively do not change the odds. 6.4 Final Project The Data The cars data sets contain data on specifications of 406 vehicles from 1970 to 1982. Among the variables in the data set are information on fuel consumption (mpg), horsepower, weight, acceleration, origin (Europe, Japan, U.S.), and number of cylinders. The data set contains categorical variables (such as origin), numerical discrete variables (such as number of cylinders), and continuous variables (such as weight, and acceleration). Getting Started Investigate cars_wave1.xls and cars_wave2.xls and prepare the data for SPSS Open SPSS and import cars_wave1.xls and cars_wave2.xls from Microsoft Excel. Merge cars_wave1 and cars_wave2 (add cases). Save this new SPSS file! Using the codebook below, define the proper attributes in Variable View Working with Variables Recode Origin such that 1=Domestic, 0=Foreign. Remember to recode into a different variable. Give this new variable the proper attributes in variable view. Convert Miles Per Gallon (MPG) to Liters Per 100 Kilometers Use the Compute function The formula to use: LP100K=(100*3.785)/(1.609*MPG) Export this SPSS data set to Microsoft Excel (it’s always good to have a back up!). Export all of the variables. One Variable Procedures Get descriptive statistics for all scale variables in the data set. Get frequency tables for all categorical variables (ordinal or nominal) in the data set. Create a histogram of Horsepower. Create a histogram of Weight. Create a QQ Plot for Weight (Analyze Descriptive Statistics QQ Plot Select Weight, leave others as default settings OK) Create a bar chart for Origin. Organize the output by Year (Analyzing groups of cases separately, compare groups). Before proceeding, select only cases with Year not = 0. Investigate Horesepower (descriptive statistics) Investigate Weight (descriptive statistics) What do you see? Remember to turn the Split File command off before proceeding! Relationship Between Continuous Y (Horsepower) and Continuous X (Weight) Create a Scatter Plot with Horsepower as the Y variable and Weight as the X variable. Add a Linear fit line. What is the relationship between Horsepower and Weight as shown in this graph? Calculate the Pearson and Spearman Correlation coefficients for the relationship between Horsepower and Vehicle Weight. What is the p-value for the Pearson correlation? What is the actual p-value, as opposed to the p-value that is displayed? To display the actual p-value for the Pearson correlation, double-click on the Pearson correlation output table and double-click on the p-value. (Remember, p-values cannot actually be equal to zero. The p-value you will see displayed, after double-clicking, will be in scientific notation.) Relationship Between Continuous Y and Numerical Discrete/Ordinal X Before doing any analyses, select only cases with Year not = 0. Create a side-by-side boxplot of MPG vs. Year. Choose MPG as the “variable” and Year as the “category axis”. What is the general trend of MPG across years? Relationship Between Continuous Y and Nominal X Create a side-by-side boxplot of Miles per gallon vs Country of Origin (ORIGIN). (Note: even though Origin is numeric in the data set, its values are nominal: American, European, Japanese). What is the general relationship between MPG and the Origin of the car? Create a side-by-side Boxplot of Miles per gallon vs. the recoded Country of Origin (1=Domestic, 0=Foreign). Final Steps Export the SPSS output into Microsoft Excel Select a few tables and/or charts that you would like to present and paste them into Microsoft Word 6.4.1 Final Project Solution The Data: The cars data sets contain data on specifications of 406 vehicles from 1970 to 1982. Among the variables in the data set are information on fuel consumption (mpg), horsepower, weight, acceleration, origin (Europe, Japan, U.S.), and number of cylinders. The data set contains categorical variables (such as origin), numerical discrete variables (such as number of cylinders), and continuous variables (such as weight, and acceleration). Getting Started Investigate cars_wave1.xls and cars_wave2.xls and prepare the data for SPSS Remove the first couple rows that contain a heading Remove the last row that contains summary information Save and exit Open SPSS and import cars_wave1.xls and cars_wave2.xls from Microsoft Excel. Open SPSS File Open Data Select “Excel” under File Type Browse for the Excel files and select Open Keep the box checked for “Read variable names from the first row of data” Leave the worksheet selected as the default Select OK Merge cars_wave1 and cars_wave2 (add cases). Data Merge Files Add Cases Select the open data file, then select Continue The Add Cases dialog will appear There should not be any “unpaired” variables Select OK Your active data file should now have 406 cases Save this data file and close the “non active” file Save this new SPSS file! Using the codebook below, define the proper attributes in Variable View Be sure to include the missing value code for MPG You only need to modify the measurement type, variable labels, variable values, and missing values. Working with Variables: Recode Origin such that 1=Domestic, 0=Foreign. Remember to recode into a different variable. Give this new variable the proper attributes in variable view. Transform Recode into different variables Select Country of Origin (ORIGIN) Name = NewOrigin Label = Recode of Origin Select the Change button Select the Old and New Values button Old Value: Value: 1 New Value: Value: 1 Select Add Old Value: Value: 2 New Value: Value: 0 Select Add Old Value: Value: 3 New Value: Value: 0 Select Add Old Value: Value: System or User Missing New Value: Value: System Missing Select Add Select Continue Select OK Go to Variable View and enter 1=Domestic, 0=Foreign under Values for this new variable. Also adjust the decimal place to 0. Convert Miles Per Gallon (MPG) to Liters Per 100 Kilometers Use the Compute function The formula to use: LP100K=(100*3.785)/(1.609*MPG) Transform Compute Variable Target Variable = LP100K Numerical Expression: (100*3.785)/(1.609*MPG) Select OK Go to Variable View and give this variable a label (Liters Per 100 Kilometers) Export this SPSS data set to Microsoft Excel (it’s always good to have a back up!). Export all of the variables. File Save As Change Files of Type to Excel Give a name and select location to save Save One Variable Procedures: Get descriptive statistics for all scale variables in the data set. Analyze Descriptive Statistics Descriptives Select Mpg Engine Horse Weight Accel Lp100k Select OK Get frequency tables for all categorical variables (nominal/ordinal) in the data set. Analyze Descriptive Statistics Frequencies Select Year Origin Cylinder NewOrigin Select OK Create a histogram of Horsepower. Graphs Legacy Dialogs Histogram Variable: Horsepower Check the box to display normal curve Select OK Investigate output Create a histogram of Weight. Graphs Legacy Dialogs Histogram Variable: Weight Check the box to display normal curve Select OK Investigate output Create a QQ Plot for Weight (to help assess normality) Analyze Descriptive Statistics QQ Plot Select Weight, leave others as default settings Select OK Create a bar chart for Origin. Graphs Legacy Dialogs Bar Simple, summaries for groups of cases Select Define Select Origin for the Category Axis Select OK Organize the output by Year (Analyzing groups of cases separately, compare groups). Before proceeding, select only cases with Year not = 0. Investigate Horsepower (descriptive statistics) Data Select Cases Select If Condition is Satisfied (select If button) Enter this condition: year ~= 0 Select Continue Output: Filter out unselected cases Select OK Data Split File Select Compare Groups Select Model Year (YEAR) for “Groups Based On” Select “Sort the file by grouping variable” Select OK Analyze Descriptive Statistics Descriptives Select Horsepower Select OK Investigate Weight (descriptive statistics) Analyze Descriptive Statistics Descriptives Select Weight Select OK What do you see happening in these two variables over time? It appears that the average horsepower and average weight are decreasing over time Remember to turn the Split File command off before proceeding! Data Split File Select Reset Select OK Relationship Between Continuous Y (Horsepower) and Continuous X (Weight): Create a Scatter Plot with Horsepower as the Y variable and Weight as the X variable. Add a Linear fit line. Graphs Legacy Dialog Scatter/Dot Simple Scatter Select Define Y Axis: Horsepower X Axis: Weight Select OK Double click on the chart in the Output Viewer to open Chart Editor Select “Add Fit Line at Total” Button (lowest row, 5th object inward) The defaults are sufficient, so close out of the “Add Fit Line at Total” dialog Close out of chart editor What is the relationship between Horsepower and Weight as shown in this graph? There is a strong positive linear relationship Calculate the Pearson and Spearman Correlation coefficients for the relationship between Horsepower and Vehicle Weight. What is the p-value for the Pearson correlation? Analyze Correlate Bivariate Select Horsepower and Weight Select Ok The pvalue is listed as .000 What is the actual p-value, as opposed to the p-value that is displayed? To display the actual p-value for the Pearson correlation, double-click on the Pearson correlation output table and double-click on the p-value. (Remember, p-values cannot actually be equal to zero. The p-value you will see displayed, after double-clicking, will be in scientific notation.) 1.18068E-120 Relationship Between Continuous Y and Numerical Discrete/Ordinal X: Before doing any analyses, select only cases with Year not = 0. Data Select Cases Select If Condition is Satisfied (select If button) Enter this condition: year ~= 0 Select Continue Output: Filter out unselected cases Select OK Create a side-by-side boxplot of MPG vs. Year. Choose MPG as the “variable” and Year as the “category axis”. Graphs Legacy Dialogs Boxplot Simple, Summaries for groups of cases Select Define Variable: MPG Category Axis: Year Select OK What is the general trend of MPG across years? The median MPG appears to increase over time Relationship Between Continuous Y and Nominal X: Create a side-by-side boxplot of Miles per gallon vs. Country of Origin (ORIGIN). (Note: even though Origin is numeric in the data set, its values are nominal: American, European, and Japanese). Graphs Legacy Dialogs Boxplot Simple, Summaries for groups of cases Select Define Variable: MPG Category Axis: ORIGIN Select OK What is the general relationship between MPG and the Origin of the car? The median MPG appears to be larger for European and Japanese cars when compared to American cars Create a side-by-side Boxplot of Miles per gallon vs. the recoded Country of Origin (1=Domestic, 0=Foreign). Graphs Legacy Dialogs Boxplot Simple, Summaries for groups of cases Select Define Variable: MPG Category Axis: RecodeOrigin Select OK Create a correlation matrix and scatter plot matrix for Horsepower, Weight, and Year. How strongly are these variables correlated? Graphs Legacy Dialogs Scatter/Dot Matrix Scatter Define Select Horsepower, Weight, Year under Matrix Variables Select OK "]
]
